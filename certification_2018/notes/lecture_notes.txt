Data distinctions:
    - Shareable vs non-shareable
        -- lock file:- non-shared; home directories:- shared
    - Variable vs static

Main Directory Layout 1:
    -------------------------------------------------------------------------------------------
    Directory       |        In FHS? |          Purpose
    -------------------------------------------------------------------------------------------
        /                   Yes         Primary directory of the entire file system hierarchy.
        /bin                Yes         Essentially executable programs that must be available in "single user mode".
        /boot               Yes         Files needed to boot the system such as the kernel, initrd or inittramfs images, and
                                        boot configuration files and bootloader programs
        /dev                Yes         Devie Nodes, used to interact with hardware and software devices.
        /etc                Yes         System wide configuration files.
        /home               Yes         User home directories including personal settings, files, etc.
        /lib                Yes         Libraries required by executable binaries in /bin and /sbin.
        /lib64              Yes         64-bit libraries required by executable binaries in /bin and /sbin, for systems which can
                                        run both 32-bit and 64-bit programs
        /media              Yes         Mount points for removable media such as CDs, DVDs, USB sticks etc.
        /mnt                Yes         Temporarily mounted filesystems
        /opt                Yes         Optional application software packages
        /proc               Yes         Virtual pseudo-filesystem giving information about the system and processes running
                                        on it. Can be used to alter system parameters.
        /sys                No          Virtual pseudo-filesystem giving information about the system and processes running
        /root               Yes         Home directory for the root user
                                        on it. Can be used to alter parameters. Similar to a device tree and is part of the Unified Device Model
        /sbin               Yes         Essential system binaries
        /srv                Yes         Site-specific data served up by the system. Seldom used.
        /tmp                Yes         Temporary files; on many distributiona lost across a reboot and may be a ramdisk in memory
        /usr                Yes         Multi-user applications, utilities and data; theoritically read-only.
        /var                Yes         Variable data that changes during system operation.

Main Directory Layout II:

extra compoents of FHS specific to certain distributions include:

/misc: for miscellaneous data, 
/tftpboot: used for booting using tftp

Special folders:
/bin:  
        - executables programs and scripts needed by both system adm ins and non-privileged users,
        - needed in single user mode
        - may contain executable used directoy by scripts
        - may not include any subdirectories
        - programs which must exists in /bin, include:
            - cat, chgrp, chmod, cp, date, dd, df, dmesg, echo, false, hostname, kill, ln, login, mkdir
                mknode, more, mount, mv ps, pwd, rm, rmdir, sed, sh, stty, su, sync, true, umount and uname. 
            - Optinally test, csh, ed, tar, cpio, gunzip, zcat, netstat and ping

/boot:
        - Essential files for booting the system must be in the /boot directory and its subdirectories, two very important ones are:
            - vmlinuz:- compressed linuz kernel
            - initramfs:- the initial RAM Filesystem, which is mounted before the real root filesystem becomes available.
        - Non-essential files include:
            - config:- used when compiling the kernel, here for booking keeping
            - System.map:- the kernel "sysmbol table", which is very useful for debugging.
            - Master boot sectors, other data.

/dev:

        - special device files also known as device nodes.
        - Note:- Network devices don't device nodes and are referenced by name only, e.g.: eth1, wlan0.

/etc:

        - machine specific configuration files.
        - others include: /etc/init.d, contains start up and shutdown scripts when using System V initialization

/lib and /lib64:

        - kernel modules:- /lib/modules/<kernel-version-number>
        - PAM:- /lib/security

/media:

        - on RHEL and SUSE removable media pops up under /run/media

/mnt:
        - Common use for it is mounting of:

            -- NFS, Samba, CIFS, AFS

/proc:
        - The kernel exposes some important data structures through /proc entries.
        - Additionally each active process on the system has its own subdirectory that gives detailed information about the 
            state of the process, the resources it's using, and its history.
        - importsnt pseudo-files like /proc/interrupts, /proc/meminfo, /proc/mounts, and 
            /proc/partitions, gives an up-to-the-moment glimpse of the system hardware.
        - /proc/filesystem, /proc/sys:- provide system configuration information an interfaces.

/sys:
        - used both to gather information about the system, and modify its behaviour while running.

/sbin:
        - contains binaries essential for booting, restoring, and/or repairing inaddition to those binaries in the
            /bin directory. 
        - programs that must be there include:
            -- fdisk, fsck, getty, halt, ifconfig, init, mkfs, mkswap, reboot, route, swapon, update

/tmp:
        - preventing use of this location to create large files systems we issue the followinf command:
            -- systemctl mask tmp.mount, then reboot
/usr:
        - secondary file hierarchy
        - used for files which are not needed for system booting
        - typically contain read-only data
        - contents:- /usr/bin, /usr/etc, /usr/games, /usr/include (Header files to compile applications), /usr/lib
                        /usr/lib64, /usr/local(third-level hierarchy for machine local files), /usr/sbin, /usr/share
                        /usr/src, /usr/tmp
/run:
        - store transient files: those that contain runtime information, which may need to be written early in system startup but don't need 
            to be preserved when rebooting.


Processes, Programs and Threads:
--------------------------------

A process is an executing program and associated resources, including environment, open files, signal handlers, etc. The same program may be executing more than once simultaneously, and thus, be responsible for multiple processes.

At the same time, two or more tasks, or threads of execution, can share various resources, such as their entire memory spaces (or just particular memory areas), open files, etc. When there is an everything shared circumstance, one speaks of a multi-threaded process.

In other operating systems, there may be a big distinction between full heavy weight processes and light weight ones; strictly speaking, the heavy weight process may include a number of light weight processes, or just one of them.

In Linux, the situation is quite different. Each thread of execution is considered individually, the difference between heavy and light having to do only with sharing of resources and somewhat faster context switching between threads of execution.

Unlike some other operating systems, Linux has always done an exceptionally fast job of creating, destroying, and switching between processes. Thus, the model adopted for multi-threaded applications resembles multiple processes; each thread is scheduled individually and normally, as if it were a stand-alone process. This is done instead of involving more levels of complication, such as having a separate method of scheduling among the threads of a process, as well as having a scheduling method between different processes.

At the same time, Linux respects POSIX and other standards for multi-threaded processes; e.g., each thread returns the same process ID (called the thread group ID internally), while returning a distinct thread ID (called the process ID internally). This can lead to confusion for developers, but should be invisible to administrators. 

2.23: /tmp

Putting files here can be disabled with the command:

   $ sudo systemctl mask tmp.mount

2.24.a. /usr 1

- secondary filesystem hierarchy
- used for files not needed for system booting
- contains binaries not needed in single user mode

2.26.a. /run 1

- store transient files: those have information that may be needed to be written early in system startup
- pseudo-filesystem existing only in memory

2.27. Examine main Consumers of Storage



3.5:Processes:-

A process is an instance of a program in execution. It may be in a number of different states, such as running or sleeping. Every process has a pid (Process ID), a ppid (Parent Process ID), and a pgid (Process Group ID). In addition, every process has program code, data, variables, file descriptors, and an environment.

init is usually the first user process run on a system, and thus becomes the ancestor of all subsequent processes running on the system, except for those initiated directly from the kernel (which show up with [] around their name in a ps listing).

If the parent process dies before the child, the ppid of the child is set to 1; i.e., the process is adopted by init. (Note: in recent Linux systems using systemd, the ppid will be set to 2, which corresponds to an internal kernel thread known as kthreadd, which has taken over from init the role of adopter of orphaned children.)

A child process which terminates (either normally or abnormally) before its parent, which has not waited for it and examined its exit code, is known as a zombie (or defunct) process. Zombies have released almost all resources and remain only to convey their exit status. One function of the init process is to check on its adopted children and let those who have terminated die gracefully. Hence, it is sometimes known as the zombie killer, or more grimly, the child reaper.

Processes are controlled by scheduling, which is completely preemptive. Only the kernel has the right to preempt a process; they cannot do it to each other.

For historical reasons, the largest PID has been limited to a 16-bit number, or 32768. It is possible to alter this value by changing /proc/sys/kernel/pid_max, since it may be inadequate for larger servers. As processes are created, eventually they will reach pid_max, at which point they will start again at PID = 300.

3.6:Process Attributes:-

All processes have certain attributes:

    The program being executed
    Context (state)
    Permissions
    Associated resources.

Every process is executing some program. At any given moment, the process may take a snapshot of itself by trapping the state of its CPU registers, where it is executing in the program, what is in the process' memory, and other information. This is the context of the process.

Since processes can be scheduled in and out when sharing CPU time with others (or have to be put to sleep while waiting for some condition to be fulfilled, such as the user to make a request or data to arrive), being able to store the entire context when swapping out the process and being able to restore it upon execution resumption is critical to the kernel's ability to do context switching.

3.7.a:Controlling Processes with ulimit:-

ulimit is a built-in bash command that displays or resets a number of resource limits associated with processes running under a shell. You can see what running ulimit with the -a argument gives us in the screenshot on this page.

Note: If you run this command as root, you will get a somewhat different output.

3.7.b:

A system administrator may need to change some of these values in either direction:

    To restrict capabilities so an individual user and/or process cannot exhaust system resources, such as memory, cpu time or the maximum number of processes on the system.
    To expand capabilities so a process does not run into resource limits; for example, a server handling many clients may find that the default of 1024 open files makes its work impossible to perform.

There are two kinds of limits:

    Hard: The maximum value, set only by the root user, that a user can raise the resource limit to.
    Soft: The current limiting value, which a user can modify but cannot exceed the hard limit.

One can set any particular limit by doing:

$ ulimit [options] [limit]

as in

$ ulimit -n 1600

which would increase the maximum number of file descriptors to 1600.

Note that the changes only affect the current shell. To make changes that are effective for all logged-in users, one needs to modify /etc/security/limits.conf, a very nicely self-documented file, and then reboot.

3.8:Process permissions and setuid:-

Every process has permissions based on which specific user invoked it. In addition, it may also have permissions based on who owns its program file.

As we will explain later in the local security section, programs which are marked with an s execute bit have a different effective user id than their real user id. These are referred to as setuid programs. They run with the user id of the user who owns the program; non-setuid programs run with the permissions of the user who runs them. setuid programs owned by root can be a well-known security problem. 

The passwd program is an example of a setuid program. Any user can run it. When a user executes this program, the process must run with root permission in order to be able to update the write-restricted /etc/passwd and /etc/shadow files where the user passwords are maintained.

3.9:More on Process States:

Processes can be in one of several possible states, the main ones being:

    -->Running
    The process is either currently executing on a CPU or CPU core or sitting in the run queue, eagerly awaiting a new time slice. It will resume running when the scheduler decides it is now deserving to occupy the CPU, or when another CPU becomes idle and the scheduler migrates the process to that CPU.
    -->Sleeping (i.e., Waiting)
    The process is waiting on a request (usually I/O) that it has made and cannot proceed further until the request is completed. When the request is completed, the kernel will wake up the process and put it back on the run queue and it will be given a time slice on a CPU when the scheduler decides to do so.
   -->Stopped
    The process has been suspended. This state is commonly experienced when a programmer wants to examine the executing program's memory, CPU registers, flags, or other attributes. Once this is done, the process may be resumed. This is generally done when the process is being run under a debugger or the user hits Ctrl-Z.
    -->Zombie
    The process enters this state when it terminates, and no other process (usually the parent) has inquired about its exit state; i.e., reaped it. Such a process is also called a defunct process. A zombie process has released all of its resources, except its exit state and its entry in the process table. If the parent of any process dies, the process is adopted by init (PID = 1) or kthreadd (PID = 2).


3.10: Execution Modes:-

At any given time, a process (or any particular thread of a multi-threaded process) may be executing in either user mode or system mode, which is usually called kernel mode by kernel developers.

What instructions can be executed depends on the mode and is enforced at the hardware, not software, level.

The mode is not a state of the system; it is a state of the processor, as in a multi-core or multi-CPU system each unit can be in its own individual state.

In Intel parlance, user mode is also termed Ring 3 and system mode is termed Ring 0.

3.11: User Mode:-

Except when executing a system call (described in the next section), processes execute in user mode, where they have lesser privileges than in kernel mode.

When a process is started, it is isolated in its own user space to protect it from other processes. This promotes security and creates greater stability. This is sometimes called process resource isolation.

Each process executing in user mode has its own memory space, parts of which may be shared with other processes; except for the shared memory segments, a user process is not able to read or write into or from the memory space of any other process.

Even a process run by the root user or as a setuid program runs in user mode, except when jumping into a system call, and has only limited ability to access hardware. 


 ------------------                                               -------------------
|                 |                                               |   Kernel        |
|                 |     System Call                               |   Mode          |
| User Mode       |---------------------------------------------->|                 |
|                 |<----------------------------------------------|                 |
|                 |        Return                                 |                 |
-------------------                                               -------------------                    


3.12: Kernel Mode:-

In kernel (system) mode, the CPU has full access to all hardware on the system, including peripherals, memory, disks, etc. If an application needs access to these resources, it must issue a system call, which causes a context switch from user mode to kernel mode. This procedure must be followed when reading and writing from files, creating a new process, etc.  

Application code never runs in kernel mode, only the system call itself which is kernel code. When the system call is complete, a return value is produced and the process returns to user mode with the inverse context switch.

There are other times when the system is in kernel mode that have nothing to do with processes, such as when handling hardware interrupts or running the scheduling routines and other management tasks for the system.

3.13: Daemons:-

A daemon process is a background process whose sole purpose is to provide some specific service to users of the system:

    Daemons can be quite efficient because they only operate when needed.
    Many daemons are started at boot time.
    Daemon names often (but not always) end with d.
    Some examples include httpd and systemd-udevd.
    Daemons may respond to external events (systemd-udevd) or elapsed time (crond).
    Daemons generally have no controlling terminal and no standard input/output devices.
    Daemons sometimes provide better security control.

When using SysVinit, scripts in the /etc/init.d directory start various system daemons. These scripts invoke commands as arguments to a shell function named daemon, defined in the /etc/init.d/functions file.

3.14: Creating Processes in a Command Shell:-

What happens when a user executes a command in a command shell interpreter, such as bash?

    A new process is created (forked from the user's login shell).
    A wait system call puts the parent shell process to sleep.
    The command is loaded onto the child process's space via the exec system call. In other words, the code for the command replaces the bash program in the child process's memory space.
    The command completes executing, and the child process dies via the exit system call.
    The parent shell is re-awakened by the death of the child process and proceeds to issue a new shell prompt. The parent shell then waits for the next command request from the user, at which time the cycle will be repeated.

If a command is issued for background processing (by adding an ampersand -&- at the end of the command line), the parent shell skips the wait request and is free to issue a new shell prompt immediately, allowing the background process to execute in parallel. Otherwise, for foreground requests, the shell waits until the child process has completed or is stopped via a signal.

Some shell commands (such as echo and kill) are built into the shell itself, and do not involve loading of program files. For these commands, no fork or exec are issued for the execution.

3.15: Kernel-Created Processes:-

Not all processes are created, or forked from user parents. The Linux kernel directly creates two kinds of processes on its own initiative. These are:

    Internal kernel processes:
    These take care of maintenance work, such as making sure buffers get flushed out to disk, that the load on different CPUs is balanced evenly, that device drivers handle work that has been queued up for them to do, etc. These processes often run as long as the system is running, sleeping except when they have something to do. 
    External user processes
    These are processes which run in user space like normal applications but which the kernel started. There are very few of these and they are usually short lived.

It is easy to see which processes are of this nature; when you run a command such as

$ ps -elf

to list all processes on the system while showing the parent process IDs, they will all have  PPID = 2, which refers to kthreadd, the internal kernel thread whose job is to create such processes, and their names will be encapsulated in square brackets, such as [ksoftirqd/0].

3.16: Process Creating and Forking:-

An average Linux system is always creating new processes. This is often called forking; the original parent process keeps running while the new child process starts.

When most computers had only single processors, they were usually configured so the parent would initially pause while the child started to run; there is a UNIX expression:  "Children come first."  However, with modern multi-CPU systems, both will tend to run simultaneously on different CPUs.

Often rather than just a fork, one follows it with an exec, where the parent process terminates and the child process inherits the process ID of the parent. The term fork and exec is used so often, people think of it sometimes as one word.

Older UNIX systems often used a program called spawn, which is similar in many ways to fork and exec, but differs in details. It is not part of the POSIX standard, and is not a normal part of Linux.

To see how new processes may start, consider a web server that handles many clients. It may launch a new process every time a new connection is made with a client. On the other hand, it may simply start only a new thread as part of the same process; in Linux, there really isn't much difference on a technical level between creating a full process or just a new thread, as each mechanism takes about the same time and uses roughly the same amount of resources.

As another example, the sshd daemon is started when the init process executes the sshd init script, which then is responsible for launching the sshd daemon. This daemon process listens for ssh requests from remote users.

When a request is received, sshd creates a new copy of itself to service the request. Each remote user gets their own copy of the sshd daemon running to service their remote login. The sshd process will start the login program to validate the remote user. If the authentication succeeds, the login process will fork off a shell (say bash) to interpret the user commands, and so on. 

3.17.a.: Using nice to Set Priorities:-

Process priority can be controlled through the nice and renice commands. Since the early days of UNIX, the idea has been that a nice process lowers its priority to yield to others. Thus, the higher the niceness is, the lower the priority.

The niceness value can range from -20 (the highest priority) to +19 (the lowest priority). The normal way to run nice is as in:

$ nice -n 5 command [ARGS]

which would increase the niceness by 5. This is equivalent to doing:

$ nice -5 command [ARGS] 

3.17.b.: Using nice to Set Priorities:-

If you do not give a nice value, the default is to increase the niceness by 10. If you give no arguments at all, you report your current niceness. So, for example:

$ nice
0
$ nice cat &
[1] 24908
$ ps -l
F S UID   PID  PPID C PRI NI ADDR SZ WCHAN  TTY          TIME CMD
0 S 500  4670  4603 0 80   0 - 16618 wait   pts/0    00:00:00 bash
0 S 500 24855  4670 0 80   0 - 16560 wait   pts/0    00:00:00 bash
0 T 500 24908 24855 0 90  10 - 14738 signal pts/0    00:00:00 cat
0 R 500 24909 24855 0 80   0 - 15887 -      pts/0    00:00:00 ps

Note that increasing the niceness of a process does not mean it won't run; it may even get all the CPU time if there is nothing else with whitch to compete.

If you supply such a large increment or decrement that you try to step outside the -20 to 19 range, the increment value will be truncated.

3.18: Modifying the Nice Value:-

By default, only a superuser can decrease the niceness; i.e., increase the priority. However, it is possible to give normal users the ability to decrease their niceness within a predetermined range, by editing /etc/security/limits.conf.

To change the niceness of an already running process, it is easy to use the renice command, as in:

$ renice +3 13848

which will increase niceness by 3 of the process with pid  =  13848. More than one process can be done at the same time and there are some other options, so see man renice. 

See 'man nice'

3.20.: Static and Shared Libraries:-

Programs are built using libraries of code, developed for multiple purposes and used and reused in many contexts.

There are two types of libraries:

    Static
    The code for the library functions is inserted in the program at compile time, and does not change thereafter, even if the library is updated.
    Shared
    The code for the library functions is loaded into the program at run time, and if the library is changed later, the running program runs with the new library modifications.

Using shared libraries is more efficient because they can be used by many applications at once; memory usage, executable sizes, and application load time are reduced.

Shared Libraries are also called DLLs (Dynamic Link Library).

3.21.: Shared Libraries Versions:-

Shared libraries need to be carefully versioned. If there is a significant change to the library and a program is not equipped to handle it, serious problems can be expected. This is sometimes known as DLL Hell.

Therefore, programs can request a specific major library version rather than the latest one on the system. However, usually the program will always use the latest minor version available.

Some application providers will use static libraries bundled into the program to avoid these problems. However, if there are improvements or bugs and security holes fixed in the libraries, they may not make it into the applications in a timely fashion.

Shared libraries have the extension .so. Typically, the full name is something like libc.so.N  where N is a major version number.

Under Linux, shared libraries are carefully versioned. For example:

c7:/usr/lib64>ls -lF libgdbm.so*

lrwxrwxrwx 1 root root 16 Apr 9 2015 libgdbm.so -> libgdbm.so.4.0.0*

lrwxrwxrwx 1 root root 16 Apr 9 2015 libgdbm.so.4 -> libgdbm.so.4.0.0*

-rwxr-xr-x 1 root root 36720 Jan 24 2014 libgdbm.so.4.0.0*

c7:/usr/lib64>

so a program that just asks for libgdm  gets  libgdm.so  and the others for specific major and minor versions.

3.22.a.: Finding Shared Libraries:-

A program which uses shared libraries has to be able to find them at runtime.

ldd can be used to ascertain what shared libraries an executable requires. It shows the soname of the library and what file it actually points to.

3.22.b.: Finding Shared Libraries:-

ldconfig is generally run at boot time (but can be run anytime), and uses the file /etc/ld.so.conf, which lists the directories that will be searched for shared libraries. ldconfig must be run as root and shared libraries should only be stored in system directories when they are stable and useful.

Besides searching the data base built up by ldconfig, the linker will first search any directories specified in the environment variable LD_LIBRARY_PATH, a colon separated list of directories, as in the PATH variable. So, you can do:

$ LD_LIBRARY_PATH=$HOME/foo/lib

$ foo [args]

or

$ LD_LIBRARY_PATH=$HOME/foo/lib foo [args]

4.3: What Are Signals?

Signals are one of the oldest methods of Inter-Process Communication (IPC) and are used to notify processes about asynchronous events (or exceptions).

By asynchronous, we mean the signal-receiving process may:

    Not expect the event to occur.
    Expect the event, but not know when it is most likely to occur.

For example, if a user decides to terminate a running program, it could send a signal to the process through the kernel to interrupt and kill the process.

There are two paths by which signals are sent to a process:

    From the kernel to a user process, as a result of an exception or programming error.
    From a user process (using a system call) to the kernel which will then send it to a user process. The process sending the signal can actually be the same as the one receiving it.

Signals can only be sent between processes owned by the same user or from a process owned by the superuser to any process.

When a process receives a signal, what it does will depend on the way the program is written. It can take specific actions, coded into the program, to handle the signal or it can just respond according to system defaults. Two signals (SIGKILL and SIGSTOP) cannot be handled and will always terminate the program.



4.4.a.: Types of Signals:-

There are a number of different types of signals, and the particular signal which is dispatched indicates what type of event (or exception) occurred. Generally, signals are used to handle two things:

    Exceptions detected by hardware (such as an illegal memory reference)
    Exceptions generated by the environment (such as the premature death of a process from the user's terminal).

To see a list of the signals in Linux, along with their numbers, do kill -l, as reflected in this screenshot.

The signals from SIGRTMIN on are termed real-time signals and are a relatively recent addition. They have no predefined purpose, and differ in some important ways from normal signals; they can be queued up and are handled in a FIFO (First In First Out) order.

The meaning attached to the signal type indicates what event caused the signal to be sent. While users can explicitly send any signal type to one of their processes, the meaning attached may no longer be implied by the signal number or type, and can be used in any way that the process desires.

Typing man 7 signal will give further documentation.

Signal                          Value   DefaultAction           POSIX?          Meaning
SIGHUP                          1       Terminate               Yes             Hangup  detected on controlling terminal or death of controlling  process.
SIGINT                          2       Terminate               Yes             Interrupt  from   keyboard.
SIGQUIT                         3       Cordump                 Yes             Quit from keyboard.
SIGILL                          4       Coredump                Yes             Illegal Instruction.
SIGTRAP                         5       Coredump                No              Trace/breakpoint trap for debugging.
SIGABRT
SIGIOT                          6       Coredump                Yes             Abnormal termination.
SIGBUS                          7       Coredump                Yes             Bus error.
SIGFPE                          8       Coredump                Yes             Floating point exception.
SIGKILL                         9       Terminate               Yes             Kill signal (can not be caught or ignored).
SIGUSR1                         10      Terminate               Yes             User-definedsignal 1.
SIGSEGV                         11      Coredump                Yes             Invalid memory reference.
SIGUSR2                         12      Terminate               Yes             User-defined signal 2.
SIGPIPE                         13      Terminate               Yes             Broken pipe: write to pipe with no readers.
SIGALRM                         14      Terminate               Yes             Timer  signal from alarm.
SIGTERM                         15      Terminate               Yes             Process termination.
SIGSTKFLT                       16      Terminate               No              Stack fault on math co-processor.
SIGCHLD                         17      Ignore                  Yes             Child stopped or terminated.
SIGCONT                         18      Continue                Yes             Continue if stopped.
SIGSTOP                         19      Stop                    Yes             Stop process (can not be caught or ignored).
SIGTSTP                         20      Stop                    Yes             Stop types at tty.
SIGTTIN                         21      Stop                    Yes             Background process requires tty input.
SIGTTOU                         22      Stop                    Yes             Background process requires tty output.
SIGURG                          23      Ignore                  No              Urgent condition on socket (4.2 BSD).
SIGXCPU                         24      Coredump                Yes             CPU time limit exceeded (4.2 BSD).
SIGXFSZ                         25      Coredump                Yes             File size limit exceeded (4.2 BSD).
SIGVTALRM                       26      Terminate               No              Virtual alarm clock (4.2 BSD).
SIGPROF                         27      Terminate               No              Profile alarm clock (4.2 BSD).
SIGWINCH                        28      Ignore                  No              Window resize signal (4.3 BSD, Sun).
SIGIO
SIGPOLL                         29      Terminate               No              I/O now possible (4.2 BSD) (System V).
SIGPWR                          30      Terminate               No              Power Failure (System V).
SIGSYS
SIGUNUSED                       31      Terminate               No              Bad System Called. Unused signal.

4.5: kill:-

A process cannot send a signal directly to another process; it must ask the kernel to send the signal by executing a system call. Users (including the superuser) can send signals to other processes from the command line or scripts by using kill as in:

$ kill 1991

$ kill -9 1991

$ kill -SIGKILL 1991

where we are sending a signal to the process with PID = 1991. If a signal number is not given (as in the first example), the default is to send SIGTERM (15), a terminate signal that can be handled; the program can take elusive action or clean up after itself, rather than just die immediately. If this signal is ignored, the user can usually send a SIGKILL (9), which cannot be ignored, to terminate with extreme prejudice.

The name kill is really a bad name, a misnomer that survives for historical reasons. Although it is often used to kill (terminate) processes, the command's real function is to send any and all signals to processes, even totally benign informative ones.

4.6.: killall and pkill:-

killall kills all processes with a given name, assuming the user has sufficient privilege. It uses a command name rather than a process ID, and can be done as in:

$ killall bash

$ killall -9 bash

$ killall -SIGKILL bash

pkill sends a signal to a process using selection criteria:

$ pkill [-signal] [options] [pattern]

For example:

$ pkill -u libby foobar

will kill all of libby's processes with a name of foobar.

Another example:

$ pkill -HUP rsyslogd

makes rsyslog re-read its configuration file.

5.1. Package Management Systems

- APT: Advanced Packageing Tool
- RPM: Redhat Package Management

- Levels:
    - Low level:
        - rpm
        - dpkg
    - Higher level:
        - yum, dnf, zypper
        - apt-get apt

5.3. Software Packaging Concepts:

- Allows for automating installations, upgrading, configuring and removing software packages in a known predictable, consistent manner.
- These systems:
    - gather and compress associated software files into single package (archive), which may require one or more packages to be installed first
    - allow for easy software installation or removal,
    - can verify file integrity via an internal database
    - can authenticate the origin of the packages.
    - facilitate upgrades
    - group packages by logical features
    - manage dependencies between packages

5.4. Why Use Packages:

Software package management systems are widely seen as one of the biggest advancements Linux brought to enterprise IT environments. By keeping track of files and metadata in an automated, predictable and reliable way, system administrators can use package management systems to make their installation processes scale to thousands of systems without requiring manual work on each individual system. Features include:

    Automation:  No need for manual installs and upgrades.
    Scalability:  Install packages on one system, or 10,000 systems.
    Repeatability and predictability.
    Security and auditing.

5.5. Package Types

Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. ackages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. 


5.6. Available Package Management Systems:

There are two very common package management systems:

    RPM (Red Hat Package Manager)
    This system is used by all Red Hat-derived distributions, such as Red Hat Enterprise Linux, CentOS, Scientific Linux and CentOS, as well as by SUSE and its related community openSUSE distribution.
    dpkg (Debian Package)
    This system is used by all Debian-derived distributions ,including Debian, Ubuntu and Linux Mint.

There are other package management systems, such as portage/emerge used by Gentoo, pacman used by Arch, and specialized ones used by Embedded Linux systems and Android.

Another ancient system is just to supply packages as tarballs without any real management or clean removal strategies; this approach still marks Slackware, one of the oldest Linux distributions.

But most of the time, it is either RPM or dpkg and these are the only ones we will consider in this course.


5.7. Packaging Tool Levels and Varieties

There are two levels to packaging systems:

    Low Level Utility
    This simply installs or removes a single package, or a list of packages, each one of which is individually and specifically named. Dependencies are not fully handled, only warned about:
    - If another package needs to be installed, first installation will fail.
    - If the package is needed by another package, removal will fail.
    The rpm and dpkg utilities play this role for the packaging systems that use them.
    High Level Utility
    This solves the dependency problems:
    - If another package or group of packages needs to be installed before software can be installed, such needs will be satisfied.
    - If removing a package interferes with another installed package, the administrator will be given the choice of either aborting, or removing all affected software.
    The yum, dnf, and zypper utilities (and more recently, PackageKit) take care of the dependency resolution for rpm systems, and apt-get and apt-cache and other utilities take care of it for dpkg systems.

In this course, we will only discuss the command line interface to the packaging systems; while the graphical frontends used by each Linux distribution can be useful, we would like to be less tied to any one interface and have more flexibility. 

5.8. Package Soures

Every distribution has one or more package repositories where system utilities go to obtain software and to update with new versions. It is the job of the distribution to make sure all packages in the repositories play well with each other.

There are always other, external repositories, which can be added to the standard distribution-supported list. Sometimes, these are closely associated with the distribution, and only rarely produce significant problems; an example would be the EPEL (Extra Packages for Enterprise Linux) set of version-dependent repositories, which fit well with RHEL since their source is Fedora and the maintainers are close to Red Hat.

However, some external repositories are not very well constructed or maintained. For example, when a package is updated in the main repository, dependent packages may not be updated in the external one, which can lead to one form of dependency hell. 

5.11. Available Source Control Systems

There is no shortage of available products, both proprietary and open; a brief list of products released under a GPL license includes:

 
Product 	URL
==========================
RCS	        http://www.gnu.org/software/rcs
CVS	        http://ximbiot.com/cvs/wiki 
Subversion	http://subversion.tigris.org 
git	        http://www.kernel.org/pub/software/scm/git
GNU Arch	http://www.gnu.org/software/gnu-arch 
Monotone	http://www.monotone.ca
Mercurial	http://mercurial-scm.org/
PRCS	    http://prcs.sourceforge.net

 

We will focus only on git, a widely used product which arose from the Linux kernel development community. git has risen to a dominant position in use for open source projects in a remarkably short time, and is often used even in closed source environments.


5.12 The Linux Kernel and the Birth of git

The Linux kernel development system has special needs in that it is widely distributed throughout the world, with literally thousands of developers involved. Furthermore it is all done very publicly, under the GPL license.

For a long time, there was no real source revision control system. Then, major kernel developers went over to the use of BitKeeper (see http://www.bitkeeper.com), a commercial project which granted a restricted use license for Linux kernel development.

However, in a very public dispute over licensing restrictions in the spring of 2005, the free use of BitKeeper became unavailable for Linux kernel development.

The response was the development of git, whose original author was Linus Torvalds. The source code for git can be obtained from http://www.kernel.org/pub/software/scm/git/, and full documentation can be found at http://www.kernel.org/pub/software/scm/git/docs/.

5.13. How git works

Technically, git is not a source control management system in the usual sense, and the basic units it works with are not files. It has two important data structures: an object database and a directory cache.

The object database contains objects of three varieties:

    Blobs: Chunks of binary data containing file contents
    Trees: Sets of blobs including file names and attributes, giving the directory structure
    Commits: Changesets describing tree snapshots.

The directory cache captures the state of the directory tree.

By liberating the controls system from a file-by-file-based system, one is better able to handle changesets which involve many files.

git is always under rapid development and graphical interfaces to it are also under speedy construction. For example, see http://www.kernel.org/git/. One can easily browse particular changes, as well as source trees.

Sites such as http://www.github.com now host literally millions of git repositories, both public and private. There are a host of easy-to-find articles, books, online tutorials, etc., on how to profitably use git.


6.2. Laerning Objectives

By the end of this chapter, you should be able to:

    Understand how the RPM system is organized and what major operations the rpm program can accomplish.
    Explain the naming conventions used for both binary and source rpm files.
    Know how to query, verify, install, uninstall, upgrade and freshen packages.
    Grasp why new kernels should be installed rather than upgraded.
    Know how to use rpm2cpio to copy packaged files into a cpio archive, as well as to extract the files without installing them.


6.3. RPM

RPM (the Red Hat Package Manager) was developed (unsurprisingly) by Red Hat. All files related to a specific task are packaged into a single rpm file, which also contains information about how and where to install and uninstall the files. New versions of software lead to new rpm files which are then used for updating.

rpm files also contain dependency information. Note that unless given a specific URL to draw from, rpm in itself does not retrieve packages over the network and installs only from the local machine using absolute or relative paths.

rpm files are usually distribution-dependent; installing a package on a different distribution than it was created for can be difficult, if not impossible. 


6.4. Advantages of Using RPM

For system administrators, RPM makes it easy to:

    Determine what package (if any) any file on the system is part of.
    Determine what version is installed.
    Install and uninstall (erase) packages without leaving debris behind.
    Verify that a package was installed correctly; this is useful for both troubleshooting and system auditing.
    Distinguish documentation files from the rest of the package and optionally decide not to install them to save space.
    Use ftp or HTTP to install packages over the Internet.

For developers RPM offers advantages as well:

    Software often is made available on more than one operating system. With RPM the original full and unmodified source is used as the basis, but a developer can separate out the changes needed to build on Linux.
    More than one architecture can be built using only one source package.

6.5. Package File Names

RPM package file names are based on fields that represent specific information, as documented in the RPM standard  (http://www.rpm.org/)

    - The standard naming format for a binary package is:
    <name>-<version>-<release>.<distro>.<architecture>.rpm
    sed-4.2.1-10.el6.x86_64.rpm
    - The standard naming format for a source package is:
    <name>-<version>-<release>.<distro>.src.rpm
    sed-4.2.1-10.el6.src.rpm

Note that the distro field often actually specifies the repository that the package came from, as a given installation may use a number of different package repositories as we shall discuss when we discuss yum and zypper which work above RPM.

6.6. Database Directory

/var/lib/rpm is the default system directory which holds RPM database files in the form of  Berkeley DB hash files. The database files should not be manually modified; updates should be done only through use of the rpm program.

An alternative database directory can be specified with the --dbpath option to the rpm program. One might do this, for example, to examine an RPM database copied from another system.

You can use the --rebuilddb option to rebuild the database indices from the installed package headers; this is more of a repair, and not a rebuild from scratch.

6.7. Helper Programs and Modifying Settings

Helper programs and scripts used by RPM reside in /usr/lib/rpm. There are quite a few; for example on a RHEL 7 system: 

$ ls /usr/lib/rpm | wc -l

73

where wc is reporting the number of lines of output.

You can create an rpmrc file to specify default settings for rpm. By default, rpm looks for:

    /usr/lib/rpm/rpmrc
    /etc/rpmrc
    ~/.rpmrc

in the above order. Note all these files are read; rpm does not stop as soon as it finds that one exists. An alternative rpmrc file can be specified using the --rcfile option.

6.8.a. Queries I

All rpm inquiries include the -q option, which can be combined with numerous sub-options, as in:

    Which version of a package is installed?
    $ rpm -q bash
    Which package did this file come from?
    $ rpm -qf /bin/bash
    What files were installed by this package?
    $ rpm -ql bash
    Show information about this package.
    $ rpm -qi bash
    Show information about this package from the package file, not the package database.
    $ rpm -qip foo-1.0.0-1.noarch.rpm
    List all installed packages on this system.
    $ rpm -qa 

6.8.b. Queries II

A couple of other useful options are --requires and --whatprovides:

    Return a list of prerequisites for a package:
    $ rpm -qp --requires foo-1.0.0-1.noarch.rpm
    Show what installed package provides a particular requisite package:
    $ rpm -q --whatprovides libc.so.6 

6.9.a. Verifying Pacakages I

The -V option to rpm allows you to verify whether the files from a particular package are consistent with the system's RPM database. To verify all packages installed on the system:

$ rpm -Va
missing   /var/run/pluto
....
S.5....T. c /etc/hba.conf
S.5....T. /usr/share/applications/defaults.list
....L.... c /etc/pam.d/fingerprint-auth
....L.... c /etc/pam.d/password-auth
....
.M....... /var/lib/nfs/rpc_pipefs
....
.....UG.. /usr/local/bin
.....UG.. /usr/local/etc

showing just a few items. (Note this command can take a long time, as it examines all files owned by all packages.)

Output is generated only when there is a problem. 


6.9.b. Verifying Packages II

Each of the characters displayed on the previous page denotes the result of a comparison of attribute(s) of the file to the value of
those attribute(s) recorded in the database. A single . (period) means the test passed, while a single ? (question mark) indicates the test could not be performed (e.g. file permissions prevent reading). Otherwise, the character denotes failure of the corresponding verification test:

    S: file size differs
    M: file permissions and/or type differs
    5: MD5 checksum differs
    D: device major/minor number mismatch
    L: symbolic link path mismatch
    U: user ownership differs
    G: group ownership differs
    T: modification time differs
    P: capabilities differ

Note that many of these verification tests do not indicate a problem. For example, many configuration files are modified as the system evolves.

6.9.c. Verifying Packages III

If you specify one or more package names as an argument, you examine only that package as in the following examples:

    No output when everything is OK:
    $ rpm -V bash
    Output indicating that a file's size, checksum, and modification time have changed:
    $ rpm -V talk
    S.5....T in.ntalkd.8
    Output indicating that a file is missing:
    $ rpm -V talk
    missing /usr/bin/talk

6.10. Installing Packages

Installing a package is as simple as:

$ sudo rpm -ivh foo-1.0.0-1.noarch.rpm

where the -i is for install, -v is for verbose, and -h just means print out hash marks while doing to show progress.

RPM performs a number of tasks when installing a package:

    Performs dependency checks:
    Necessary because some packages will not operate properly unless one or more other packages are also installed.
    Performs conflict checks:
    Include attempts to install an already-installed package or to install an older version over a newer version.
    Executes commands required before installation:
    The developer building a package can specify that certain tasks be performed before or after the install.
    Deals intelligently with configuration files:
    When installing a configuration file, if the file exists and has been changed since the previous version of the package was installed, RPM saves the old version with the suffix .rpmsave. This allows you to integrate the changes you have made to the old configuration file into the new version of the file. This feature depends on properly created RPM packages.
    Unpacks the files from packages and installs them with correct attributes:
    In addition to installing files in the right place, RPM also sets attributes such as permissions, ownership, and modification (build) time.
    Executes commands required after installation:
    Performs any post-install tasks required for setup or initialization
    Updates the system RPM database:
    Every time RPM installs a package, it updates information in the system database. It uses this information when checking for conflicts.

6.11.a. Uninstalling Packages I

The -e option causes rpm to uninstall (erase) a package. Normally, rpm -e fails with an error message if the package you are attempting to uninstall is either not actually installed, or is required by other packages on the system. A successful uninstall produces no output.

$ sudo rpm -e system-config-lvm

package system-config-lvm is not installed


6.11.b. Uninstalling Packages II

You can use the --test option along with -e to determine whether the uninstall would succeed or fail, without actually doing the uninstall. If the operation would be successful, rpm prints no output. Add the -vv option to get more information.

Remember the package argument for the erase is the package name, not the rpm file name.

Important (but obvious) note: Never remove (erase/uninstall) the rpm package itself. The only way to fix this problem is to re-install the operating system, or by booting into a rescue environment.

6.13. Upgrading Packages

Upgrading replaces the original package (if installed) as in:

$ sudo rpm -Uvh bash-4.2.45-5.el7_0.4.x86_64.rpm

You can give a list of package names, not just one.

When upgrading, the already installed package is removed after the newer version is installed. The one exception is the configuration files from the original installation, which are kept with a .rpmsave extension.

If you use the -U option and the package is not already installed, it is simply installed and there is no error.

The -i option is not designed for upgrades; attempting to install a new RPM package over an older one fails with error messages, because it tries to overwrite existing system files.

However, different versions of the same package may be installed if each version of the package does not contain the same files: kernel packages and library packages from alternative architectures are typically the only packages that would be commonly installed multiple times.

If you want to downgrade with rpm -U (that is, to replace the current version with an earlier version), you must add the --oldpackage option to the command line.

6.14. Freshening Packages

The command:

$ sudo rpm -Fvh *.rpm

will attempt to freshen all the packages in the current directory. The way this works is:

    If an older version of a package is installed, it will be upgraded to the newer version in the directory.
    If the version on the system is the same as the one in the directory, nothing happens.
    If there is no version of a package installed, the package in the directory is ignored. 

Freshening can be useful for applying a lot of patches (i.e., upgraded packages) at once.


6.15. Upgrading the Kernel

When you install a new kernel on your system, it requires a reboot (one of the few updates that do) to take effect. You should not do an upgrade (-U) of a kernel: an upgrade would remove the old currently running kernel.

This in and of itself won't stop the system, but if, after a reboot, you have any problems, you will no longer be able to reboot into the old kernel, since it has been removed from the system. However, if you install (-i), both kernels coexist and you can choose to boot into either one; i.e., you can revert back to the old one if need be.

To install a new kernel do:

$ sudo rpm -ivh kernel-{version}.{arch}.rpm

filling in the correct version and architecture names.

When you do this, the GRUB configuration file will automatically be updated to include the new version; it will be the default choice at boot, unless you reconfigure the system to do something else.

Once the new kernel version has been tested, you may remove the old version if you wish, though this is not necessary. Unless you are short on space, it is recommended that you keep one or more older kernels available.


6.16. Using rpm2cpio

Suppose you have a need to extract files from an rpm but do not want to actually install the package?

The rpm2cpio program can be used to copy the files from an rpm to a cpio archive, and also extract the files if so desired.

Create the cpio archive with:

$ rpm2cpio foobar.rpm > foobar.cpio

To list files in an rpm:

$ rpm2cpio foobar.rpm | cpio -t

but a better way is to do:

$  rpm -qilp foobar.rpm

To extract onto the system:

$ rpm2cpio bash-4.2.45-5.el7_0.4.x86_64.rpm |  cpio -ivd bin/bash

$ rpm2cpio foobar.rpm | cpio --extract --make-directories


7.1. DPKG - Introduction

The Debian Package Manager (DPKG) is used by all Debian-based distributions to control the installation, verification, upgrade, and removal of software on Linux systems. The low-level dpkg program can perform all these operations, either on just one package, or on a list of packages. Operations which would cause problems (such as removing a package that another package depends on, or installing a package when the system needs other software to be installed first) are blocked from completion.


7.2. learning Objectives

By the end of this chapter, you should be able to:

    Discuss the DPKG packaging system and its uses.
    Explain the naming conventions used for both binary and source deb files.
    Know what source packages look like.
    Use querying and verifying operations on packages.
    Install, upgrade, and uninstall Debian packages.

7.3. DPKG Essentials

DPKG (Debian Package) is the packaging system used to install, remove, and manage software packages under Debian Linux and other distributions derived from it. Like RPM, it is not designed to directly retrieve packages in day-to-day use, but to install and remove them locally.

Package files have a .deb suffix and the DPKG database resides in the /var/lib/dpkg directory.

Like rpm, the dpkg program has only a partial view of the universe: it knows only what is installed on the system, and whatever it is given on the command line, but knows nothing of the other available packages, whether they are in some other directory on the system, or out on the Internet. As such, it will also fail if a dependency is not met, or if one tries to remove a package other installed packages need. 


7.4. Package File Names

Debian package file names are based on fields that represent specific information. The standard naming format for a binary package is:

<name>_<version>-<revision_number>_<architecture>.deb

as in:

logrotate_3.8.7-1_amd64.deb

on Debian, and

logrotate_3.8.7-1ubuntu1_amd64.deb

on Ubuntu. Note that, for historical reasons, the 64-bit x86 platform is called amd64 rather than x86_64, and distributors such as Ubuntu manage to insert their name in the package name.


7.5.a. Source Packages I

In the Debian packaging system, a source package consists of at least three files:

    An upstream tarball, ending with .tar.gz. This is the unmodified source as it comes from the package maintainers.
    A description file, ending with .dsc, containing the package name and other metadata, such as architecture and dependencies.
    A second tarball that contains any patches to the upstream source, and additional files created for the package, and ends with a name .debian.tar.gz or .diff.gz, depending on distribution.

7.6. DPKG Queries

Here are some examples of queries you can make:

    List all packages installed:
    $ dpkg -l
    One can also specify a package name.
    List files installed in the wget package:
    $ dpkg -L wget
    Show info about an installed package:
    $ dpkg -s wget
    Show info about a package file:
    $ dpkg -I webfs_1.21+ds1-8_amd64.deb
    List files in a package file:
    $ dpkg -c webfs_1.21+ds1-8_amd64.deb
    Show what package owns /etc/init/networking.conf:
    $ dpkg -S /etc/init/networking.conf
    Show the status of a package:
    $ dpkg -s wget
    Verify the installed package's integrity:
    $ dpkg -V package
    Without arguments, this will verify all packages on the system. See the man page to interpret the output. Note: only recent versions of dpkg (1.17+) support this option.


7.7. Installing/Upgrading/Uninstalling Packages

The command:

$ sudo dpkg -i foobar.deb

would be used for either installing or upgrading the foobar package.

If the package is not currently installed, then it will be installed. If the package is newer than the one currently installed, then it will be upgraded.

The command:

$ sudo dpkg -r package

is used to remove all of an installed package except for its configuration files. The command:

$ sudo dpkg -P package

is used to remove all of an installed package including its configuration files.  (Note that -P stands for purge.)

8.1. yum - Intro

The yum program provides a higher level of intelligent services for using the underlying rpm program. It can automatically resolve dependencies when installing, updating and removing packages. It accesses external software repositories, synchronizing with them and retrieving and installing software as needed.


8.2. Learning Objectives

By the end of this chapter, you should be able to: 

    Discuss package installers and their characteristics.
    Explain what yum is.
    Configure yum to use repositories.
    Discuss the queries yum can be used for.
    Verify, install, remove, and upgrade packages using yum.

8.3. Package Installers

The lower-level package utilities such as rpm and dpkg deal with the details of installing specific software package files and managing already installed software.

The higher-level package management systems (such as yum, dnf, apt and zypper) work with databases of available software and incorporate the tools needed to find, install, update, and uninstall software in a highly intelligent fashion. They:

    Can use both local and remote repositories as a source to install and update binary as well as source software packages.
    Are used to automate the install, upgrade, and removal of software packages.
    Resolve dependencies automatically.
    Save time because there is no need to either download packages manually or search out dependency information separately.

The software repositories are provided by distributions and other independent software providers. The package installers maintain databases of available software derived from catalogs kept by the repositories. Unlike the low-level package tools, they have the ability to find and install dependencies automatically, a critical feature.

In this section we will talk about yum and dnf; we will get to zypper and apt next.


8.4. What is yum?

yum provides a frontend to rpm. Its primary task is to fetch packages from multiple remote repositories and resolve dependencies among packages. It is used by the majority (but not all) distributions that use rpm, including RHEL, CentOS, Scientific Linux and Fedora.

yum caches information and databases to speed up performance. To remove some or all cached information, one can run the command:

$ yum clean [ packages | metadata | expire-cache | rpmdb | plugins | all ]

yum has a number of modular extensions (plugins) and companion programs that can be found under /usr/bin/yum* and /usr/sbin/yum*.

We will concentrate on the command line use of yum and not consider the graphical interfaces distributions provide.


8.5. Configuring yum to Use Repositories

Repository configuration files are kept in /etc/yum.repos.d/ and have a .repo extension. For example, on one RHEL 7 system we have:

    ls -l /etc/yum.repos.d

Note that on RHEL 6 there is no redhat.repo file. RHEL 6 and earlier versions handled the distribution-supplied repos in a somewhat different manner, although RHEL clones like CentOS used conventional repos for the main distribution packages.


8.6. Repository Files

A very simple repository file might look like:

[repo-name]

name=Description of the repository

baseurl=http://somesystem.com/path/to/repo

enabled=1

gpgcheck=1

More complicated examples can be found in /etc/yum.repos.d and it would be a good idea to examine them.

One can toggle the use of a particular repository on or off by changing the value of enabled to 0 or 1, or using the --disablerepo=somerepo and --enablerepo=somerepo options when using yum. One can (but should not) also turn off integrity checking with the gpgcheck variable.


8.7.a. Queries I

Like rpm, yum can be used for queries such as searches; however, it can search not just what is present on the local system, it can also inquire about remote repositories. Some examples:

    Search for packages with keyword in name:

    $ sudo yum search keyword
    $ sudo yum list "*keyword*"

    These two commands give somewhat different information. The first one tells more about the packages, while the second one makes it clearer what is installed and what else is available.
    Display information about a package:

    $ sudo yum info package

    Information includes size, version, what repository it came from, a source URL, and a longer description. Wildcards can be given, as in yum info "libc*", for this and most yum commands. Note that the package need not be installed, unlike queries made with rpm -q.


8.7.b. Queries II

More yum examples:

    List all packages, or just those installed, available, or updates that have not yet been installed:

    $ sudo yum list [installed | updates | available ]
    Show information about package groups installed or available, etc.:

    $ sudo yum grouplist [group1] [group2]
    $ sudo yum groupinfo group1 [group2]
    Show packages that contain a certain file name:

    $ sudo yum provides

    as in

    $ sudo yum provides "/logrotate.conf"

    Please note the need to use at least one / in the file name, which can be confusing.

8.8. Verify Packages

Package verification requires installation of the yum-plugin-verify package. So, you might have to do:

$ sudo yum install yum-plugin-verify

Note that this is a yum plugin, not an executable. There are many other plugins available for yum, which extend the possible set of commands and arguments it can take:

    To verify a package, giving the most information:
    $ sudo yum verify [package]
    To mimic rpm -V exactly:
    $ sudo yum verify-rpm [package]
    To list all differences, including configuration files:
    $ sudo yum verify-all [package]

Without arguments, the above commands will verify all packages installed on the system.

By default, the verification commands ignore configuration files which may change through normal and safe usage. There are some other options: see man yum-verify.

8.9.a. Installing/Removing/Upgrading Packages I

Here are some examples of commonly performed operations:

    Install one or more packages from repositories, resolving and installing any necessary dependencies:

    $ sudo yum install package1 [package2]
    Install from a local rpm:

    $ sudo yum localinstall package-file

    This is not quite the same as

    $ rpm -i package-file

    because it will attempt to resolve dependencies by accessing remote repositories.

8.9.b. Installing/Removing/Upgrading Packages II

Here are some more examples of commonly performed operations:

    Install a specific software group from a repository, resolving and installing any necessary dependencies for each package in the group:

    $ sudo yum groupinstall group-name

    or

    $ sudo yum install @group-name 
    Remove packages from the system:

    $ sudo yum remove package1 [package2]

    One must be careful with package removal, as yum will not only remove requested packages, but all packages that depend on them! This may not be what you want, so never run yum remove with the -y option, which assumes automatic confirmation of removal.
    Update a package from a repository:

    $ sudo yum update [package]

    If no package name is given, all packages are updated.



8.9.c. Installing/Removing/Upgrading Packages III

During installation (or update), if a package has a configuration file which is updated, it will rename the old configuration file with an .rpmsave extension. If the old configuration file will still work with the new software, it will name the new configuration file with an .rpmnew extension. You can search for these filename extensions (almost always in the /etc subdirectory tree) to see if you need to do any reconciliation, by doing:

$ sudo find /etc -name "*.rpm*"

This is the same behavior the more naked underlying rpm utility exhibits, but we mention it here for reference.

8.10.a. Additional Commands I

 There is no shortage of additional capabilities for yum, according to what plugins are installed. You can list them all with:

$ sudo yum list "yum-plugin*"

In particular:

    Show a list of all enabled repositories:

    $ sudo yum repolist
    Initiate an interactive shell in which to run multiple YUM commands:

    $ sudo yum shell [text-file]

    If text-file is given, yum will read and execute commands from that file instead of from the terminal.

8.11.b. Additional Commands II

Some more examples of yum commands are:

    Download packages, but do not install them; just store them under the /var/cache/yum directory, or another directory you can specify:

    $ sudo yum install --downloadonly package

    or you can type "d" instead of "y" or "n" when prompted after issuing an install command. The package(s) will be downloaded under /var/cache/yum in a location depending on the repository from which the download proceeds, unless the --downloaddir= option is used. Any other necessary packages will also be downloaded to satisfy dependencies.
    You can view the history of yum commands, and, with the correct options, even undo or redo previous commands:

    $ sudo yum history

8.11. dnf

dnf is intended to be a next generation replacement for yum. However, it has yet to be adopted by any major Enterprise distribution; Fedora is a test bed for RHEL and it is rarely used directly in Enterprise deployments.

Furthermore, you can gradually learn to use dnf on Fedora systems because it accepts the subset of yum commands that take care of the majority of day-to-day tasks, and points out at each use of yum that has a dnf equivalent.

To learn more, see https://docs.fedoraproject.org/en-US/Fedora/24/html/System_Administrators_Guide/part-Package_Management.html.

9.1. zypper - Introduction

For use on SUSE-based systems, the zypper program provides a higher level of intelligent services for using the underlying rpm program, and plays the same role as yum on Red Hat-based systems. It can automatically resolve dependencies when installing, updating and removing packages. It accesses external software repositories, synchronizing with them and retrieving and installing software as needed.

9.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain what zypper is.
    Discuss the queries zypper can be used for.
    Install, remove and ugrade packages using zypper.


9.3. What is zypper?

zypper is the command line tool for installing and managing packages in SUSE Linux and openSUSE. It is very similar to yum in its functionality and even in its basic command syntax, and also works with rpm packages.

zypper retrieves packages from repositories, installs, removes and updates while resolving any dependencies encountered. It is equivalent in practice to yum and apt-get in that it can retrieve packages from a repository and can also resolve dependencies. 

9.4. zypper Queries

Here are some examples of commonly performed operations involving querying:

    Show a list of available updates:

    $ zypper list-updates
    List available repositories:

    $ zypper repos
    Search repositories for string:

    $ zypper search <string>
    List information about package:

    $ zypper info <package>
    Search repositories to ascertain what packages provide a file:

    $ zypper search --provides <file> 

9.5.a. Installing/Removing/Upgrading I

Here are some examples of commonly performed operations:

    Install or update package(s):

    $ sudo zypper install package
    Do not ask for confirmation when installing or upgrading:

    $ sudo zypper --non-interactive install <package>

    This is useful for scripts and is equivalent to running yum -y.


9.5.a. Installing/Removing/Upgrading I

Here are some more examples of commonly performed operations:

    Update all installed packages:

    $ sudo zypper update

    Giving package names as an argument will update only those packages and any required dependencies. Do this without asking for confirmation:

    $ sudo zypper --non-interactive update
    Remove a package from the system:

    $ sudo zypper remove <package>

    Like with yum, one has to be careful with the removal command, as any package that needs the package being removed would be removed as well.


9.6. Additional zypper Commands

Sometimes, a number of zypper commands must be run in a sequence. To avoid re-reading all the databases for each command, you can run zypper in shell mode as in:

$ sudo zypper shell
> install bash
...
> exit

Because zypper supports the readline library, you can use all the same command line editing functions in the zypper shell available in the bash shell.

To add a new repository:

$ sudo zypper addrepo URI alias

which is located at the supplied URI and will use the supplied alias.

To remove a repository from the list:

$ sudo zypper removerepo alias

using the alias of the repo you want to delete.

9.7 Using YasT Demo

Video presentation


10.1. APT - Introduction

For use on Debian-based systems, the APT (Advanced Packaging Tool) set of programs provides a higher level of intelligent services for using the underlying dpkg program, and plays the same role as yum on Red Hat-based systems. The main utilities are apt-get and apt-cache. It can automatically resolve dependencies when installing, updating and removing packages. It accesses external software repositories, synchronizing with them and retrieving and installing software as needed.

10.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain what APT is.
    Use apt-cache to perform queries.
    Install, remove, and upgrade packages using apt-get.

10.3. What is APT?

APT is not a program in itself: it stands for Advanced Packaging Tool, which includes a number of utilities, such as apt-get and apt-cache. These, of course, in turn, invoke the lower-level dpkg program.

The APT system works with Debian packages whose files have a .deb extension. There are many distributions that have descended from Debian (including Ubuntu and Linux Mint) which have adopted the Debian packaging system with no essential modification. In fact, it is not uncommon to use a repository on more than one Debian-based Linux distribution.

Once again, we are going to ignore graphical interfaces (on your computer) such as synaptic or the Ubuntu Software Center, or other older frontends to APT, such as aptitude.

However, excellent Internet-based resources can be found at http://packages.debian.org and http://packages.ubuntu.com. These databases let you search for packages, examine their contents, and download.

10.4. apt-get

apt-get is the main APT command line tool for package management. It can be used to install, manage and upgrade individual packages or the entire system. It can even upgrade the distribution to a completely new release, which can be a difficult task.

There are even (imperfect) extensions that let apt-get work with rpm files. 

Like yum and zypper it works with multiple remote repositories.

10.5. Queries Using apt-cache

Queries are done using the apt-cache utility:

    Search the repository for a package named apache2:

    $ apt-cache search apache2
    Display basic information about the apache2 package:

    $ apt-cache show apache2
    Display more detailed information about the apache2 package:

    $ apt-cache showpkg apache2
    List all dependent packages for apache2:

    $ apt-cache depends apache2
    Search the repository for a file named apache2.conf:

    $ apt-file search apache2.conf
    List all files in the apache2 package:

    $ apt-file list apache2

    Find package that provides the file specified as argument
    $ apt-file find <file-name>

10.6.a. Installing/Removing/Upgrading I

The apt-get program is the work horse of installing, removing, and upgrading packages:

    Synchronize the package index files with their repository sources. The indexes of available packages are fetched from the location(s) specified in /etc/apt/sources.list:

    $ sudo apt-get update
    Install new packages or update an already installed package:

    $ sudo apt-get install [package]
    Remove a package from the system without removing its configuration files:

    $ sudo apt-get remove [package]
    Remove a package from the system, as well as its configuration files:

    $ sudo apt-get --purge remove [package]
    Apply all available updates to packages already installed:

    $ sudo apt-get upgrade

10.6.b. Installing/Removing/Upgrading II

The apt-get program is the work horse of installing, removing and upgrading packages (continued):

    Do a smart upgrade that will do a more thorough dependency resolution and remove some obsolete packages and install new dependencies:

    $ sudo apt-get dist-upgrade

    This will not update to a whole new version of the Linux distribution as is commonly misunderstood.
    Note that you must update before you upgrade, unlike with yum, where the update argument does both steps, it updates the repositories and then upgrades the packages. This can be confusing to habitual yum users on Debian-based systems.
    Get rid of any packages not needed anymore, such as older Linux kernel versions:

    $ sudo apt-get autoremove
    Clean out cache files and any archived package files that have been installed:

    $ sudo apt-get clean

    This can save a lot of space.

11.1. System Monitoring - Introduction

11.2. Learning Objectives

By the end of this chapter, you should be able to:

    Recognize and use available system monitoring tools.
    Use the /proc and /sys pseudo-filesystems.
    Use sar to gather system activity and performance data and create reports that are readable by humans.

11.3.a. Available Monitoring Tools I

Linux distributions come with many standard performance and profiling tools already installed. Many of them are familiar from other UNIX-like operating systems, while some were developed specifically for Linux.

Most of these tools make use of mounted pseudo-filesystems, especially /proc and /sys, both of which we have already discussed when examining filesystems and kernel configuration. We will look at them both.

While there are also a number of graphical system monitors that hide many of the details, we will consider only the command line tools in this course.

Before considering some of the main utilities in some detail, you can see a summary on the next few pages, broken down by type; please note that some of the utilities have overlapping domains of coverage. 

11.3.b. Available Monitoring Tools II

                Process and Load Monitoring Utilities

 
Utility	        Purpose	                                                    Package
=======================================================================================
top	        Process activity, dynamically updated	                        procps
uptime	    How long the system is running and the average load	            procps
ps	        Detailed information about processes	                        procps
pstree	    A tree of processes and their connections  	                    psmisc (or pstree)
mpstat	    Multiple processor usage	                                    sysstat
iostat	    CPU utilization and I/O statistics	                            sysstat
sar	        Display and collect information about system activity	        sysstat
numastat	Information about NUMA (Non-Uniform Memory Architecture)	    numactl
strace	    Information about all system calls a process makes 	            strace



 11.3.c. Available Monitoring Tools III

Below you will find a summary of the main memory and I/O monitoring utility tools:

 

 

Memory Monitoring Utilities 

 
Utility    	Purpose 	                                                            Package 
=================================================================================================
free	    Brief summary of memory usage                                           procps 
vmstat 	    Detailed virtual memory statistics and block I/O, dynamically updated 	procps 
pmap 	    Process memory map 	                                                    procps 

 

 

I/O Monitoring Utilities

 
Utility	        Purpose	                                                                    Package
=====================================================================================================
iostat	        CPU utilization and I/O statistics	                                        sysstat
sar	            Display and collect information about system activity	                    sysstat
vmstat	        Detailed virtual memory statistics and block I/O, dynamically updated 	    procps

11.3.d. Available Monitoring Tools IV

Below you will find a summary of the main network monitoring utility tools

 

 

Network Monitoring Utilities

 
Utility	            Purpose	                                            Package
======================================================================================
netstat	            Detailed networking statistics	                    netstat
iptraf	            Gather information on network interfaces	        iptraf
tcpdump	            Detailed analysis of network packets and traffic	tcpdump
wireshark	        Detailed network traffic analysis	                wireshark

11.4. The /proc and /sys Psuedo-filesystems

The /proc and /sys pseudo-filesystems contain a lot of information about the system. Furthermore, many of the entries in these directory trees are writable and can be used to change system behavior; in most cases, this requires a root user.

These are pseudo-filesystems because they exist totally in memory; if you look at the disk partition when the system is not running, there will be only an empty directory which is used as a mount point.

Furthermore, the information displayed is gathered only when it is looked at; there is no constant or periodic polling to update entries. 

11.5. /proc Basics

The /proc pseudo-filesystem has a long history; it has roots in other UNIX operating system variants, and, originally, was developed to display information about processes on the system, each of which has its own subdirectory in /proc with all important process characteristics available.

Over time, it grew to contain a lot of information about system properties, such as interrupts, memory, networking, etc, in a somewhat anarchistic way. It is still extensively used, and we will often refer to it.

11.7.a. /proc/sys I

Most of the tunable system parameters can be found in the subdirectory tree rooted at /proc/sys:


total 0
dr-xr-xr-x 1 root root 0 Apr 24 09:14 abi/
dr-xr-xr-x 1 root root 0 Apr 24 09:14 debug/
dr-xr-xr-x 1 root root 0 Apr 24 09:14 dev/
dr-xr-xr-x 1 root root 0 Apr 24 08:25 fs/
dr-xr-xr-x 1 root root 0 Apr 24 08:25 kernel/
dr-xr-xr-x 1 root root 0 Apr 24 09:14 net/
dr-xr-xr-x 1 root root 0 Apr 24 09:14 sunrpc/
dr-xr-xr-x 1 root root 0 Apr 24 08:25 vm/

11.7.b. /proc/sys II

Each of these subdirectories contains information, as well as knobs that can be tuned (with care):

    abi/
    Contains files with application binary information; rarely used.
    debug/
    Debugging parameters; for now, just some control of exception reporting.
    dev/
    Device parameters, including subdirectories for cdrom, scsi, raid, and parport.
    fs/
    Filesystem parameters, including quota, file handles used, and maximums, inode and directory information, etc.
    kernel/
    Kernel parameters. There are many important entries here.
    net/
    Network parameters. There are subdirectories for ipv4, netfilter, etc.
    vm/
    Virtual memory parameters. There are many important entries here.

11.7.c. /proc/sys III

Viewing and changing the parameters can be done with simple commands. For example, the maximum number of threads allowed on the system can be seen by looking at:

$ ls -l /proc/sys/kernel/threads-max
$ cat /proc/sys/kernel/threads-max
129498

We then can modify the value and verify the change was effected:

$ sudo bash -c 'echo 100000 > /proc/sys/kernel/threads-max'
$ cat /proc/sys/kernel/threads-max
100000

Remember from our discussion of sysctl the same effect is accomplished by:

$ sudo sysctl kernel.threads-max=100000

Viewing the value can be done as a normal user, while changing it requires superuser privilege.

11.8. /sys Basics

The /sys pseudo-filesystem is an integral part of what is termed the Unified Device Model. Conceptually, it is based on a device tree and one can walk through it and see the buses, devices, etc. It also now contains information which may or may not be strictly related to devices, such as kernel modules.

It has a more tightly defined structure than does /proc. Most entries contain only one line of text, although there are exceptions, unlike its antecedent, which has many multi-line entries whose exact contents have been known to change between kernel versions. Thus, the interface is hopefully more stable.

There are system properties which have display entries in both /proc and /sys; for compatibility with widely used system utilities, the older forms are only gradually being whittled down. 

11.9.a. A Survey of /sys I

Support for the sysfs virtual filesystem is built into all modern kernels, and it should be mounted under /sys. However, the unified device model does not require mounting sysfs in order to function.

Let's take a look at what can be found using the 3.18 kernel; we warn you that the exact layout of this filesystem has a tendency to mutate. Doing a top level directory command yields:

$ ls -F /sys
block/ bus/ class/ dev/ devices/ firmware/ fs/ kernel/ module/ power/

which displays the basic device hierarchy. The device model sysfs implementation also includes information not strictly related to hardware.

11.9.b. A Survey of /sys II

Network devices can be examined with:

$ ls -lF /sys/class/net

11.10.a. sar I

sar stands for the Systems Activity Reporter. It is an all-purpose tool for gathering system activity and performance data and creating reports that are readable by humans.

On Linux systems, the backend to sar is sadc (system activity data collector), which actually accumulates the statistics. It stores information in the /var/log/sa directory, with a daily frequency by default, but which can be adjusted. Data collection can be started from the command line, and regular periodic collection is usually started as a cron job stored in /etc/cron.d/sysstat.

sar then reads in this data (either from the default locations or by use of a file specified with the -f option), and then produces a report.

sar is invoked via:

$ sar [ options ] [ interval ] [ count ]

where the report is repeated after interval seconds a total of count times (which defaults to 1). With no options, it gives a report on CPU usage.


11.10.b. sar II

Here is a list of the major sar options, or modes, each one of which has its own sub-options:

 

                    sar Options
 Option   	    Meaning
==========================================================================
-A	            Almost all information
-b	            I/O and transfer rate statistics (similar to iostat)
-B	            Paging statistics including page faults
-x	            Block device activity (similar to iostat -x)
-n	            Network statistics
-P	            Per CPU statistics (as in sar -P ALL 3)
-q	            Queue lengths (run queue, processes and threads)
-r	            Swap and memory utilization statistics
-R	            Memory statistics
-u	            CPU utilization (default)
-v	            Statistics about inodes and files and file handles
-w	            Context switching statistics
-W	            Swapping statistics, pages in and out per second


12.1. Process Monitoring - Introduction

Keeping track of running (and sleeping) processes is an essential system administration task. The ps program has been a main tool for doing so in UNIX-based operating systems for decades.

However, because the utility has a long and complicated history of being used differently in more than one operating system variety, it has a large assortment of options that can be applied with often confusing combinations. Another trusty tool is provided by top, which interactively monitors the system's state.

12.2. Learning Objectives

 By the end of this chapter, you should be able to:

    Use ps to view characteristics and statistics associated with processes.
    Identify different ps output fields and customize the ps output.
    Use pstree  to get a visual description of the process ancestry and multi-threaded applications.
    Use top to view system loads interactively.

12.3. MOnitoring Tools

In this section, we will concentrate on process monitoring. In order to do this, Linux administrators make use of many utilities, such as ps, pstree and top, all of which have long histories in UNIX-like operating systems.

Once again, let us review the list of some of the main tools for process monitoring:

 

Process and Load Monitoring Utilities

 
Utility	            Purpose	                                                    Packag
===============================================================================================
top	                Process activity, dynamically updated	                    procps
uptime	            How long the system is running and the average load	        procps
ps	                Detailed information about processes	                    procps
pstree	            A tree of processes and their connections  	                psmisc (or pstree)
mpstat	            Multiple processor usage	                                sysstat
iostat	            CPU utilization and I/O statistics	                        sysstat
sar	                Display and collect information about system activity	    sysstat
numastat	        Information about NUMA (Non-Uniform Memory Architecture)	numactl
strace	            Information about all system calls a process makes 	        strace

12.4. Viewing Process State with ps

ps is a workhorse for displaying characteristics and statistics associated with processes, all of which are garnered from the /proc directory associated with the process.

This command utility has existed in all UNIX-like operating system variants, and that diversity is reflected in the complicated potpourri of options that the Linux version of ps accepts, which fall into three categories:

    UNIX options, which must be preceded by -, and which may be grouped.
    BSD options, which must not be preceded by -, and which may be grouped.
    GNU long options, each of which must be preceded by --.

Having all these possible options can make life rather confusing. Most system administrators tend to use one or two standard combinations for their daily use.


12.6.a. ps Output Fields I

Most of the fields in the preceding example are self-explanatory. Of the others:

    VSZ is the process' virtual memory size in KB.
    RSS is the resident set size; the non-swapped physical memory a task is using in KB.
    STAT describes the state of the process; in our example we see only S for sleeping, or R for running. The additional character in the state (where it exists) can be:
    - < for high priority (not nice)
    - N for low priority (nice)
    - L for having pages locked in memory
    - s for session leader
    - l for multi-threaded
    - + for being in the foreground process group.



You can see a typical usage with the UNIX option format in the screenshot provided. Note that it is now showing the Parent Process ID (PPID) and the niceness (NI). You may observe that many processes show PPID=2 in this example (taken from RHEL 7 and using systemd) an internal kernel process, kthreadd, which is designed to adopt children when the parent process dies. In older kernels and systems, you would see PPID=1 for sbin/init, but it is really the same thing going on.


12.7.b. UNIX Option Format for pa II

Some common selection options in the UNIX format are:

    -A or -e
    Select all processes
    -N
    Negate selection (means do the opposite)
    -C
    Select by command name
    -G
    Select by real group ID (also supports names)
    -U 
    Select by real user ID (also supports names).

12.8. Customizing the ps Output

If you use the -o option, followed by a comma-separated list of field identifiers, you can print out a customized list of ps fields:

    pid: Process ID number
    uid: User ID number
    cmd: Command with all arguments
    cputime: Cumulative CPU time
    pmem: Ratio of the process's resident set size to the physical memory on the machine, expressed as a percentage.

You can see an example in the screenshot provided. You can consult the ps man page for many other output options.

12.9. Using pstree

pstree gives a visual description of the process ancestry and multi-threaded applications:

$ pstree -aAp 2408

bash,2408

|-emacs,24998 pmonitor.tex

|  |-{emacs},25002

|  '-{emacs},25003

|-evince,18036 LFS201-SLIDES.pdf

|  |-{evince},18040

|  |-{evince},18046

|  '-{evince},18047

Consult the man page for pstree for an explanation of many options; in the above we have chosen just to show information for pid=2408.

Note that one of its child processes (evince, pid=18036) has three children of its own. Another way to see that is:

$ ls -l /proc/18036/task 

total 0

dr-xr-xr-x 5 coop coop 0 Sep 11 07:15 18036

dr-xr-xr-x 5 coop coop 0 Sep 11 07:15 18040

dr-xr-xr-x 5 coop coop 0 Sep 11 07:15 18046

dr-xr-xr-x 5 coop coop 0 Sep 11 07:15 18047

12.10. Viewing System Loads with top

When one wants to know what the system is spending its time on, the first tool one often uses is top. The screenshot shows you what you can see when using top without arguments.

By default, top refreshes itself every 3.0 seconds.

12.11.a. top Options I

top is an ancient utility and has a ton of options, as well as interactive commands triggered when certain keys are pressed. For example, if one hits 1, each CPU is shown separately, and if one hits i only active processes are shown. You can see what doing both gives us in the screenshot.

12.11.b. top Options II

Ony has a lot of control over how processes are sorted and which fields are displayed; there are many others besides the defaults. For example, hitting h or ? gives a brief list of interactive commands and q exits. 

Furthermore, one can kill a task by hitting k, or renice it (change its priority) with r.

Doing man top will give you extensive documentation on configuration possibilities, options, and interactive possibilities.

Note that there are popular alternatives to the standard top program, some of which have more visual interfaces and/or additional information, such as htop, ntop and atop. And most Linux distributions have a graphical system monitor (such as gnome-system-monitor or ksysguard) which has a top-like display window that can be shown.

 
13.1. Memory: Monitoring Usage and Tunning - Introduction

Over time, systems have become more demanding of memory resources at the same time RAM prices have decreased and performance has improved. Yet, it is often the case that bottlenecks in overall system performance and throughput are memory-related; the CPUs and the I/O subsystem can be waiting for data to be retrieved from or written to memory. There are many tools for monitoring, debugging and tuning a system's behavior with regard to its memory.

13.2. Learning Objectives

By the end of this chapter, you should be able to:

    List the primary (inter-related) considerations and tasks involved in memory tuning.
    Know how to use entries in /proc/sys/vm, and decipher /proc/meminfo.
    Use vmstat to display information about memory, paging, I/O, processor activity, and processes' memory consumption.
    Understand how the OOM-killer decides when to take action and selects which processes should be exterminated to open up some memory.

13.3. Memory Tunning Considerations

Tuning the memory sub-system can be a complex process. First of all, one has to take note that memory usage and I/O throughput are intrinsically related, as, in most cases, most memory is being used to cache the contents of files on disk.

Thus, changing memory parameters can have a large effect on I/O performance, and changing I/O parameters can have an equally large converse effect on the virtual memory sub-system.

When tweaking parameters in /proc/sys/vm, the usual best practice is to adjust one thing at a time and look for effects. The primary (inter-related) tasks are:

    Controlling flushing parameters; i.e., how many pages are allowed to be dirty and how often they are flushed out to disk.
    Controlling swap behavior; i.e., how much pages that reflect file contents are allowed to remain in memory, as opposed to those that need to be swapped out as they have no other backing store.
    Controlling how much memory overcommission is allowed, since many programs never need the full amount of memory they request, particularly because of copy on write (COW) techniques.

Memory tuning can often be subtle, and what works in one system situation or load may be far from optimal in other circumstances.

13.4. Memory Monitoring Tools

Here is a list of some important basic tools for monitoring and tuning memory in Linux:


                    Memory Monitoring Utilities

 
Utility    	Purpose	                                                                    Package
===================================================================================================
free	    Brief summary of memory usage	                                            procps
vmstat	    Detailed virtual memory statistics and block I/O, dynamically updated     	procps 
pmap 	    Process memory map 	                                                        procps 

 13.5.a. /proc/sys/vm I

The /proc/sys/vm directory contains many tunable knobs to control the Virtual Memory system. Exactly what appears in this directory will depend somewhat on the kernel version. Almost all of the entries are writable (by root).

Remember that these values can be changed either by directly writing to the entry, or using the sysctl utility. Furthermore, by modifying /etc/sysctl.conf, values can be set at boot time.

You can find full documentation for the /proc/sys/vm directory in the kernel source (or kernel documentation package on your distribution), usually under Documentation/sysctl/vm.txt.

13.5.b. /proc/sys/vm II

/proc/sys/vm Entries

  
Entry	                    Purpose 
admin_reserve_kbytes	    Amount of free memory reserved for privileged users
block_dump            	    Enables block I/O debugging
compact_memory 	            Turns on or off memory compaction (essentially defragmentation) when configured into the kernel
dirty_background_bytes 	    Dirty memory threshold that triggers writing uncommitted pages to disk
dirty_background_ratio 	    Percentage of total pages at which kernel will start writing dirty data out to disk
dirty_bytes 	            The amount of dirty memory a process needs to initiate writing on its own
dirty_expire_centisecs 	    When dirty data is old enough to be written out in hundredths of a second)
dirty_ratio	                Percentage of pages at which a process writing will start writing out dirty data on its own
dirty_writeback_centisecs 	Interval in which periodic writeback daemons wake up to flush. If set to zero, there is no automatic periodic writeback
drop_caches 	            Echo 1 to free page cache, 2 to free dentry and inode caches, 3 to free all. Note only clean cached pages are dropped; do sync first to flush dirty pages
extfrag_threshold	        Controls when the kernel should compact memory
hugepages_treat_as_movable 	Used to toggle how huge pages are treated
hugetlb_shm_group 	        Sets a group ID that can be used for System V huge pages
laptop_mode 	            Can control a number of features to save power on laptops
legacy_va_layout 	        Use old layout (2.4 kernel) for how memory mappings are displayed
lowmen_reserve_ratio 	    Controls how much low memory is reserved for pages that can only be there; i.e., pages which can go in high memory instead will do so. Only important on 32-bit systems with high memory
max_map_count 	            Maximum number of memory mapped areas a process may have. The default is 64 K
min_free_kbytes 	        Minimum free memory that must be reserved in each zone
mmap_min_addr 	            How much address space a user process cannot memory map. Used for security purposes, to avoid bugs where accidental kernel null dereferences can overwrite the first pages used in an application
nr_hugepages 	            Minimum size of hugepage pool
nr_pdflush_hugepages 	    Maximum size of the hugepage pool = nr_hugepages *nr_overcommit_hugepages 
nr_pdflush_threads 	        Current number of pdflush threads; not writeable
oom_dump_tasks 	            If enabled, dump information produced when oom-killer cuts in
oom_kill_allocating_task	If set, the oom-killer kills the task that triggered the out of memory situation, rather than trying to select the best one
overcommit_kbytes 	        One can set either overcommit_ratio or this entry, but not both
overcommit_memory	        If 0, kernel estimates how much free memory is left when allocations are made. If 1, permits all allocations until memory actually does run out. If 2, prevents any overcommission
overcommit_ratio 	        If overcommit_memory = 2 memory commission can reach swap plus this percentage of RAM
page-cluster 	            Number of pages that can be written to swap at once, as a power of two. Default is 3 (which means 8 pages)
panic_on_oom 	            Enable system to crash on an out of memory situation
percpu_pagelist_fraction	Fraction of pages allocated for each cpu in each zone for hot-pluggable CPU machines
scan_unevictable_pages 	    If written to, system will scan and try to move pages to try and make them reclaimable
stat_interval 	            How often vm statistics are updated (default 1 second) by vmstat
swappiness	                How aggressively should the kernel swap
user_reserve_kbytes	        If overcommit_memory is set to 2 this sets how low the user can draw memory resources
vfs_cache_pressure	        How aggressively the kernel should reclaim memory used for inode and dentry cache. Default is 100; if 0 this memory is never reclaimed due to memory pressure


13.6.a. vmstat I

vmstat is a multi-purpose tool that displays information about memory, paging, I/O, processor activity and processes. It has many options. The general form of the command is: 

$ vmstat [options] [delay] [count]

If delay is given in seconds, the report is repeated at that interval count times; if count is not given, vmstat will keep reporting statistics forever, until it is killed by a signal, such as Ctl-C.

If no other arguments are given, you can see what vmstat displays, where the first line shows averages since the last reboot, while succeeding lines show activity during the specified interval.

$ vmstat 2 4

13.6.b. vmstat II

vmstat Fields 

 
Field 	            Subfield 	            Meaning 
============================================================================================
Processes	        r 	                    Number of processes waiting to be scheduled in
Processes	        b	                    Number of processes in uninterruptible sleep 
memory 	            swpd 	                Virtual memory used (KB) 
memory 	            free 	                Free (idle) memory (KB) 
memory 	            buff 	                Buffer memory (KB) 
memory 	            cache 	                Cached memory (KB) 
swap 	            si 	                    Memory swapped in (KB) 
swap 	            so 	                    Memory swapped out (KB) 
I/O 	            bi 	                    Blocks written to devices (blocks/sec) 
I/O	                bo 	                    Blocks read from devices (blocks/sec) 
system 	            in 	                    Interrupts/second 
system 	            cs 	                    Context switches/second 
CPU 	            us 	                    CPU time running user code (percentage) 
CPU 	            sy 	                    CPU time running kernel (system) code (percentage)
CPU 	            id 	                    CPU time idle (percentage)
CPU  	            wa 	                    Time waiting for I/O (percentage) 
CPU 	            st 	                    Time "stolen" from virtual machine (percentage) 

13.6.c. vmstat III

If the option -S m is given, memory statistics will be in MB instead of KB.

With the -a option, vmstat displays information about active and inactive memory, where active memory pages are those which have been recently used; they may be clean (disk contents are up to date) or dirty (need to be flushed to disk eventually). By contrast, inactive memory pages have not been recently used and are more likely to be clean and are released sooner under memory pressure:

$ vmstat -a 2 4

Memory can move back and forth between active and inactive lists, as they get newly referenced, or go a long time between uses.

13.6.e. vmstat V

To get a table of disk statistics use the -d option:


$ vmstat -d
disk- ------------reads------------ ------------writes----------- -----IO------
       total merged sectors      ms  total merged sectors      ms    cur    sec
loop0     39      0     240    2356      0      0       0       0      0      2
loop1    293      0    2628   20692      0      0       0       0      0      1
loop2     39      0     240     608      0      0       0       0      0      0
loop3     53      0    2144    1120      0      0       0       0      0      1
loop4  10817      0   23636  273344      0      0       0       0      0     11
loop5     88      0     770   20860      0      0       0       0      0      2
loop6     37      0     674    1368      0      0       0       0      0      1
loop7     54      0    2106    2888      0      0       0       0      0      2
sda    65340  13287 4657720 4544888  10025  14478  377770 1248812      0    365
sr0        0      0       0       0      0      0       0       0      0      0
sr1       17      0     112      44      0      0       0       0      0      0
sdb        0      0       0       0      0      0       0       0      0      0
loop8      5      0      16     100      0      0       0       0      0      0
loop9   1831      0    3818   49912      0      0       0       0      0      2
loop10     38      0     658     816      0      0       0       0      0      0

13.6.f. vmstat VI

vmstat Disk Fields 

 
Field        	Subfield	Meaning
=================================================================
reads	        total	    Total reads completed successfully
reads	        merged	    Grouped reads (resulting in one I/O)
reads	        ms	M       illiseconds spent reading
writes	        total	    Total writes completed successfully
writes      	merged	    Grouped writes (resulting in one I/O)
writes	        ms	        Milliseconds spent writing
I/O	            cur	        I/O in progress
I/O	            sec	        seconds spent for I/O

13.6.g. vmstat VII

If you just want to get some quick statistics on only one partition, use the -p option:


$ vmstat -p /dev/sda2 2
sda2          reads   read sectors  writes    requested writes
               65077    4635186      10521     400304
               65077    4635186      10521     400304
               65077    4635186      10522     400312
               65077    4635186      10522     400312
               65077    4635186      10522     400312
               65077    4635186      10522     400312
               65077    4635186      10529     400648
               65077    4635186      10529     400648
               65077    4635186      10529     400648

13.7.b. /proc/meminfo II

It is worthwhile to go through this listing and understand most of the entries:


/proc/meminfo Entries

 
Entry                    	Meaning
============================================================================================
MemTotal	                Total usable RAM (physical minus some kernel reserved memory)
MemFree	                    Free memory in both low and high zones
Buffers	                    Memory used for temporary block I/O storage
Cached	                    Page cache memory, mostly for file I/O
SwapCached	                Memory that was swapped back in but is still in the swap file
Active	                    Recently used memory, not to be claimed first
Inactive	                Memory not recently used, more eligible for reclamation
Active(anon)	            Active memory for anonymous pages
Inactive(anon)	            Inactive memory for anonymous pages
Active(file)	            Active memory for file-backed pages
Inactive(file)	            Inactive memory for file-backed pages
Unevictable	                Pages which can not be swapped out of memory or released
Mlocked	                    Pages which are locked in memory
SwapTotal	                Total swap space available
SwapFree	                Swap space not being used
Dirty	                    Memory which needs to be written back to disk
Writeback	                Memory actively being written back to disk
AnonPages	                Non-file back pages in cache
Mapped	                    Memory mapped pages, such as libraries
Shmem	                    Pages used for shared memory
Slab	                    Memory used in slabs
SReclaimable	            Cached memory in slabs that can be reclaimed
SUnreclaim	                Memory in slabs that can't be reclaimed
KernelStack	                Memory used in kernel stack
PageTables	                Memory being used by page table structures
Bounce	                    Memory used for block device bounce buffers
WritebackTmp	            Memory used by FUSE filesystems for writeback buffers
CommitLimit	                Total memory available to be used, including overcommission
Committed_AS	            Total memory presently allocated, whether or not it is used
VmallocTotal	            Total memory available in kernel for vmalloc allocations
VmallocUsed	                Memory actually used by vmalloc allocations
VmallocChunk	            Largest possible contiguous vmalloc area
HugePages_Total	            Total size of the huge page pool
HugePages_Free	            Huge pages that are not yet allocated
HugePages_Rsvd	            Huge pages that have been reserved, but not yet used
HugePages_Surp	            Huge pages that are surplus, used for overcommission
Hugepagesize	            Size of a huge page

 

 Note that the exact entries you may see will depend on the exact kernel version you are running.


13.8.a. OOM Killer I

The simplest way to deal with memory pressure would be to permit memory allocations to succeed as long as free memory is available and then fail when all memory is exhausted.

The second simplest way is to use swap space on disk to push some of the resident memory out of core; in this case, the total available memory (at least in theory) is the actual RAM plus the size of the swap space. The hard part of this is to figure out which pages of memory to swap out when pressure demands. In this approach, once the swap space itself is filled, requests for new memory must fail.

Linux, however, goes one better; it permits the system to overcommit memory, so that it can grant memory requests that exceed the size of RAM plus swap. While this might seem foolhardy, many (if not most) processes do not use all requested memory. 

An example would be a program that allocates a 1 MB buffer, and then uses only a few pages of the memory. Another example is that every time a child process is forked, it receives a copy of the entire memory space of the parent. Because Linux uses the COW (copy on write) technique, unless one of the processes modifies memory, no actual copy needs be made. However, the kernel has to assume that the copy might need to be done.

Thus, the kernel permits overcommission of memory, but only for pages dedicated to user processes; pages used within the kernel are not swappable and are always allocated at request time.

One can modify, and even turn off this overcommission by setting the value of /proc/sys/vm/overcommit_memory:

    0:  (default) Permit overcommission, but refuse obvious overcommits, and give root users somewhat more memory allocation than normal users.
    1:  All memory requests are allowed to overcommit.
    2:  Turn off overcommission. Memory requests will fail when the total memory commit reaches the size of the swap space plus a configurable percentage (50 by default) of RAM. This factor is modified changing /proc/sys/vm/overcommit_ratio.

13.8.b. OOM Killer II

If available memory is exhausted, Linux invokes the OOM-killer (Out Of Memory) to decide which process(es) should be exterminated to open up some memory.

There is no precise science for this; the algorithm must be heuristic and cannot satisfy everyone. In the minds of many developers the purpose of the OOM-killer is to permit a graceful shutdown, rather than be a part of normal operations.

An amusing take on this was given by Andries Brouwer (http://lwn.net/Articles/104185/):

"An aircraft company discovered that it was cheaper to fly its planes with lesGs fuel on board. The planes would be lighter and use less fuel and money was saved. On rare occasions however the amount of fuel was insufficient, and the plane would crash. This problem was solved by the engineers of the company by the development of a special OOF (out-of-fuel) mechanism. In emergency cases a passenger was selected and thrown out of the plane. (When necessary, the procedure was repeated.) A large body of theory was developed and many publications were devoted to the problem of properly selecting the victim to be ejected. Should the victim be chosen at random? Or should one choose the heaviest person? Or the oldest? Should passengers pay in order not to be ejected, so that the victim would be the poorest on board? And if for example the heaviest person was chosen, should there be a special exception in case that was the pilot? Should first class passengers be exempted? Now that the OOF mechanism existed, it would be activated every now and then, and eject passengers even when there was no fuel shortage. The engineers are still studying precisely how this malfunction is caused."

In order to make decisions of who gets sacrificed to keep the system alive, a value called the badness is computed (which can be read from /proc/[pid]/oom_score) for each process on the system and the order of the killing is determined by this value.

Two entries in the same directory can be used to promote or demote the likelihood of extermination. The value of oom_adj is the number of bits the points should be adjusted by. Normal users can only increase the badness; a decrease (a negative value for oom_adj) can only be specified by a superuser. The value of oom_adj_score directly adjusts the point value. Note that the use of oom_adj is deprecated.


14.1. I/O Monitoring and Tuning - Introduction

video

14.2. Learning Objectives

By the end of this chapter, you should be able to:

    Use iostat to monitor system I/O device activity.
    Use iotop to display a constantly updated table of current I/O usage.
    Use ionice to set both the I/O scheduling class and the priority for a given process.


14.3. Disk Bottlenecks

Disk performance problems can be strongly coupled to other factors, such as insufficient memory or inadequate network hardware and tuning. Disentangling can be difficult.

As a rule, a system can be considered as I/O-bound when the CPU is found sitting idle waiting for I/O to complete, or the network is waiting to clear buffers.

However, one can be misled. What appears to be insufficient memory can result from too slow I/O; if memory buffers that are being used for reading and writing fill up, it may appear that memory is the problem, when the real problem is that buffers are not filling up or emptying out fast enough. Similarly, network transfers may be waiting for I/O to complete and cause network throughput to suffer.

Both real-time monitoring and tracing are necessary tools for locating and mitigating disk bottlenecks. However, rare or non-repeating problems can make this difficult to accomplish.

There are many relevant variables and I/O tuning is complex. We will also consider I/O scheduling later.

14.4.a. iostat I

iostat is the basic workhorse utility for monitoring I/O device activity on the system. It can generate reports with a lot of information, with the precise content controlled by options.

You can see in this screenshot what simply typing iostat gives us.

$ iostat

Linux 4.4.0-121-generic (george-HP-Pavilion-17-Notebook-PC) 	24/04/2018 	_x86_64_	(4 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           4.85    0.03    2.79   10.38    0.00   81.95

Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
loop0             0.01         0.02         0.00        120          0
loop1             0.06         0.25         0.00       1314          0
loop2             0.01         0.02         0.00        120          0
loop3             0.01         0.21         0.00       1072          0
loop4             2.48         2.67         0.00      13879          0
loop5             0.02         0.07         0.00        385          0
loop6             0.01         0.06         0.00        337          0
loop7             0.01         0.20         0.00       1053          0
sda              39.82       722.98       508.69    3756300    2642957
scd1              0.00         0.01         0.00         56          0
loop8             0.00         0.00         0.00          8          0
loop9             0.47         0.49         0.00       2539          0
loop10            0.01         0.06         0.00        329          0

14.4.b. iostat II

After a brief summary of CPU utilization, I/O statistics are given: tps (I/O transactions per second; logical requests can be merged into one actual request), blocks read and written per unit time, where the blocks are generally sectors of 512 bytes; and the total blocks read and written.

Information is broken out by disk partition (and if LVM is being used also by dm (device mapper) logical partitions).


14.5.a. iostat Options I

A somewhat different display is generated by giving the -k option, which shows results in KB instead of blocks. You can also use -m to get results in MB.

14.5.b. iostat Options II

Another useful option is -N to show by device name (or -d for a somewhat different format), as in the screenshot provided.

14.6.a. iostat Extended Oprions I

A much more detailed report can be obtained by using the -x option (for extended).

14.6.b. iostat Extended Options II

The fields you saw in the screenshot on the previous page have the following meanings:

 

Extended iostat Fields 
Field    	Meaning 
Device 	    Device or partition name 
rrqm/s 	    Number of read requests merged per second, queued to device 
wrqm/s	    Number of write requests merged per second, queued to device 
r/s 	    Number of read requests per second, issued to the device
w/s 	    Number of write requests per second, issued to the device 
rkB/s 	    KB read from the device per second 
wkB/s 	    KB written to the device per second 
avgrq-sz 	Average request size in 512 byte sectors per second 
avgqu-sz 	Average queue length of requests issued to the device 
await 	    Average time (in msecs) I/O requests between when a request is issued and when it is completed: queue time plus service time 
svctm 	    Average service time (in msecs) for I/O requests 
%util 	    Percentage of CPU time during the device serviced requests 

 

Note that if the utilization percentage approaches 100, the system is saturated, or I/O bound.


14.7.a. iotop I

Another very useful utility is iotop, which must be run as root. It displays a table of current I/O usage and updates periodically, like top. You can see in the screenshot what typing sudo iotop with no options gives us.

Please note that the be and rt entries in the PRIO are explained in the ionice section, and stand for best effort and real time.


14.8.a. Using ionice to Set I/O Priorities I

The ionice utility lets you set both the I/O scheduling class and priority for a given process. It takes the form:

$ ionice [-c class] [-n priority] [-p pid ] [COMMAND [ARGS] ]

If a pid is given with the -p argument results apply to the requested process, otherwise it is the process that will be started by COMMAND with possible arguments. If no arguments are given, ionice returns the scheduling class and priority of the current shell process, as in:

$ ionice

idle: prio 7

The -c parameter specifies the I/O scheduling class, which can have the following 3 values:

I/O Scheduling Classes

I/O Scheduling 
Class	            -c value	        Meaning
===================================================================================================
None or Unknown	        0	            Default value
Real Time	            1 	            Get first access to the disk, can starve other processes. The priority defines how big a time slice each process gets.
Best effort 	        2 	            All programs serviced in round-robin fashion, according to priority settings. The Default. 
Idle	                3 	            No access to disk I/O unless no other program has asked for it for a defined period. 


14.8.b. Using ionice to Set I/O Priorities II

The Best Effort and Real Time classes take the -n argument which gives the priority, which can range from 0 to 7, with 0 being the highest priority. An example:

$ ionice -c 2 -n 3 -p 30078

Note: ionice works only when using the CFQ I/O Scheduler, which we will talk about in the next section.

15.1. I/O Scheduling - Introduction

System performance often depends very heavily on optimizing the I/O scheduling strategy. Many (often competing) factors influence behavior; these include minimizing hardware access times, avoiding wear and tear on storage media, ensuring data integrity, granting timely access to applications that need to do I/O, and being able to prioritize important tasks. Linux offers a variety of I/O Schedulers to choose from, each of which has tunable parameters, as well as a number of utilities for reporting on and analyzing I/O performance.

15.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain the importance of I/O scheduling and describe the conflicting requirements that need to be satisfied.
    Delineate and contrast the options available under Linux.  
    Understand how the CFQ (Completely Fair Queue) and Deadline algorithms work.

15.3. I/O Scheduling

The I/O scheduler provides the interface between the generic block layer and low-level physical device drivers. Both the VM (Virtual Memory) and VFS (Virtual File System) layers submit I/O requests to block devices; it is the job of the I/O scheduling layer to prioritize and order these requests before they are given to the block devices.

Any I/O scheduling algorithm has to satisfy certain (sometimes conflicting) requirements:

    Hardware access times should be minimized; i.e., requests should be ordered according to physical location on the disk. This leads to an elevator scheme where requests are inserted in the pending queue in physical order.
    Requests should be merged to the extent possible to get as big a contiguous region as possible, which also minimizes disk access time.
    Requests should be satisfied with as low a latency as is feasible; indeed,in some cases, determinism (in the sense of deadlines) may be important.
    Write operations can usually wait to migrate from caches to disk without stalling processes. Read operations, however, almost always require a process to wait for completion before proceeding further. Favoring reads over writes leads to better parallelism and system responsiveness.
    Processes should share the I/O bandwidth in a fair, or at least consciously prioritized fashion; even it means some overall performance slowdown of the I/O layer, process throughput should not suffer inordinately.

15.4. I/O Scheduler Choices

Since these demands can be conflicting, different I/O schedulers may be appropriate for different workloads; e.g., a large database server vs. a desktop system. Furthermore, different hardware may mandate different strategy. In order to provide flexibility, the Linux kernel has an object oriented scheme, in which pointers to the various needed functions are supplied in a data structure, the particular one of which can be selected at boot on the kernel command line, as in:

linux ...  elevator=[cfq|deadline|noop]

At least one of the I/O scheduling algorithms must be compiled into the kernel. The current choices are:

    Completely Fair Queueing (CFQ)
    Deadline Scheduling
    noop (A simple scheme).

The default choice is a compile configuration option; modern distributions choose either CFQ or Deadline.

15.5. I/O Scheduling and SSD Devices

The gradual introduction of SSD (Solid State Drive) devices, which use flash memory to emulate hard disks, has important implications for I/O scheduling. 

Such devices do not require an elevator scheme and benefit from wear leveling to spread I/O over the devices which have limited write/erase cycles.

One can examine /sys/block/<device>/queue/rotational to see whether or not the device is an SSD or not, as in:

$ cat /sys/block/sda/queue/rotational

1

$ cat /sys/block/sdb/queue/rotational

0


15.6.a. Tunables and Switching the I/O Scheduler at runtime I

Each of the I/O schedulers exposes parameters which can be used to tune behavior at run time. The parameters are accessed through the pseudo-filesystem mounted at /sys.

In addition, it is possible to use different I/O schedulers for different devices. The choice can be made easily through the command line. For example:

$ cat /sys/block/sda/queue/scheduler

noop deadline [cfq]

$ echo noop > /sys/block/sda/queue/scheduler

$ cat /sys/block/sda/queue/scheduler

[noop] deadline cfq



15.6.b. Tunables and Switching the I/O Scheduler at runtime II


The actual tunables vary according to the particular I/O scheduler, and can be found under:

/sys/block/<device>/queue/iosched

You can see the actual tunables for a disk using CFQ in this screenshot.

We will discuss some of these parameters shortly.


15.8. CFQ (Completely Fair Queue) Scheduler

The CFQ (Completely Fair Queue) method has the goal of equal spreading of I/O bandwidth among all processes submitting requests.

Theoretically, each process has its own I/O queue, which works together with a dispatch queue which receives the actual requests on the way to the device. In actual practice, the number of queues is fixed (at 64) and a hash process based on the process ID is used to select a queue when a request is submitted.

Dequeuing of requests is done round robin style on all the queues, each one of which works in FIFO (First In First Out) order. Thus, the work is spread out. To avoid excessive seeking operations, an entire round is selected, and then sorted into the dispatch queue before actual I/O requests are issued to the device. 


15.9. CFQ Tunables

In the examples below, the parameter HZ is a kernel-configured quantity, that corresponds to the number of jiffies per second, which the kernel uses as a coarse measure of time. Without getting into detail, let us just point out that time units HZ/2 is 0.5 seconds and 5 * HZ is 5 seconds etc.

    quantum
    Maximum queue length in one round of service.  (Default = 4);
    queued
    Minimum request allocation per queue.  (Default = 8);
    fifo_expire_sync
    FIFO timeout for sync requests.  (Default = HZ/2);
    fifo_expire_async
    FIFO timeout for async requests.  (Default = 5  *  HZ);
    fifo_batch_expire
    Rate at which the FIFO's expire.  (Default = HZ/8);
    back_seek_max
    Maximum backwards seek, in KB. (Default = 16K);
    back_seek_penalty
    Penalty for a backwards seek.  (Default = 2).

15.10. Deadline Scheduler

The Deadline I/O scheduler aggressively reorders requests with the simultaneous goals of improving overall performance and preventing large latencies for individual requests; i.e., limiting starvation.

With each and every request, the kernel associates a deadline. Read requests get higher priority than write requests.

Five separate I/O queues are maintained:

    Two sorted lists are maintained, one for reading and one for writing, and arranged by starting block.\u200b
    Two FIFO lists are maintained, again one for reading and one for writing. These lists are sorted by submission time.\u200b
    A fifth queue contains the requests that are to be shoveled to the device driver itself. This is called the dispatch queue.

Exactly how the requests are peeled off the first four queues and placed on the fifth (dispatch queue) is where the art of the algorithm is.

15.11. Deadline Tunables

Here are the available tunables for the Deadline scheduler:

    read_expire:
    How long (in milliseconds) a read request is guaranteed to occur within. (Default = HZ/2 = 500 ). 
    write_expire:
    How long (in milliseconds) a write request is guaranteed to occur within. (Default = 5 * HZ = 5000).
    writes_starved:
    How many requests we should give preference to reads over writes. (Default = 2 ).
    fifo_batch:
    How many requests should be moved from the sorted scheduler list to the dispatch queue, when the deadlines have expired. (Default = 16).
    front_merges:
    Back merges are more common than front merges as a contiguous request usually continues to the next block. Setting this parameter to 0 disables front merges and can give a boost if you know they are unlikely to be needed. (Default = 1 ).

16.1. Linux Filesystems and VFS - Introduction

16.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain the basic filesystem organization.
    Understand the role of the VFS.
    Know what filesystems are available in Linux and which ones can be used on your actual system.
    Grasp why journalling filesystems represent significant advances.
    Discuss the use of special filesystems in Linux.

16.3. Filesystem Basics

Application programs read and write files, rather than dealing with physical locations on the actual hardware on which files are stored.

Files and their names are an abstraction camouflaging the physical I/O layer. Directly writing to disk in a raw fashion (ignoring the filesystem layer) is very dangerous and is only done by low-level operating system software, never by a user application.

Local filesystems generally reside within a disk partition which can be a physical partition on a disk, or a logical partition controlled by a Logical Volume Manager (LVM). Filesystems can also be of a network nature and their true physical embodiment completely hidden to the local system across the network. 


16.4. Filesystem Tree Organization

All Linux systems use an inverted tree hierarchy branching off the root (/) directory. While the entire tree may be contained in one local filesystem in one partition, usually there are multiple partitions (or network filesystems) joined together at mount points. These can also include removable media, such as USB drives, optical drives, etc.

In addition, certain virtual pseudo filesystems (useful abstractions which exist only in memory) will be mounted within the tree; these include /proc, /sys and /dev and perhaps /tmp and /run as well.

Each of the elements mounted within the tree may in fact have its own filesystem variety. But, to the applications and operating system, it all appears in one unified tree structure. 


16.5. Virtual File System (VFS)

Linux implements a Virtual File System (VFS), as do all modern operating systems. When an application needs to access a file, it interacts with the VFS abstraction layer, which then translates all the I/O system calls (reading, writing etc.) into specific code relevant to the particular actual filesystem.

Thus, neither the specific actual filesystem or physical media and hardware on which it resides need be considered by applications. Furthermore, network filesystems (such as NFS) can be handled transparently.

This permits Linux to work with more filesystem varieties than any other operating system. This democratic attribute has been a large factor in its success.

Most filesystems have full read and write access, while a few have only read access and perhaps experimental write access. Some filesystem types, especially non-UNIX based ones, may require more manipulation in order to be represented in the VFS.

Variants such as vfat do not have distinct read/write/execute permissions for the owner/group/world fields; the VFS has to make an assumption about how to specify distinct permissions for the three types of user, and such behavior can be influenced by mounting operations.There are non-kernel filesystem implementations, such as the read/write ntfs-3g
(http://www.tuxera.com/community/ntfs-3g-download) which are reliable but have weaker performance than in-kernel filesystems.

16.6. Available FIlesystems

The most commonly used filesystems include ext4, xfs, btrfs, squashfs, nfs, and vfat.

The table below shows you a partial list of the currently supported filesystems.

 

 Available Filesystems

 
Name	                    Description
===================================================================================
ext4, ext3, ext2	        Native Linux filesystem
proc	                    Used for /proc/
vfat	                    Windows VFAT (includes FAT32, FAT, etc.)
ntfs	                    Windows NT NTFS (read-only)
udf	                        CD R/W, DVD
hfs+        	            Apple MacIntosh Extended HFS
jffs, jffs2	                Journalling Flash Filesystem
iso9660	                    cdrom etc., including Joliet extensions
tmpfs   	                Ram disk that is swappable
gfs2	                    Clustering filesystem from Red Hat
nfs	                        Network Filesystem (through version 4)
smb	                        Samba networking
ncp	                        Novell Netware FS using NCP Protocol
coda	                    Experimental distributed filesystem
afs	                        Andrew distributed filesystem, from Carnegie Mellon
ocfs2	                    Extent-based, disk cluster filesystem from Oracle 

16.8. Journalling FIlesystems

A number of newer, high performance filesystems include full journalling capability.

Journalling filesystems recover from system crashes or ungraceful shutdowns with little or no corruption, and do so very rapidly. While this comes at the price of having some more operations to do, additional enhancements can more than offset the price.

In a journalling filesystem, operations are grouped into transactions. A transaction must be completed without error, atomically; otherwise, the filesystem is not changed. A log file is maintained of transactions. When an error occurs, usually only the last transaction needs to be examined.

The following journalling filesystems are freely available under Linux:

    ext3 was an extension of the earlier non-journalling ext2 filesystem
    ext4 is a vastly enhanced outgrowth of ext3. Features include extents, 48-bit block numbers, and up to 16TB size. Most Linux distributions have used ext4 as the default filesystem for quite a few years
    reiserfs was the first journalling implementation used in Linux, but lost its leadership and further development was abandoned
    JFS was originally a product of IBM and was ported from IBM's AIX operating system
    XFS was originally a product of SGI, and was ported from SGI's IRIX operating systems. RHEL 7 has adopted XFS as its default filesystem
    btrfs is the newest of the journalling filesystems and is still under rapid development.

16.9. Current FIlesystem Types

You can see a list of the filesystem types currently registered and understood by the currently running Linux kernel by doing: 

$ cat /proc/filesystems

Note that additional filesystem types may have their code loaded only when the system tries to access a partition that uses them.

16.10. Special FIlesystems'

Linux widely employs the use of special filesystems for certain tasks. These are particularly useful for accessing various kernel data structures and tuning kernel behavior, or for implementing particular functions. Note that some of these special filesystems have no mount point; this means user applications don't interact with them, but the kernel uses them, taking advantage of VFS layers and code.

 

Special Filesystems

 

Filesystem
Mount               Point        	                    Purpose
=============================================================================================
rootfs	            None	                            During kernel load, provides an empty root directory
hugetlbfs	        Anywhere	                        Provides extended page access (2 or 4 MB on X86)
bdev	            None	                            Used for block devices
proc	            /proc	                            Pseudo filesystem access to many kernel structures and subsystems
sockfs	            None	                            Used by BSD Sockets
tmpfs	            Anywhere	                        RAM disk with swapping, re-sizing
shm	                None	                            Used by System V IPC Shared Memory
pipefs	            None	                            Used for pipes
binfmt_misc	        Anywhere	                        Used by various executable formats
devpts	            /dev/pts	                        Used by Unix98 pseudo-terminals
usbfs	            /proc/bus/usb	                    Used by USB sub-system for dynamical devices
sysfs	            /sys (or elsewhere)	                Used as a device tree
debugfs	            /sys/kernel/debug (or elsewhere)	Used for simple debugging file access

17.1. Disk Partitioning - Introduction

video

17.2. Learning Objectives

By the end of this chapter, you should be able to:

    Describe and contrast the most common types of hard disks and data buses.
    Explain disk geometry and other partitioning concepts.
    Understand how disk devices are named and how to identify their associated device nodes.
    Distinguish among and select different partitioning strategies.
    Use utilities such as blkid and fdisk.
    Back up and restore partition tables.

17.3.a. Common Disk Types I

There are a number of different hard disk types, each of which is characterized by the type of data bus they are attached to, and other factors, such as speed, capacity, how well multiple drives work simultaneously, etc.:

    SATA (Serial Advanced Technology  Attachment)
    These were designed to replace Parallel ATA (PATA), as IDE came to be called. They had faster data transfer, smaller cables and were seen by the operating system as SCSI devices, simplifying the writing of device drivers etc., even though the hardware is not real SCSI.
    Compared to PATA, SATA offers a smaller cable size (7 pins), native hot swapping, and faster and more efficient data transfer. The newest drives can handle 16 GB/s, but 3 GB/s and 6 GB/s are more common in consumer grade devices.
    SCSI (Small Computer Systems Interface)
    These have been the mainstay of Enterprise servers for decades. While they may have lower capacity than that of SATA drives, they tend to be much faster and work in parallel much better, such as is needed for RAID configurations. There are numerous SCSI versions, such as Fast, Wide, Ultra and UltraWide just to make things confusing, and there are many different device drivers depending on the hardware, unlike for SATA, where standardized drivers can fit a large variety of hardware. 
    SCSI disks range from narrow (8 bit bus) to wide (16 bit bus) with a transfer rate of from about 5 MB per second (narrow, standard SCSI) to about 160 MB per second (Ultra-Wide SCSI-3). Most PCs use single-ended or differential SCSI drives. Unfortunately, the two types are not compatible with each other. Fortunately, the two types of devices may coexist on the same controller. Single-ended device controllers may host up to 7 devices and use a maximum cable length of about 6 meters. Differential controllers may host up to 15 devices and have a maximum cable length of about 12 meters.

17.3.b. Common DIsk Types II

Other types of hard disk, besides the ones just mentioned, are:

    SAS
    Serial Attached SCSI is a newer point-to-point serial protocol replacing the earlier Parallel SCSI interface. Data transfer rates are similar to SATA, but overall performance is better.
    USB
    Universal Serial Bus devices include pen drives and external USB drives. The operating system sees them as SCSI devices.
    SSD
    Solid State Drives have come down in price, have no moving parts, use less power than drives with rotational media, and have faster transfer speeds. Internal SSDs are even installed with the same form factor and in the same enclosures as conventional drives. SSDs still cost quite a bit more, but price is decreasing. It is common to have both SSDs and rotational drives in the same machines, with frequently accessed and performance critical data transfers taking place on the SSDs.
    IDE and EIDE (Integrated Drive Electronics, and Enhanced IDE) 
    These were the standard in consumer laptops and desktops for years. However, they are small and slow when compared to more modern hardware and they have therefore become obsolete; controllers can no longer be found in current machines.


17.4.a. Disk Geometry I

Disk Geometry is a concept with a long history for rotational media; one talks of heads, cylinders, tracks and sectors. The below screenshot shows how to view the geometry with fdisk, which we will explore shortly.


17.4.b. DIsk Geomatry II

Rotational disks are composed of one or more platters, each of which is read by one more heads. The heads read a circular track off a platter as the disk spins.

These circular tracks are divided into data blocks called sectors, typically 512 bytes in size. A cylinder is a group which consists of the same track on all platters.

For a long time, this physical structural image has been less and less relevant as internal electronics on the drive actually obscure much of it. Furthermore, SSDs have no moving parts or anything like the above ingredients.

Currently, disks are starting to be manufactured with sectors larger than 512 bytes; 4 KB is becoming available. While larger sector sizes can lead to faster transfer speeds, operating system support is not yet mature in dealing with the larger sizes. 

17.5. Partitioning

Disks are divided into partitions. In geometrical terms, these consist of physically contiguous groups of sectors or cylinders.

A disk may have up to four primary partitions. One of the primary partitions can be designated as an extended partition, which can be subdivided further into logical partitions. 

SCSI and related standards, such as SATA, support up to 15 partitions on the disk. Partitions 1-4 are primary or extended partitions; partitions 5-15 are logical partitions. There can only be one extended partition, but it can be divided into as many logical partitions as needed, until one hits the maximum number of partitions allowed.

For example, the first SCSI or SATA drive is called sda, the second sdb and so on. On the first drive, /dev/sda1 is the first primary partition and /dev/sda2 is the second, etc.

If we created an extended partition as /dev/sda3 it could then be divided into logical partitions, with number designations like /dev/sda5, /dev/sda6 etc.

Note: Linux doesn't require partitions to begin or end on cylinder boundaries, but other operating systems might complain if they don't. For this reason, the widely deployed Linux partitioning utilities try to play nice and end on boundaries. Obviously, partitions should not overlap either. 


17.6.a. Why Partition? I

There are multiple reasons as to why it makes sense to divide your system data into multiple partitions, including:

    Separation
    It is desirable to isolate user and application data from operating system files, most of which are only read except during installation and upgrades. For example, /home, which contains user-specific files is often put on a separate partition. 
    Sharing
    Multiple operating systems or machines may use the same filesystems. For example, /home might be mounted as an NFS share across a network. Or one might have a multi-boot system, even with just different Linux versions and you might want to share something like /usr/local or /home.
    Security
    It may be desirable to impose different quotas, permissions and settings for different parts of the system.
    Size
    Some data is rather constant and some is rather variable or volatile and changes often and can grow quite a bit in size. For example, such variable data is often placed in a /var partition. If the partition gets filled up, it will be less likely to crash the system if one is not filling up a more critical space.


17.4.b. Why Partition? II

Other reasons are:

    Performance
    Data which has to be read often, especially in large chunks, will be accessed more rapidly if it is either placed in a partition on a quicker disk (such as an SSD) or in old-fashioned terms, close to the center of the disk where seek times are shorter.
    Swap
    Linux systems prefer to have swap space placed in a separate partition rather than a file on another partition. This has a secondary advantage that hibernation schemes exploit the space in the swap partition.

A common partition layout contains a /boot partition, a partition for the root filesystem /, a swap partition, and a partition for the /home directory tree.

Keep in mind that it is more difficult to re-size a partition after the fact than during install/creation time. Plan accordingly.

We will discuss filesystem layouts and partitioning impact on them in a later section.


17.7.a. Partition Table I

The disk partition table is contained within the disk's Master Boot Record (MBR), which is 512 bytes in length and whose structure is defined by an operating system-independent convention.

The partition table is 64 bytes long and is placed after the 446 byte boot record. (Note for the curious, there are 2 more bytes at the end of the MBR known as the magic number, signature word, or end of sector marker, which always have the value 0x55AA.)

The first 446 bytes are reserved for program code. They typically hold part of a boot loader program such as GRUB.

Only one partition on a given disk may be marked active. When the system boots, that partition is where the master boot loader looks for items to load. 

17.7.b. Partition Table II

Each entry in the partition table is 16 bytes long, and describes one of the four possible primary partitions. The information for each is:

    Active bit
    Beginning address in cylinder/head/sectors (CHS) format (ignored by Linux)
    Partition type code, indicating: xfs, LVM, ntfs, ext4, swap, etc.
    Ending address in CHS (also ignored by Linux)
    Start sector, counting linearly from 0
    Number of sectors in partition.

Linux only uses the last two fields for addressing using the linear block addressing (LBA) method.

17.8. Naming Disk Devices and Nodes

The Linux kernel interacts at a low level with disks through device nodes normally found in the /dev directory. Normally, device nodes are accessed only through the infrastructure of the kernel's Virtual File System; raw access through the device nodes is an extremely efficient way to destroy a filesystem. For example, you do this when formatting a partition, as in:

$ sudo mkfs.ext4 /dev/sda9

Device nodes for SCSI and SATA disks follow a simple naming convention:

    The first hard disk is /dev/sda
    The second hard disk is /dev/sdb
    Etc.

Partitions are also easily enumerated, as in:

    /dev/sdb1 is the first partition on the second disk
    /dev/sdc4 is the fourth partition on the third disk.

In the above, sd means SCSI or SATA disk. Back in the days where IDE disks could be found, they would have been /dev/hda3, /dev/hdb etc. 

Doing ls -l /dev will show you the current available disk device nodes.

17.9. More on SCSI Device Names

For SCSI devices we need to elaborate a little more on what we mean by first, second hard disk etc. These are determined by the controller number/ID number combination.

The drive designation (a, b, c, etc.) is primarily based on the ID number of the SCSI device rather than its position on the bus itself.

For example, if we had two SCSI controllers with target ID number 1 and 3 on controller 0 and target ID number 2 and 5 on controller 1 (with ID 2 as the last drive):

    ID 1 would be /dev/sda
    ID 3 would be /dev/sdb
    ID 2 (on controller 1) would be /dev/sdc
    ID 5 would be /dev/sdd

17.10.a. blkid and lsblk I

blkid is a utility to locate block devices and report on their attributes. It works with the libblkid library. It can take as an argument a particular device or list of devices. The screenshot below shows a use of blkid with arguments. 

blkid will only work on devices which contain data that is finger-printable; e.g., an empty partition will not generate a block-identifying UUID. blkid has two main forms of operation: either searching for a device with a specific NAME=value pair, or displaying NAME=value pairs for one or more devices. Without arguments, it will report on all devices. There are quite a few options designating how to specify devices and what attributes to report on.

17.10.b. blkid and lsblk II

A related utility is lsblk which presents results in a tree format


NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda      8:0    0 931.5G  0 disk 
\u251c\u2500sda1   8:1    0   512M  0 part /boot/efi
\u251c\u2500sda2   8:2    0 923.1G  0 part /
\u2514\u2500sda3   8:3    0     8G  0 part [SWAP]
sr0     11:0    1  1024M  0 rom  
loop0    7:0    0   4.9M  1 loop /snap/canonical-livepatch/38
loop1    7:1    0  93.5M  1 loop /snap/ao/9
loop2    7:2    0   4.4M  1 loop /snap/canonical-livepatch/26
loop3    7:3    0  81.7M  1 loop /snap/core/4206
loop4    7:4    0  86.6M  1 loop /snap/core/4486
loop5    7:5    0  38.9M  1 loop /snap/telegram-sergiusens/68
loop6    7:6    0  35.8M  1 loop /snap/telegram-sergiusens/53
loop7    7:7    0  86.5M  1 loop /snap/core/4407
loop8    7:8    0     4K  1 loop /snap/anbox-installer/17
loop9    7:9    0   4.9M  1 loop /snap/canonical-livepatch/39
loop10   7:10   0  38.9M  1 loop /snap/telegram-sergiusens/55
loop11   7:11   0   512M  0 loop /mnt

17.11. Sizing Up Partitions

Linux systems should use a minimum of two partitions:

    /(root): used for the entire logical filesystem
    - In practice, most installations will have more than one filesystem on more than one partition, which are joined together at mount points.
    - It is difficult with most filesystem types to resize the root partition; using LVM, which we will discuss later, can make this easier.
    While it is certainly possible to run Linux with just the root partition, most systems use more partitions to allow for easier backups, more efficient use of disk drives, and better security.
    Swap: used as an extension of physical memory; pages of memory which are not file-backed can be moved to disk until needed again.
    - The usual recommendation is swap size should be equal to physical memory in size; sometimes, twice that is recommended. However, the correct choice depends on the related issues of system use scenarios, as well as hardware capabilities. Examples of thinking on this subject can be found at https://help.ubuntu.com/  community/SwapFaq and http://www.novell.com/support/kb/doc.php?id=7010157.
    - The system may have multiple swap partitions and/or swap files.
    - On a single disk system, try to center the swap partition; on multiple disk systems, try to spread swap over disks.
    - Adding more and more swap will not necessarily help because, at a certain point, it becomes useless. One will need to either add more memory or re-evaluate the system setup.

Swap is used as virtual memory: Any time pages from processes are moved out of physical memory, they are generally stored on the swap device.

17.12. Backing Up and Restoring Partition Tables

Partitioning and re-partitioning disks are dangerous operations. In order to be able to restore the situation if something goes wrong, one needs to know how to backup and restore partition tables.

Backing up can be easily done with dd, as in:

$ sudo dd if=/dev/sda of=mbrbackup bs=512 count=1

which will back up the MBR on the first disk, including the 64-bit partition table which is part of it.

The MBR can then be restored, if necessary, by doing:

$ sudo dd if=mbrbackup of=/dev/sda bs=512 count=1

Note that the above commands only copy the primary partition table; they do not deal with any partition tables stored in the other partitions (for extended partitions, etc.)

Note: You should always assume that changing the disk partition table might eliminate all data in all filesystems on the disk (It should not, but be cautious!). Therefore, it is always prudent to make a backup of all data (that is not already backed up) before doing any of this type of work.

In particular, one must be careful in using dd: A simple typing error or misused option could destroy your entire disk; hence, do backups! 

17.13. Partition Table Editors

There are a number of utilities which can be used to manage partition tables:

    fdisk is a menu driven partition table editor. It is the most standard and one of the most flexible of the partition table editors. It is the only one of these utilities we will discuss.
    sfdisk is a non-interactive partition editor program, making it useful for scripting. Use the sfdisk tool with care!
    parted is the GNU partition manipulation program. It can create, remove, resize, and move partitions (including certain filesystems).
    gparted is a widely-used graphical interface to parted.

Many Linux distributions have a live/installation version which can be run off either a CDROM or USB stick. These media usually include a copy of gparted, so they can easily be used as a graphical partitioning tool on disks which are not actually being used while the partitioning program is run.

Note that gparted can do a lot of operations besides just adding and deleting partitions and the other operations fdisk can do, like designating the partition type. One can move and resize partitions and format them as well, which implies it has to understand the details of many filesystem types; this goes far beyond a partition editor's essential functions.

While this is convenient, it is difficult to get right and errors can have serious consequences. Thus, it is often good to drop down to the command line and do each of these operations separately with lower-level tools. In fact, Red Hat Enterprise Linux no longer supports gparted.

17.14.a. Using fdisk I

fdisk will always be included in any Linux installation, so it is a good idea to learn how to use it. You must be root to run fdisk. It can be somewhat complex to handle, and caution is advised.

The fdisk interface is simple and text-menu driven. After starting on a particular disk, as in:

$ sudo fdisk /dev/sdb

the main (one letter) commands are:

    m: Display the menu
    p: List the partition table
    n: Create a new partition
    d: Delete a partition
    t: Change a partition type
    w: Write the new partition table information and exit
    q: Quit without making changes.

Fortunately, no actual changes are made until you write the partition table to the disk by entering w. It is therefore important to verify your partition table is correct (with p) before writing to disk with w. If something is wrong, you can jump out safely with q.

17.14.b. Using fdisk II

The system will not use the new partition table until you reboot. However, you can use the following command:

$ sudo partprobe -s

to try and read in the revised partition table. However, this doesn't always work reliably and it is best to reboot before doing things like formatting new partitions, etc., as mixing up partitions can be catastrophic.

At any time you can do:

$ cat /proc/partitions

to examine what partitions the operating system is currently aware of.

18.1. Filesystem Features: Attributes, Creating, Checking, Mounting - Introduction

video

18.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain concepts such as inodes, directory files and extended attributes.
    Create and format filesystems.
    Check and fix errors on filesystems.
    Mount and unmount filesystems.

18.3. Inodes

An inode is a data structure on disk that describes and stores file attributes, including location. Every file is associated with its own inode. The information stored in the inode includes:

    Permissions\u200b
    User and group ownership\u200b
    Size\u200b
    Timestamps (nanosecond)
    - \u200bLast access time
    - Last modification time
    - Change time

Note: file names are not stored in a file's inode, but are instead stored in the directory file.

All I/O activity concerning a file usually also involves the file's inode as information must be updated.

18.4. Directory Files

A directory file is a particular type of file that is used to associate file names and inodes. There are two ways to associate (or link) a file name with an inode:

    Hard links point to an inode.\u200b
    Soft (or symbolic) links point to a file name which has an associated inode.

Each association of a directory file contents and an inode is known as a link. Additional links can be created using ln.

Because it is possible (and quite common) for two or more directory entries to point to the same inode (hard links), a file can be known by multiple names, each of which has its own place in the directory structure. However, it can have only one inode no matter which name is being used.

When a process refers to a pathname, the kernel searches directories to find the corresponding inode number. After the name has been converted to an inode number, the inode is loaded into memory and is used by subsequent requests.

18.5.a. Extended Attributes and lsattr/chattr I

 Extended Attributes associate metadata not interpreted directly by the filesystem with files. Four namespaces exist: user, trusted, security, and system. Later, we will see that the system namespace is used for Access Control Lists (ACLs), and the security namespace is used by SELinux.

Flag values are stored in the file inode and may be modified and set only by the root user. They are viewed with lsattr and set with chattr.

In the user namespace, flags may be set for files:

    i: Immutable
    A file with the immutable attribute cannot be modified (not even by root). It cannot be deleted or renamed. No hard link can be created to it, and no data can be written to the file. Only the superuser can set or clear this attribute.
    a: Append-only
    A file with the append-only attribute set can only be opened in append mode for writing. Only the superuser can set or clear this attribute.
    d: No-dump
    A file with the no-dump attribute set is ignored when the dump program is run. This is useful for swap and cache files that you don't want to waste time backing up.
    A: No atime update
    A file with the no-atime-update attribute set will not modify its atime (access time) record when the file is accessed but not otherwise modified. This can increase the performance on some systems because it reduces the amount of disk I/O on the system. 

18.5.b. Extended Attributes and lsattr/chattr II

Note that there are other flags that can be set; typing man chattr will show the whole list. The format for chattr is:

$ chattr [+|-|=mode] filename

lsattr is used to display attributes for a file:

$ lsattr filename

18.6.a. Creating and Formatting Filesystems I

Every filesystem type has a utility for formatting (making) a filesystem on a partition. The generic name for these utilities is mkfs. However, this is just a frontend for filesystem-specific programs.

$ ls -lh /sbin/mkfs*
-rwxr-xr-x 1 root root  11K Feb 15 10:22 /sbin/mkfs
-rwxr-xr-x 1 root root  27K Feb 15 10:22 /sbin/mkfs.bfs
-rwxr-xr-x 1 root root  35K Feb 15 10:22 /sbin/mkfs.cramfs
lrwxrwxrwx 1 root root    9 Dec 23  2015 /sbin/mkfs.exfat -> mkexfatfs
lrwxrwxrwx 1 root root    6 Oct 30  2015 /sbin/mkfs.ext2 -> mke2fs
lrwxrwxrwx 1 root root    6 Oct 30  2015 /sbin/mkfs.ext3 -> mke2fs
lrwxrwxrwx 1 root root    6 Oct 30  2015 /sbin/mkfs.ext4 -> mke2fs
lrwxrwxrwx 1 root root    6 Oct 30  2015 /sbin/mkfs.ext4dev -> mke2fs
-rwxr-xr-x 1 root root  27K May 26  2016 /sbin/mkfs.fat
-rwxr-xr-x 1 root root  76K Feb 15 10:22 /sbin/mkfs.minix
lrwxrwxrwx 1 root root    8 May 26  2016 /sbin/mkfs.msdos -> mkfs.fat
lrwxrwxrwx 1 root root    6 Jan 28  2017 /sbin/mkfs.ntfs -> mkntfs
lrwxrwxrwx 1 root root   10 Nov  7  2015 /sbin/mkfs.reiserfs -> mkreiserfs
lrwxrwxrwx 1 root root    8 May 26  2016 /sbin/mkfs.vfat -> mkfs.fat
-rwxr-xr-x 1 root root 356K Sep  8  2017 /sbin/mkfs.xfs

18.6.b. Creating and Formatting Filesystems II

Thus, the following two commands are entirely equivalent:

$ sudo mkfs -t ext4 /dev/sda10

$ sudo mkfs.ext4 /dev/sda10

The general format for mkfs is:

mkfs [-t fstype] [options] [device-file]

where [device-file] is usually a device name like /dev/sda3 or /dev/vg/lvm1.

Each filesystem type has its own particular options that can be set when formatting. For example, when creating an ext4 filesystem, one thing to keep in mind are the journalling settings. These include defining the journal file size and whether or not to use an external journal file.

One should look at the man page for each of the mkfs.* programs to see details.

18.7.a. Checking and Fixing Filesystems I

Every filesystem type has a utility designed to check for errors (and hopefully fix any that are found). The generic name for these utilities is fsck. However, this is just a frontend for filesystem-specific programs.


$ ls -lh /sbin/fsck*
-rwxr-xr-x 1 root root 44K Feb 15 10:22 /sbin/fsck
-rwxr-xr-x 1 root root 35K Feb 15 10:22 /sbin/fsck.cramfs
lrwxrwxrwx 1 root root   9 Dec 23  2015 /sbin/fsck.exfat -> exfatfsck
lrwxrwxrwx 1 root root   6 Oct 30  2015 /sbin/fsck.ext2 -> e2fsck
lrwxrwxrwx 1 root root   6 Oct 30  2015 /sbin/fsck.ext3 -> e2fsck
lrwxrwxrwx 1 root root   6 Oct 30  2015 /sbin/fsck.ext4 -> e2fsck
lrwxrwxrwx 1 root root   6 Oct 30  2015 /sbin/fsck.ext4dev -> e2fsck
-rwxr-xr-x 1 root root 59K May 26  2016 /sbin/fsck.fat
-rwxr-xr-x 1 root root 76K Feb 15 10:22 /sbin/fsck.minix
lrwxrwxrwx 1 root root   8 May 26  2016 /sbin/fsck.msdos -> fsck.fat
-rwxr-xr-x 1 root root 333 Feb  5  2016 /sbin/fsck.nfs
-rwxr-xr-x 1 root root 282 Nov  7  2015 /sbin/fsck.reiserfs
lrwxrwxrwx 1 root root   8 May 26  2016 /sbin/fsck.vfat -> fsck.fat
-rwxr-xr-x 1 root root 433 Sep  8  2017 /sbin/fsck.xfs
-rwxr-xr-x 1 root root 262 Mar 29 19:39 /sbin/fsck.zfs

18.7.b. Checking and Fixing Filesystems II

Thus, the following two commands are entirely equivalent:

$ sudo fsck -t ext4 /dev/sda10
$ sudo fsck.ext4 /dev/sda10

If the filesystem is of a type understood by the operating system, you can almost always just do:

$ sudo fsck -t ext4 /dev/sda10

and the system will figure out the type by examining the first few bytes on the partition.

fsck is run automatically after a set number of mounts or a set interval since the last time it was run or after an abnormal shutdown. It should only be run on unmounted filesystems. You can force a check of all mounted filesystems at boot by doing:

$ sudo touch /forcefsck
$ sudo reboot

The file /forcefsck will disappear after the successful check. One reason this is a valuable trick is it can do a fsck on the root filesystem, which is hard to do on a running system.


18.7.c. Checking and Fixing Filesystems III

The general format for fsck is:

fsck [-t fstype] [options] [device-file]

where [device-file] is usually a device name like /dev/sda3 or /dev/vg/lvm1. Usually, one does not need to specify the filesystem type, as fsck can figure it out by examining the superblocks at the start of the partition.

One can control whether any errors found should be fixed one by one manually with the -r option, or automatically, as best possible, by using the -a option, etc. In addition, each filesystem type may have its own particular options that can be set when checking.

Note that journalling filesystems are much faster to check than older generation filesystems for two reasons:

    One rarely needs to scan the entire partition for errors, as everything but the very last transaction has been logged and confirmed, so it takes almost no time to check.\u200b
    Even if one does check the whole filesystem, newer filesystems have been designed with fast fsck in mind; older filesystems did not think much about this when they were designed as sizes were much smaller.

One should look at the man page for each of the fsck.* programs to see details.

18.8. Mounting and Unmounting Filesystems

All accessible files in Linux are organized into one large hierarchical tree structure with the head of the tree being the root directory (/). However, it is common to have more than one partition (each of which can have its own filesystem type) joined together in the same filesystem tree. These partitions can also be on different physical devices, even on a network.

The mount program allows attaching at any point in the tree structure; umount allows detaching them.

The mount point is the directory where the filesystem is attached. It must exist before mount can use it; mkdir can be used to create an empty directory. If a pre-existing directory is used and it contains files prior to being used as a mount point, they will be hidden after mounting. These files are not deleted and will again be visible when the filesystem is unmounted.

By default, only the superuser can mount and unmount filesystems.

18.9. mount

Each filesystem is mounted under a specific directory, as in:

$ sudo mount -t ext /dev/sdb4 /home

    Mounts an ext4 filesystem
    The filesystem is located on a specific partition of a hard drive (/dev/sdb4)
    The filesystem is mounted at the position /home in the current directory tree
    Any files residing in the original /home directory are hidden until the partition is unmounted.

Note that in this example the filesystem is mounted by using the device node it resides on. However, it is also possible to mount using a label or a UUID. Thus, the following are all equivalent:

$ sudo mount /dev/sda2  /home
$ sudo mount LABEL=home /home
$ sudo mount    -L home /home
$ sudo mount UUID=26d58ee2-9d20-4dc7-b6ab-aa87c3cfb69a /home
$ sudo mount   -U 26d58ee2-9d20-4dc7-b6ab-aa87c3cfb69a /home

Labels are assigned by filesystem type specific utilities, such as e2label, and UUIDs are assigned when partitions are created as containers for the filesystem.

While any of these three methods for specifying the device can be used, modern systems deprecate using the device node form because the names can change according to how the system is booted, which hard drives are found first, etc. Labels are an improvement, but, on rare occasions, one could have two partitions that wind up with the same label. UUIDs, however, should always be unique, and are created when partitions are created.

18.10.a. mount Options I

mount takes many options, some generic like -a (mount all filesystems mentioned in /etc/fstab) and many filesystem specific; it has a very long man page. A common example would be:

$ sudo mount -o remount,ro /myfs 

which remounts a filesystem with a read-only attribute. 

18.11. umount

Filesystems can be unmounted, as in:

$ umount [device-file | mount-point]

Below are some examples of how to unmount a filesystem:

    Unmount the /home filesystem:
    $ sudo umount /home
    Unmount the /dev/sda3 device:
    $ sudo umount /dev/sda3

Note that the command to unmount a filesystem is umount (not unmount!).

Like mount, umount has many options, many of which are specific to filesystem type. Once again, the man pages are the best source for specific option information.

The most common error encountered when unmounting a filesystem is trying to do this on a filesystem currently in use; i.e., there are current applications using files or other entries in the filesystem.

This can be as simple as having a terminal window open in a directory on the mounted filesystem. Just using cd in that window, or killing it, will get rid of the device is busy error and allow unmounting.

However, if there are other processes inducing this error, you must kill them before unmounting the filesystem. You can use fuser to find out which users are using the filesystem and kill them (be careful with this, you may also want to warn users first). You can also use lsof ("list open files") to try and see which files are being used and blocking unmounting.

18.12. Network Shares (NFS)

t is common to mount remote filesystems through network shares, so they appear as if they were on the local machine. Probably the most common method used historically has been NFS (Network File System).

NFS was originally developed by Sun Microsystems in 1989, and has been continuously updated. Modern systems use NFSv4, which has been con\u200btinuously updated since 2000.

Other network filesystems include AFS (Andrew File System), and SMB (Server Message Book), also termed CIFS (Common Internet File System).

Because a network filesystem may be unavailable at any time, eith\u200ber because it is not present on the network share, or the network is unavailable, systems have to be prepared for this possibility.

Thus, in such circumstances, a system should be instructed not to get hung, or blocked, while waiting longer than a specified period. These can be specified in the mount command:

$ sudo mount -t nfs myserver.com:/sharedir /mnt/sharedir\u200b

or in /etc/fstab. Put the following line in /etc/fstab to mount on boot or with mount -a:\u200b

myserver.com:/sharedir /mnt/sharedir nfs rsize=8192,wsize=8192,timeo=14,intr 0 0

The system may try to mount the NFS filesystem before the network is up. The _netdev and noauto options can be used. For more information, check man nfs, examine the mount options.

It can also be solved using autofs or automount.

Mount has a large amount of options, some of which are specific to nfs. See the man pages for both nfs and mount for \u200bmore details.

18.13.a. Mounting Filesystems at Boot I

During system boot, the command mount -a is executed. This mounts all filesystems listed in the /etc/fstab configuration file. Entries can refer to both local and remote network-mounted filesystems. Here is an example showing you how to mount all filesystems listed in the /etc/fstab configuration file during system boot.

This file shows what filesystems may be automatically mounted at boot and where they may be found on the local machine or network. It can specify who may mount them and with what permissions, and other relevant options. Some of the lines refer to special pseudo-filesystems such as proc, sys, and devpts.

18.13.b. Mounting Filesystems at Boot II

Each record in the file contains fields separated by white space listing:

    Device node, label, or UUID
    For filesystems which do not have a device node, such as tmpfs, proc, and sysfs, this field is just a place holder; sometimes, you will see the word none in that column, or used on the command line.
    Mount point
    This can also be a place holder, like for swap, which is not mounted anywhere.
    A comma-separated list of options
    dump frequency (or a 0) 
    This is used by the dump -w command.
    fsck pass number (or 0, meaning do not check state at boot).

18.13.c. Mounting Filesystems at Boot III

The mount and umount utilities can use information in /etc/fstab; in such a case one could type

$ sudo mount /usr/src    

instead of

$ sudo mount LABEL=src /usr/src

in the above example.

18.14. Automatic Filesystem Mounting

Linux systems have long had the ability to mount a filesystem only when it is needed. Historically, this was done using autofs. This utility requires installation of the autofs package using the appropriate package manager and configuration of files in /etc.

While autofs is very flexible and well understood, systemd-based systems (including all recent enterprise Linux distributions) come with automount facilities built into the systemd framework. Configuring this is as simple as adding a line in /etc/fstab specifying the proper device, mount point and mounting options, such as:

LABEL=Sam128 /SAM ext4 noauto,x-systemd.automount,x-systemd.device-timeout=10,x-systemd.idle-timeout=30 0 0

and then, either rebooting or issuing the command:

$ sudo systemctl daemon-reload
$ sudo systemctl restart local-fs.target

Next, we will give an example and explain the options. 

18.15. automount Example

The example provided mounts a USB pen drive that is always plugged into the system, only when it is used. Options in /etc/fstab:

    noauto
    Do not mount at boot. Here, auto does not refer to automount.

    x-systemd.automount
    Use the systemd automount facility.

    x-systemd.automount.device-timeout=10
    If this device is not available, say it is a network device accessible through NFS, timeout after 10 seconds instead of getting hung.

    x-systemd.automount.idle-timeout=30
    If the device is not used for 30 seconds, unmount it. 

Note that the device may be mounted during boot, but then it should be unmounted after the timeout specified.

18.16. Listing Currently Mounted Filesystems

The list of currently mounted filesystems can be seen by typing: $ mount

19.1. Filesystem Features: Swap, Quotas, Usage - Introduction

Linux uses a robust swap space implementation through which the virtual memory system permits the apparent use of more memory than is physically available. Filesystem quotas can be used to administer user account usage of disk space. Utilities such as df and du enable easy monitoring of filesystem usage and capacities. 

19.1. Learning Objectives

By the end of this chapter, you should be able to:

    Explain the concepts of swap and quotas.
    Use the utilities that help manage quotas: quotacheck, quotaon, quotaoff, edquota, and quota.
    Use the utilities df and du.

19.3.a. Swap I

Linux employs a virtual memory system, in which the operating system can function as if it had more memory than it really does. This kind of memory overcommission functions in two ways:

    Many programs do not actually use all the memory they are given permission to use. Sometimes, this is because child processes inherit a copy of the parent's memory regions utilizing a COW (Copy On Write) technique, in which the child only obtains a unique copy (on a page-by-page basis) when there is a change.
    When memory pressure becomes important, less active memory regions may be swapped out to disk, to be recalled only when needed again.

Such swapping is usually done to one or more dedicated partitions or files; Linux permits multiple swap areas, so the needs can be adjusted dynamically. Each area has a priority, and lower priority areas are not used until higher priority areas are filled.

19.3.b. Swap II

In most situations, the recommended swap size is the total RAM on the system. You can see what your system is currently using for swap areas by looking at /proc/swaps and get basic memory statistics with free:

19.3.c. Swap III

The only commands involving swap are:

    mkswap: format a swap partition or file
    swapon: activate a swap partition or file
    swapoff: deactivate a swap partition or file.

At any given time, most memory is in use for caching file contents to prevent actually going to the disk any more than necessary, or in a sub-optimal order or timing. Such pages of memory are never swapped out as the backing store is the files themselves, so writing out a swap would be pointless; instead, dirty pages (memory containing updated file contents that no longer reflect the stored data) are flushed out to disk.

It is also worth pointing out that in Linux memory used by the kernel itself, as opposed to application memory, is never swapped out, in distinction to some other operating systems.

19.4. Quotas

Linux can use and enforce quotas on filesystems. Disk quotas allow administrators to control the maximum space particular users (or groups) are allowed. Considerable flexibility is allowed and quotas can be assigned on a per filesystem basis. Protection is provided against a subset of users exhausting collective resources.   

These utilities help manage quotas:

    quotacheck: generates and updates quota accounting files
    quotaon: enables quota accounting
    quotaoff: disables quota accounting
    edquota: used for editing user or group quotas
    quota: reports on usage and limits.

Quota operations require the existence of the files aquota.user and aquota.group in the root directory of the filesystem using quotas.

Quotas may be enabled or disabled on a per filesystem basis. In addition, Linux supports the use of quotas based on user and group IDs.

Different filesystem types may have additional quota-related utilities, such as xfs_quota.

19.5.a. Setting up Quotas I

To create a filesystem quota, you must first make sure you have mounted the filesystem with the user and/or group quota mount options. Without these, nothing else will work. The basic steps are:

    Mount the filesystem with user and/or group quota options:
    - Add the usrquota and/or grpquota options to the filesystems entry in /etc/fstab
    - Remount the filesystem (or mount it if new)
    Run quotacheck on the filesystem to set up quotas
    Enable quotas on the filesystem
    Set quotas with the edquota program.


19.5.b. Setting up Quotas II

Thus, to create a filesystem quota you must first make sure that you have mounted the filesystem with the user and/or group quota mount options. Without these, nothing else will work.

First, you need to put the right options in /etc/fstab as in:

/dev/sda5 /home ext4 defaults,usrquota 1 1

where we have assumed /home is on a dedicated partition.

Then, test with the following commands:

$ sudo mount -o remount /home

$ sudo quotacheck -vu /home

$ sudo quotaon -vu /home

$ sudo edquota someusername

You may also want to set up grace periods with edquota. The mount options that should be used in the /etc/fstab file are usrquota for user quotas and grpquota for group quotas.


19.6. quotacheck

The quotacheck utility creates/updates the quota accounting files (aquota.user and aquota.group) for the filesystem.

To update user files for all filesystems in /etc/fstab with user quota options:

$ sudo quotacheck -ua

To update group files for all filesystems in /etc/fstab with group quota options:

$ sudo quotacheck -ga

To update the user file for a particular filesystem:

$ sudo quotacheck -u [somefilesystem]

To update the group file for a particular filesystem:

$ sudo quotacheck -g [somefilesystem]

Use the -v option to get more verbose output.

quotacheck is generally only run when quotas are initially turned on (or need to be updated). The program may also be run when fsck reports errors in the filesystem when the system is starting up.

19.7.a. Turning quotas on and off I

quotaon is used to turn filesystem quotas on; quotaoff is used to turn them off. They are used as in:

$ sudo quotaon  [flags] [filesystem]

$ sudo quotaoff [flags] [filesystem]

where the flags can be:

-a, --all                               turn quotas off for all filesystems
-f, --off                               turn quotas off
-u, --user                              operate on user quotas
-g, --group                             operate on group quotas
-p, --print-state                       print whether quotas are on or off
-x, --xfs-command=cmd                   perform XFS quota command
-F, --format=formatname                 operate on specific quota format
-v, --verbose                           print more messages
-h, --help                              display this help text and exit
-V, --version                           display version information and exit

19.7.b. Turning quotas on and off II

Note that quotaon and quotaoff programs are really one and the same and operate accordingly to which name they are called with.

For example:

$ sudo quotaon -av
/dev/sda6 [/]: group quotas turned on
/dev/sda5 [/home]: user quotas turned on

$ sudo quotaoff -av
/dev/sda6 [/]: group quotas turned off
/dev/sda5 [/home]: user quotas turned off

$ sudo quotaon -avu
/dev/sda5 [/home]: user quotas turned on

$ sudo quotaoff -avu
/dev/sda5 [/home]: user quotas turned off

$ sudo quotaon -avg
/dev/sda6 [/]: group quotas turned on

$ sudo quotaoff -avg
/dev/sda6 [/]: group quotas turned off

Note also that quota operations will fail if the files aquota.user or aquota.group do not exist.


19.8. Examining Quotas

The quota utility is used to generate reports on quotas:

    quota (or quota -u) returns your current user quota.
    quota -g returns your current group quota.
    The superuser may look at quotas for any user or group by specifying a user or group name.

For example:

$ sudo quota george

Disk quotas for user george (uid 1000):

   Filesystem   blocks quota limit grace files quota limit grace

      /dev/sda5 837572   500  1000        5804     0     0

$ sudo quota gracie

Disk quotas for user gracie (uid 1001):

  Filesystem     blocks quota limit grace files quota limit grace

    /dev/sda5     83757  5000 10000        5804     0     0

19.9.a. Setting Quotas I

Typing edquota brings up the quota editor. For the specified user or group, a temporary file is created with a text representation of the current disk quotas for that user or group.

Then, an editor is invoked for that file, and quotas may then be modified. Once you leave the editor, the temporary file is read and the binary quota files adopt the changes.

The only fields which can be edited in the quota are the soft and hard limits. The other fields are informational only.

Below are examples of how to use edquota:

    edquota -u [username] edits limits for username
    edquota -g [groupname] edits limits for groupname
    edquota -u -p [userproto] [username] copies userproto's user quota values to username
    edquota -g -p [groupproto] [groupname] copies groupproto's group quota values to groupname
    edquota -t to set grace periods

The third and fourth commands are useful for including in scripts which might be used to create new accounts and set quotas for them.


19.9.b. Setting Quotas II

Quotas for users and groups may be set for disk blocks and/or inodes. In addition, soft and hard limits may be set as well as grace periods: Soft limits may be exceeded for a grace period. Hard limits may never be exceeded.

The grace period is set on a per filesystem basis.

$ sudo edquota gracie

$ sudo edquota -t


19.10. Filesystem Usage

The df (disk free) utility examines filesystem capacity and usage. In the example we provided here the -h option means "human-readable" (i.e., in KB, MB, GB, not bytes) and -T shows the filesystem type. Using the -i option would show inode information instead of bytes.


20.1. The Ext2/Ext3/Ext4 Filesystems - Introduction

The ext family of filesystems have been native to Linux since its earliest days, and have been the most widely used of the choices available. Until very recently, ext4 was the most frequent default choice of Linux distributions, due to its excellent combination of performance, integrity, and stability.

20.2. Learning Objectives

By the end of this chapter, you should be able to:

    Describe the main features of the ext4 filesystem and how it is laid out on disk.
    Explain the concepts of block groups, superblock, data blocks and inodes.
    Use the dumpe2fs and tune2fs utilities. 
    List the ext4 filesystem enhancements.

20.3. Ext4 History and Basics

The ext2 filesystem was Linux's original native variety and is available on all Linux systems, but is rarely used today. 

The ext3 filesystem was the first journalling extension of ext2. It had the same on-disk layout as ext2 except for the presence of a journal file.

The ext4 filesystem first appeared in kernel version 2.6.19, and its experimental designation was removed in version 2.6.28. It included significant enhancements, such as the use of extents for large files, instead of lists of file blocks.

An extent is simply a group of contiguous blocks. Using them can improve large file performance and reduce fragmentation.

ext4 is the default filesystem on most enterprise Linux distributions, although RHEL 7 has adopted XFS as the default.

20.4. Ext4 Features

There is a close correspondence of features between the VFS and the ext2/3/4 filesystems, as each has been designed with the other in mind.

Block size is selected when the filesystem is built; it can be 512, 1024, 2048, or 4096 bytes. By default, 4096 is usually used for hard disk systems, unless the partition is very small. Unless there are very many small files, larger block sizes can be more efficient in terms of minimizing hard disk access.

The Linux kernel memory management system requires only an integral number of blocks must fit into a page of memory; thus, you cannot have 8 KB blocks on an x86 platform where pages of memory are 4 KB in size.

The number of inodes on the filesystem can also be tuned, which may save disk space.

A feature called inode reservation consists of reserving several inodes when a directory is created, expecting them to be used in the future. This improves performance, because, when new files are created, the directory already has inodes allocated.

If the pathname of a symbolic link is less than 60 characters, a so-called fast symbolic link is created, which is stored directly in the inode, obviating the need to read a data block.


20.5. Ext4 Layout

All fields are written to disk in little-endian order, except the journal.

Disk blocks are partitioned into block groups, each of which contains inode and data blocks stored adjacently, thereby lowering access time.

The layout of a standard block group is simple. For block group 0, the first 1024 bytes are unused (to allow for boot sectors, etc). The superblock will start at the first block, except for block group 0. This is followed by the group descriptors and a number of GDT (Group Descriptor Table) blocks. These are followed by the data block bitmap, the inode bitmap, the inode table, and the data blocks.

Data blocks are pre-allocated to files before they are actually used. Thus, when a file's size is increased, adjacent space has already been reserved and file fragmentation is reduced.

The filesystem superblock contains bit-fields which are used to ascertain whether or not the filesystem requires checking when it is first mounted during system initialization. The status can be:

    clean: filesystem cleanly unmounted previously
    dirty: usually means mounted
    unknown: not cleanly unmounted, such as when there is a system crash.

In the latter two cases, fsck will be run to check the filesystem and fix any problems before it is mounted.

Other fields in the superblock contain information about when the filesystem was last checked, both in date and number of mounts, and automatic checking is triggered when tunable limits are exceeded for these quantities.

The first block on the filesystem is the so-called boot block, and is reserved for the partition boot sector.

20.6.a. Block Groups I

After the boot block there is a series of block groups, each of which is the same size. The layout of each block group is given in the following figure:  

                ext2/3/4 Filesystem Layout

=====================================================================================================
|               |               |                   |               |               |               |
|      Super    |      Group    |     Data Block    |    Inode      |   Inode Table |    Data       |
|      Block    |   Descriptors |       Bitmap      |    Bitmap     |   (n Blocks)  |   Blokcs      |
|               |               |                   |               |               |               |
=====================================================================================================

20.6.b. Block Groups II

The first and second blocks are the same in every block group, and comprise the Superblock and the Group Descriptors. Under normal circumstances, only those in the first block group are used by the kernel; the duplicate copies are only referenced when the filesystem is being checked. If everything is OK, the kernel merely copies them over from the first block group. If there is a problem with the master copies, it goes to the next and so on until a healthy one is found and the filesystem structure is rebuilt. This redundancy makes it very difficult to thoroughly fry an ext2/3/4 filesystem, as long as the filesystem checks are run periodically.

In the early incarnations of the ext filesystem family, each block group contained the group descriptors for every block group, as well as a copy of the superblock. As an optimization, however, today not all block groups have a copy of the superblock and group descriptors. To see what you have, you could examine it as in the accompanying screenshot, (putting in an appropriate device node) to see precise locations. This happens when the filesystem is created with the sparse_super option, which is the default.

20.6.c. Block Groups III

The number of block groups is constrained by the fact that the block bitmap, which identifies used and free blocks within the group, has to fit in a single block. Thus, if a block is 4096 bytes in size, a block group can contain no more than 32 K blocks, or 128 MB. If we take the largest possible block group size, a 10 GB partition would thus have to have at least 80 block groups.

The block allocator tries to keep each file's blocks within the same block group to reduce seek times.

20.7. dumpe2fs

As we have just demonstrated, one can use the utility dumpe2fs to scan the filesystem information; doing so on a partition reveals:  

$ sudo dumpe2fs /dev/sda1

Filesystem volume name:  RHEL7
Last mounted on:         /
Filesystem UUID:         9d6b5801-9c7e-4c17-9068-49923952338e
Filesystem magic number: 0xEF53
Filesystem revision #:   1 (dynamic)
Filesystem features:     has_journal ext_attr resize_inode dir_index filetype needs_recovery extent 64bit flex_bg sparse_super

Filesystem flags:        signed_directory_hash
Default mount options:   user_xattr acl
Filesystem state:        clean
Errors behavior:         Continue
Filesystem OS type:      Linux
Inode count:             1908736
Block count:             7630592
Reserved block count:    381529

Free blocks:             5353383
Free inodes:             1682479
First block:             0
Block size:              4096
Fragment size:           4096
Group descriptor size:   64
Reserved GDT blocks:     1024
Blocks per group:        32768
Fragments per group:     32768
Inodes per group:        8192
Inode blocks per group:  512
Flex block group size:   16
Filesystem created:      Wed Sep 3 03:52:55 2014
Last mount time:         Fri Oct 24 09:18:58 2014
Last write time:         Fri Oct 24 09:18:58 2014
Mount count:             89
Maximum mount count:     -1
Last checked:            Wed Sep 3 03:52:55 2014
Check interval:          0 (<none>)
Lifetime writes:         103 GB
Reserved blocks uid:     0 (user root)
Reserved blocks gid:     0 (group root)
First inode:             11
Inode size:              256
Required extra isize:    28
Desired extra isize:     28
Journal inode:           8
First orphan inode:      396118
Default directory hash:  half_md4
Directory Hash Seed:     e488c43e-241c-4014-91d8-6a9d3d6c7784
Journal backup:          inode blocks
Journal features:        journal_incompat_revoke journal_64bit
Journal size:            128M
Journal length:          32768
Journal sequence:        0x00023592
Journal start:           16394
 

Group 0: (Blocks 0-32767) [ITABLE_ZEROED]
    Checksum 0x2921, unused inodes 7738
    Primary superblock at 0, Group descriptors at 1-4
    Reserved GDT blocks at 5-1028
    Block bitmap at 1029 (+1029), Inode bitmap at 1045 (+1045)
    Inode table at 1061-1572 (+1061)
    22880 free blocks, 8174 free inodes, 2 directories, 7738 unused inodes
    Free blocks: 9381-9672, 10180-32767
    Free inodes: 19-8192

Group 1: (Blocks 32768-65535) [INODE_UNINIT, ITABLE_ZEROED]

    Checksum 0x473e, unused inodes 8192
    Backup superblock at 32768, Group descriptors at 32769-32772
    Reserved GDT blocks at 32773-33796
    Block bitmap at 1030 (bg #0 + 1030), Inode bitmap at 1046 (bg #0 + 1046)
    Inode table at 1573-2084 (bg #0 + 1573)
    14918 free blocks, 8192 free inodes, 0 directories, 8192 unused inodes
    Free blocks: 33797, 33800-33919, 34108-34511, 34521-34559, 34784-34815, 37053-38015, 38039- 38040, 38080-38527, 38529-38911, Free inodes: 8193-16384
.....
Group 196: (Blocks 6422528-6455295) [INODE_UNINIT, ITABLE_ZEROED]
    Checksum 0x946d, unused inodes 8192
    Block bitmap at 6291460 (bg #192 + 4), Inode bitmap at 6291476 (bg #192 + 20)
    Inode table at 6293536-6294047 (bg #192 + 2080)
    32768 free blocks, 8192 free inodes, 0 directories, 8192 unused inodes
    Free blocks: 6422528-6455295

    Free inodes: 1605633-1613824
    ....
Group 232: (Blocks 7602176-7630591) [INODE_UNINIT, ITABLE_ZEROED]
    Checksum 0xa174, unused inodes 8192
    Block bitmap at 7340040 (bg #224 + 8), Inode bitmap at 7340056 (bg #224 + 24)
    Inode table at 7344160-7344671 (bg #224 + 4128)
    28416 free blocks, 8192 free inodes, 0 directories, 8192 unused inodes
    Free blocks: 7602176-7630591
    Free inodes: 1900545-1908736

20.8. tunee2fs

 tune2fs can be used to change filesystem parameters.

To change the maximum number of mounts between filesystem checks (max-mount-count):

$ sudo tune2fs -c 25 /dev/sda1

To change the time interval between checks (interval-between-checks):

$ sudo tune2fs -i 10 /dev/sda1

To list the contents of the superblock including the current values of parameters which can be changed:

$ sudo tune2fs -l /dev/sda1

20.9. Superblock Information

The superblock contains global information about the filesystem, including:

    Mount count and maximum mount count (The mount count is incremented every time the disk is successfully mounted, and its value is the number of times this has been done since the last fsck.) One can also force a filesystem check after 180 days by default, or another time that can be changed by the tune2fs utility.\u200b
    Block size (Cannot be greater than a page of memory, set by mkfs.)\u200b
    Blocks per group
    Free block count
    Free inode count
    Operating System ID.

As we discussed earlier, the superblock is redundantly stored in several block groups.

20.10. Data Blocks and Inodes

The data block and inode bitmaps are blocks whose bits contain 0 for each free block or inode and 1 for each used one. There is only one of each of these bitmaps per block group.

The inode table contains as many consecutive blocks as are necessary to cover the number of inodes in the block group. Each inode requires 128 bytes; thus, a 4 KB block can contain 32 inodes. 

Note that there is space reserved for some operating system dependent information; different OSs could possibly mount an ext2/3/4 filesystem, much as Linux can mount many kinds of non-native filesystems.

Note that the inode number itself is not stored on the disk in this structure; its value can be quickly calculated from the block group number and offset within the inode table.

The ext2 and ext3 filesystems did not yet incorporate the use of extents to organize larger files. Instead, the i_block[] array of pointers to data blocks, of length EXT2_N_BLOCKS=15, is described by the inode. The way this is handled is somewhat complex:

    The first 12 elements in this array simply point to the first 12 data blocks in the file.
    The 13th element points to a block that represents a second-order array of block numbers; the 14th to a third-order array, and the 15th to a fourth-order array.

This algorithm makes addressing small files go the fastest, as it should. For instance, with a 4 KB block size, a 48 KB file can be directly addressed, a 2 MB file requires a second-order process, a 1 GB a third-order, a 4 GB file a fourth-order.

20.11. Ext4 Filesystem Enhancements

The ext4 filesystem:

    Is backwards-compatible with ext3 and ext2.
    Increases the maximum filesytem size to 1 EB (from 16 TB), and the maximum file to 16 TB (from 2 TB). These limits arise from the 48-bit addressing that is used; full 64-bit addressing may be in the future, but not really needed at this point.
    Increases without limit the maximum number of subdirectories, which was limited to 32 K in ext3.
    Splits large files into the largest possible extents instead of using indirect block mapping. This can improve large file performance and reduce fragmentation.
    Uses multiblock allocation which can allocate space all at once, instead of one block at a time. In addition, delayed allocation can also increase performance.
    Can pre-allocate disk space for a file. The allocated space is usually both guaranteed and contiguous.
    Uses allocate-on-flush, a performance technique which delays block allocation until data is written to disk.
    Uses fast fsck which can make the speed of a filesystem check go up by an order of magnitude or more.
    Uses checksums for the journal which improves reliability. This can also safely avoid a disk I/O wait during journalling, resulting in a slight performance boost.
    Uses improved timestamps measured in nanoseconds.
    Includes snapshot support.

21.1. THe XFS and btrfs Filesystems - Introduction

The XFS and btrfs filesystems have arisen as important challengers to the dominance of ext4 in Enterprise Linux distributions. These next generation filesystems have robust capabilities with respect to handling large sizes, spanning multiple physical and logical volumes and performance metrics.

21.2. Learning Objectives

By the end of this chapter, you should be able to:

    Describe the XFS filesystem.
    Maintain the XFS filesystem.
    Describe the btrfs filesystem.

21.2. XFS Features

XFS was originally designed and created by SGI and used in the IRIX operating system and was subsequently ported to Linux. It was explicitly engineered to deal with large data sets, as well as handle parallel I/O tasks very effectively.

It can handle:

    Up to 16 EB (exabytes) for the total filesystem.
    Up to 8 EB for an individual file.

High performance is one of the key design elements of XFS, which implements methods for:

    Employing DMA (Direct Memory Access) I/O
    Guaranteeing an I/O rate
    Adjusting stripe size to match underlying RAID or LVM devices.

In contrast to traditional filesystems,  XFS  can also journal quota information. This leads to decreased recovery time when a quota-enabled filesystem is uncleanly unmounted. Furthermore, the journal can be on an external device.

As with other UNIX and Linux filesystems, XFS supports extended attributes.

21.4. XFS Filesystem Maintenance

Maintaining an XFS filesystem is made easier by the fact that most of the maintenance tasks can be done on-line (i.e., while the filesystem is fully mounted). These include:

    Defragmenting
    Enlarging
    Dumping/Restoring.

Backup and restore can be done with the native XFS utilities:

    xfsdump
    xfsrestore

which can be conveniently paused and then resumed at a later time. Because these utility programs are also multi-threaded, XFS dumps and restores can be accomplished very quickly.

While XFS does not directly support hardware or software snapshots, the xfs-freeze utility can be used to quiesce the filesystem, thus allowing a snapshot tool to work on the underlying device. The Linux LVM tools will automatically use xfs-freeze to quiesce the filesystem for snapshots.

XFS supports quotas and the traditional quota commands can be used to manipulate per-filesystem quotas on an XFS volume. However, if you use the xfs-quota command you can use the per-directory quotas that XFS supports.

21.5. THe btrfs Filesystem

Both Linux developers and Linux users with high performance and high capacity or specialized needs are following the development and gradual deployment of the btrfs filesytem, which was created by Chris Mason. The name stands for B-tree file system. Full documentation can be found at  http://btrfs.wiki.kernel.org/index.php/Main_Page .

btrfs is intended to address the lack of pooling, snapshots, checksums, and integral multi-device spanning in other Linux filesystems such as ext4. Such features can be crucial for Linux to scale into larger enterprise storage configurations.

While btrfs has been in the mainline kernel since 2.6.29 it has generally been viewed as experimental, although a few vendors have used it in new products. 

One of the main features is the ability to take frequent snapshots of entire filesystems, or sub-volumes of entire filesystems in virtually no time. Because btrfs makes extensive use of COW techniques (Copy on Write), such a snapshot does not involve any more initial space for data blocks or any I/O activity except for some metadata updating.

One can easily revert to the state described by earlier snapshots and even induce the kernel to reboot off an earlier root filesystem snapshot.

btrfs maintains its own internal framework for adding or removing new partitions and/or physical media to existing filesystems, much as LVM (Logical Volume Management) does.

Before btrfs becomes suitable for day-to-day use in critical filesystems, some tasks require finishing. For a review of the development history of btrfs and expected evolution see http://lwn.net/Articles/575841.

22.1. Disk Encryption - Introduction

Filesystems may be encrypted to protect them from both prying eyes and attempts to corrupt the data they contain. Encryption can be chosen at installation or incorporated later. Linux distributions most often use the LUKS method and perform encryption-related tasks using cryptsetup.

22.2. Learning Objectives

By the end of this chapter, you should be able to:

    Provide sound reasons for using encryption and know when it is called for.
    Understand how LUKS operates through the use of cryptsetup.
    Be able to set up and use encrypted filesystems and partitions.
    Know how to configure the system to mount encrypted partitions at boot. 

22.3. Why Use Encryption?

Encryption should be used wherever sensitive data is being stored and transmitted. Configuring and using block device level encryption provides one of the strongest protections against harm caused by loss or compromise of data contained in hard drives and other media. 

Modern Linux distributions offer the choice of encrypting all or some of your disk partitions during installation. It is also straightforward to create and format encrypted partitions at a later time, but you cannot encrypt an already existing partition in place without a data copying operation. 

22.4. LUKS 

Modern Linux distributions provide block device level encryption mainly through the use of LUKS (Linux Unified Key Setup). Using block device encryption is highly recommended for portable systems such as laptops, tablets, and smart phones.

LUKS is installed on top of cryptsetup, a powerful utility that can also use other methods such as plain dm-crypt volumes, loop-AES and TrueCrypt-compatible format. We won't discuss these alternatives, as LUKS (which was originally designed for Linux but has also been exported to other operating systems) is the standard method most often used in Linux.

The dm-crypt kernel module uses the device mapper kernel infrastructure that is also heavily used by LVM, which we will discuss later.

Because LUKS stores all necessary information in the partition header itself, it is rather easy to migrate partitions to other disks or systems.

LUKS can also be used to transparently encrypt swap partitions. 

22.5. cryptsetup

Basically, everything is done with the Swiss army knife program cryptsetup. Once encrypted volumes have been set up, they can be mounted and unmounted with normal utilities.

The general form of a command is:

cryptsetup [OPTION...] <action> <action-specific>

and a rather full listing of possibilities can be generated by:

$ cryptsetup --help

22.6.a. Using an Encrypted Partition I

If the partition /dev/sda7 already exists, the following commands will set up encryption, make it available to LUKS, format it, mount it, use it, and unmount it.

First, we need to give the partition to LUKS:

$ sudo cryptsetup luksFormat /dev/sda7

You will be prompted for a passphrase that will need to open use of the encrypted volume later. Note that you only have to do this step once, when setting up encryption.

You may have trouble here if your kernel does not support the default encryption method used by cryptsetup. In that case, you can examine /proc/crypto to see the methods your system supports, and then you can supply a method, as in:

$ sudo cryptsetup luksFormat --cipher aes /dev/sda7

22.6.b. Using an Encrypted Partition II

You can make the volume available at any time with:

$ sudo cryptsetup --verbose luksOpen /dev/sda7

where you will be prompted to supply the passphrase. You can format the partition:

$ sudo mkfs.ext4  /dev/mapper/SECRET

mount it:

$ sudo mount /dev/mapper/SECRET /mnt

and then use to your heart's content just as if it were an unencrypted partition mounted at /mnt.  When you are done, unmount with:

$ sudo umount /mnt

and then remove the mapper association for now, the partition will always be available for later use:

$ sudo cryptsetup --verbose luksClose SECRET

22.7. Mounting at Boot

To mount an encrypted partition at boot, two conditions have to be satisfied: 

    Make an appropriate entry in /etc/fstab. There is nothing special about this and it does not refer to encryption in any way.
    Add an entry to /etc/crypttab. This can be as simple as:

    SECRET /dev/mapper/MYSECRET

    You can do more in this file, such as specifying the password if you don't want to be prompted at boot (which seems counterproductive security-wise). See man crypttab to find out what you can do with this file.

22.9. KNowledge Check 22.1

Steps to setup encryption with LUKS:

- Create partition for encryted block device
- Format with cryptsetup
- Create the un-encrypted pass through device
- Format with a standard fiesystem such as ext4
- Mount the filesystem on the encrypted block device

23.1. Logiacal Volume Management (LVM) - Introduction

video

23.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain the concepts behind LVM.
    Create logical volumes.
    Display logical volumes.
    Resize logical volumes.
    Use LVM snapshots.

23.3. LVM

LVM (Logical Volume Management) breaks up one virtual partition into multiple chunks, each of which can be on different partitions and/or disks.

There are many advantages to using LVM; in particular, it becomes really easy to change the size of the logical partitions and filesystems, to add more storage space, rearrange things, etc.

One or more physical volumes (disk partitions) are grouped together into a volume group. Then, the volume group is subdivided into logical volumes, which mimic to the system nominal physical disk partitions and can be formatted to contain mountable filesystems.

There are a variety of command line utilities tasked to create, delete, resize, etc. physical and logical volumes. For a graphical tool, some Linux distributions use system-config-lvm. However, RHEL 7 does not support this tool and there is currently no graphical tool that works reliably with the most recent variations in filesystem types etc. Fortunately, the command line utilities are not hard to use and are more flexible anyway.

LVM does impact performance. There is a definite additional cost that comes from the overhead of the LVM layer. However, even on non-RAID systems, if you use striping (splitting of data to more than one disk),  you can achieve some parallelization improvements.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+                                                                                                                +
+                                                               LVM                                              +
+                         ======================================|============================================    +
+                         |                                     |                                           |    +
+         Filesystem      |             /home                   |                   /data                   |    +
+                         |             (ext3)                  |                   (xfs)                   |    +
+                         ======================================|============================================    +
+                                                                                                                +
+                         ======================================|============================================    +
+                         |                                     |                                           |    +
+ Logical Volumes (LV)    |      /dev/primary_vg/home_lv        |        /dev/primary_vg/data_lv            |    +
+                         |                                     |                                           |    +
+                         ======================================|============================================    +
+                                                                                                                +
+                         ===================================================================================    +
+                         |                                                                                 |    +
+ Volume Groups (VG)      |                                primary_vg                                       |    +
+                         |                                                                                 |    +
+                         ===================================================================================    +
+                                                                                                                +
+                         ====================  =================  ==================   =====================    +
+                         |                  |  |               |  |                |   |                   |    +
+  Physical Volumes       |   /dev/sdb1      |  |  /dev/sdb2    |  |  /dev/sda1     |   |  /dev/sda2        |    +
+                         |                  |  |               |  |                |   |                   |    +
+                         ====================  =================  ==================   =====================    +
+                                                                                                                +
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

                          ====================  =================  ==================   =====================    
                          |                  |  |               |  |                |   |                   |    
  Partitions              |   /dev/sdb1      |  |  /dev/sdb2    |  |  /dev/sda1     |   |  /dev/sda2        |    
                          |                  |  |               |  |                |   |                   |    
                          ====================  =================  ==================   =====================    


                          =====================================    ==========================================    
                          |                                   |    |                                        |    
  Physical Devices        |              /dev/sdb             |    |               /dev/sda                |    
                          |                                   |    |                                        |    
                          =====================================    ==========================================    


23.4. LVM and RAID

Like RAID (which we will discuss in the next chapter), the use of logical volumes is a mechanism for creating filesystems which can span more than one physical disk.

Logical volumes are created by putting all the devices into a large pool of disk space (the volume group) and then allocating space from the pool to create a logical volume.

Logical volumes have features similar to RAID devices. They can actually be built on top of a RAID device. This would give the logical volume the redundancy of a RAID device with the scalability of LVM.

LVM has better scalability than RAID: logical volumes can easily be resized; i.e., enlarged or shrunk, as needs require. If more space is needed, additional devices can be added to the logical volume at any time. 


23.5. Volumes and Volume Groups

Partitions are converted to physical volumes and multiple physical volumes are grouped into volume groups; there can be more than one volume group on the system.

Space in the volume group is divided into extents; these are 4 MB in size by default, but the size can easily be changed when being allocated.

There are a number of command line utilities used to create and manipulate volume groups, whose name always start with vg including:

    vgcreate:  Creates volume groups.
    vgextend:  Adds to volume groups.
    vgreduce:  Shrinks volume groups.

Utilities that manipulate what physical partitions enter or leave volume groups start with pv and include:

    pvcreate:  Converts a partition to a physical volume.
    pvdisplay:  Shows the physical volumes being used.
    pvmove:  Moves the data from one physical volume within the volume group to others; this might be required if a disk or partition is being removed for some reason. It would then be followed by:
    pvremove:  Remove a partition from a physical volume.

Typing man lvm will give a full list of LVM utilities.

23.6. Logical Volumes Utilities

There are a number of utilities that manipulate logical volumes. Unsurprisingly, they all begin with lv. We will discuss the most commonly used ones, but a short list can be obtained as in the screenshot provided.

Note:

    These utilities are in /sbin, not in /usr/sbin, as they may be needed either for boot or repair and recovery.
    Most of them are symbolically linked to lvm, a Swiss army knife program that does all the work, but figures out what is being asked to do based on the name it is invoked with. This is also true for most of the pv* and vg* utilities, as you can verify easily enough.

23.7.a. Creating Logical Volumes I

lvcreate allocates logical volumes from within volume groups. The size can be specified either in bytes or number of extents (remember, they are 4 MB by default). Names can be anything desired.

lvdisplay reports on available logical volumes.

Filesystems are placed in logical volumes and are formatted with mkfs as usual.

Starting with possibly creating a new volume group, the steps involved in setting up and using a new logical volume are:

    Create partitions on disk drives (type 8e in fdisk) .
    Create physical volumes from the partitions.
    Create the volume group.
    Allocate logical volumes from the volume group.
    Format the logical volumes.
    Mount the logical volumes (also update /etc/fstab as needed).


23.7.b. Creating Logical Volumes II

For example, assuming one has already created partitions /dev/sdb1 and /dev/sdc1 and given them type 8e:

$ sudo pvcreate /dev/sdb1

$ sudo pvcreate /dev/sdc1

$ sudo vgcreate -s 16M vg /dev/sdb1

$ sudo vgextend vg /dev/sdc1

$ sudo lvcreate -L 50G -n mylvm vg

$ sudo mkfs -t ext4 /dev/vg/mylvm

$ mkdir /mylvm

$ sudo mount /dev/vg/mylvm /mylvm

Be sure to add the line

/dev/vg/mylvm /mylvm ext4 defaults 0 0

to /etc/fstab to make this a persistent mount.


23.8. Displaying Logical Volumes

In order to display information about LVM the following command line programs are available:

    pvdisplay shows physical volumes as in
    $ sudo pvdisplay
    $ sudo pvdisplay /dev/sda5
    vgdisplay shows volume groups as in
    $ sudo vgdisplay
    $ sudo vgdisplay /dev/vg0
    lvdisplay shows logical volumes as in
    $ sudo lvdisplay
    $ sudo lvdisplay /dev/vg0/lvm1

Without arguments, these utilities will display all physical volumes, volume groups, or logical volumes.

23.9. Resizing Logical Volumes

 One great advantage of using LVM is that it is easy and quick to change the size of a logical volume, especially when compared with trying to do this with a physical partition that already contains a filesystem.

When doing this, extents can be added or subtracted from the logical volume, and they can come from anywhere in the volume group; they need not be from physically contiguous sections of the disk.

If the volume contains a filesystem, expanding or shrinking it is an entirely different operation than changing the size of the volume:

    When expanding a logical volume with a filesystem, one must first expand the volume and then expand the filesystem.\u200b
    When shrinking a logical volume with a filesystem, one must first shrink the filesystem and then shrink the volume.

The filesystem cannot be mounted when being shrunk. However, some filesystems permit expansion while they are mounted.

The utilities which change the filesystem size are obviously filesystem dependent; for ext4 the program is resize2fs.

23.10. Examples of Resizing

To grow a logical volume with an ext4 filesystem:

$ sudo lvextend -L +500M /dev/vg/mylvm

$ sudo resize2fs /dev/vg/mylvm

where the plus sign indicates adding space.

To shrink the filesystem:

$ sudo umount /mylvm

$ sudo fsck -f /dev/vg/mylvm

$ sudo resize2fs /dev/vg/mylvm 200M

$ sudo lvreduce  -L 200M /dev/vg/mylvm

$ sudo mount /dev/vg/mylvm

It turns out that if you have a recent version of the lvm utilities you can do these operations in one step instead of two, using the -r option, as in:

$ sudo

$ sudo lvextend -r -L +100M /dev/vg/mylvm

$ sudo lvreduce -r -L -100M /dev/vg/mylvm

where the quantities use plus and minus signs to indicate the change required. This uses the underlying fsadm utility, which can resize any type of filesystem for which you have support. It would be a good idea to read the man page for fsadm.

You can also reduce a volume group, as in:

$ sudo pvmove /dev/sdc1

$ sudo vgreduce vg /dev/sdc1

23.11. LVM Snapshots

LVM Snapshots create an exact copy of an existing logical volume.

They are useful for backups, application testing, and deploying VMs (Virtual Machines). The original state of the snapshot is kept as the block map.

Snapshots only use space for storing deltas:

    When the original logical volume changes, original data blocks are copied to the snapshot.
    If data is added to snapshot, it is stored only there.

To create a snapshot of an existing logical volume:

$ sudo lvcreate -l 128 -s -n mysnap /dev/vg/mylvm

To then make a mount point and mount the snapshot:

$ mkdir /mysnap
$ mount -o ro /dev/vg/mysnap /mysnap

To use the snapshot and to remove the snapshot:

$ sudo umount /mysnap
$ sudo lvremove /dev/vg/mysnap

Always be sure to remove the snapshot when you are through with it. If you do not remove the snapshot and it fills up because of changes, it will be automatically disabled. A snapshot with the size of the original will never overflow.

24.1. RAID - Introduction

The use of RAID spreads I/O activity over multiple physical disks, rather than just one. Its purpose is to enhance data integrity and recoverability in case of failure, as well as to boost performance when used with modern storage devices. There are a number of different RAID levels which vary in their relative strengths in safety, performance, complexity and cost.

24.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain the concept of RAID.
    Summarize RAID levels.
    Configure a RAID device using the essential steps provided.
    Monitor RAID devices in multiple ways.
    Use hot spares.

24.3.a. RAID I

 RAID (Redundant Array of Independent Disks) spreads I/O over multiple disks. This can really increase performance in modern disk controller interfaces, such as SCSI, which can perform the work in parallel efficiently.

RAID can be implemented either in software (it is a mature part of the Linux kernel), or in hardware. If your hardware RAID is known to be of good quality, it should be more efficient than using software RAID. With the hardware implementation, the operating system is actually not directly aware of using RAID; it is transparent. For example, three 512GB hard drives (two for data, one for parity) configured with RAID-5 will just look like a single 1TB disk.

However, one disadvantage of using hardware RAID is that if the disk controller fails, it must be replaced by a compatible controller, which may not be easy to obtain. When using software RAID, the same disks can be attached to and work with any disk controller. Such considerations are more likely to be relevant for low and mid-range hardware.

Three essential features of RAID are:

    mirroring: writing the same data to more than one disk
    striping: splitting of data to more than one disk
    parity: extra data is stored to allow problem detection and repair, yielding fault tolerance.

Thus, use of RAID can improve both performance and reliability. 


24.3.b. RAID II

One of the main purposes of a RAID device is to create a filesystem which spans more than one disk. This allows us to create filesystems which are larger than any one drive. RAID devices are typically created by combining partitions from several disks together.

Another advantage of RAID devices is the ability to provide better performance, redundancy, or both. Striping provides better performance by spreading the information over multiple devices so simultaneous writes are possible. Mirroring writes the same information to multiple drives, giving better redundancy.

mdadm is used to create and manage RAID devices.

Once created, the array name, /dev/mdX, can be used just like any other device, such as /dev/sda1.

24.4. RAID Levels

There are a number of RAID specifications of increasing complexity and use. The most commonly used are levels 0, 1, and 5.

    RAID 0 uses only striping. Data is spread across multiple disks. However, in spite of the name, there is no redundancy and there is no stability or recovery capabilities. In fact, if any disk fails, data will be lost. But performance can be improved significantly because of parallelization of I/O tasks.
    RAID 1 uses only mirroring; each disk has a duplicate. This is good for recovery. At least two disks are required.
    RAID 5 uses a rotating parity stripe; a single drive failure will cause no loss of data, only a performance drop. There must be at least 3 disks.
    RAID 6 has striped disks with dual parity; it can handle loss of two disks, and requires at least 4 disks. Because RAID 5 can impose significant stress on disks, which can lead to failures during recovery procedures, RAID 6 has become more important. 
    RAID 10 is a mirrored and striped data set. At least 4 drives are needed.

As a general rule, adding more disks improves performance.

24.5.a. Software RAID Configuration I

The essential steps in configuring a software RAID device are:

    Create partitions on each disk (type fd in fdisk)
    Create RAID device with mdadm
    Format RAID device 
    Add device to /etc/fstab
    Mount RAID device
    Capture RAID details to ensure persistence.

The command:

$ sudo mdadm -S

can be used to stop RAID.

24.5.b. Software RAID Configuration II

For example:

First, create two partitions of type fd on disks sdb and sdc (say /dev/sdbX and /dev/sdcX) by running fdisk on each:

$ sudo fdisk /dev/sdb

$ sudo fdisk /dev/sdc

Then, set up the array, format it, add to the configuration and mount it:

$ sudo mdadm --create /dev/md0 --level=1 --raid-disks=2 /dev/sdbX /dev/sdcX

$ sudo mkfs.ext4 /dev/md0

$ sudo bash -c "mdadm --detail --scan >> /etc/mdadm.conf"

$ sudo mkdir /myraid

$ sudo mount /dev/md0 /myraid

Be sure to add a line in /etc/fstab for the mount point:

/dev/md0  /myraid  ext4  defaults 0 2

24.5.c. Software RAID Configuration III

You can examine /proc/mdstat to see the RAID status, as in:

$ cat /proc/mdstat

         Personalities : [raid1]

    md0 : active raid1 sdb8[1] sdc7[0]

    ---------- 521984 blocks [2/2]

    unused devices: <none>

You can use:

$ sudo mdadm -S /dev/md0

to stop the RAID device.

24.6.Monitoring RAIDS

You can monitor RAID devices multiple ways, as in:

$ sudo mdadm --detail /dev/md0

$ cat /proc/mdstat

One can also use mdmonitor, which requires configuring /etc/mdadm.conf. The command:

$ sudo mdadm --detail /dev/mdX

will show the current status of the RAID device /dev/mdX. Another way to do this is to examine the /proc filesystem:

$ cat /proc/mdstat

It will show the status of all RAID devices on the system.

You can also use the mdmonitor service by editing /etc/mdadm.conf and adding a line like:

 MAILADDR eddie@haskell.com

so that it notifies you with email sent to eddie@haskell.com when a problem occurs with a RAID device, such as when any of the arrays fail to start or fall into a degraded state. You turn it on with:

$ sudo systemctl start mdmonitor

and make sure it starts at boot with:

$ sudo systemctl enable mdmonitor

(Note: On Ubuntu systems, the service is called mdadm rather than mdmonitor.)

24.7. RAID Hoe Spares

One of the important things that RAID provides is redundancy. To help ensure any reduction in that redundancy is fixed as quick as possible, a hot spare can be used.

To create a hot spare when creating the RAID array:

$ sudo mdadm --create /dev/md0 -l 5 -n3 -x 1 /dev/sda8 /dev/sda9 /dev/sda10 /dev/sda11

The -x 1 switch tells mdadm to use one spare device. Note that a hot spare can also be added at a later time.

The command:

$ sudo mdadm --fail /dev/md0 /dev/sdb2

will test the redundancy and hot spare of your array.

To restore the tested drive, or a new drive in a legitimate failure situation, first remove the "faulty" member, then add the "new" member, as in:

$ sudo mdadm --remove /dev/md0 /dev/sdb2

$ sudo mdadm --add /dev/md0 /dev/sde2

25.1. Kernel Services and Configuration - Introduction

video

25.2. Learning Objectives

By the end of this chapter, you should be able to:

    Grasp the main responsibilities the kernel must fulfill and how it achieves them.
    Explain what parameters can be set on the kernel command line and how to make them effective either for just one system boot, or persistently.
    Know where to find detailed documentation on these parameters.
    Know how to use sysctl to set kernel parameters either after the system starts, or persistently across system reboots. 

25.3. Kernel Overview

Narrowly defined, Linux is only the kernel of the operating system, which includes many other components, such as libraries and applications that interact with the kernel.

The kernel is the essential central component that connects the hardware to the software and manages system resources, such as memory and CPU time allocation among competing applications and services. It handles all connected devices using device drivers, and makes the devices available for operating system use.

A system running only a kernel has rather limited functionality. It will be found only in dedicated and focused embedded devices

25.4. Main Kernel Tasks

The main responsibilities of the kernel include:

    System initialization and boot up
    Process scheduling
    Memory management
    Controlling access to hardware
    I/O (Input/Output) between applications and storage devices
    Implementation of local and network filesystems
    Security control, both locally (such as filesystem permissions) and over the network
    Networking control.

25.5. Kernel Command Line

Various parameters are passed to the system at boot on the kernel command line. Normally, these are on the kernel (or linux16) line in the GRUB configuration file, but can be modified at boot.

For GRUB Version 2, a sample kernel command line might look like:

linux16 /boot/vmlinuz-3.19.1.0 \

        root=UUID=178d0092-4154-4688-af24-cda272265e08 ro \

                     vconsole.keymap=us crashkernel=auto  \

        vconsole.font=latarcyrheb-sun16 rhgb quiet LANG=en_US.UTF-8 

or, with a more minimal set of options:

linux16 /boot/vmlinuz-4.7.3 root=LABEL=RHEL7 ro rhgb quiet

and would be found in /boot/grub2/grub.cfg.            

Everything after the vmlinuz file specified is an option. Any options not understood by the kernel will be passed to init (pid = 1), the first user process to be run on the system.                                                                               

You should not edit this file directly, but modify the relevant files under /etc.

In the examples provided above, long lines were broken up for display, but they are each all one long line. To see what command line a system was booted with type:

$ cat /proc/cmdline

BOOT_IMAGE=/boot/vmlinuz-4.7.3 root=LABEL=RHEL7

25.6.a. Kernel Boot parameters I

There is a rather surprisingly long list of available kernel parameters. Detailed documentation can be found:

    In the kernel source in the file Documentation/kernel-parameters.txt.
    Online, at https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html.
    On the system in the kernel documentation package provided by most distributions with a name like kernel-doc or linux-doc.
    By typing man bootparam.

Parameters can be specified simply as a value given as an argument, or in the form param=value, where the given value can be a string, integer, array of integers, etc., as explained in the documentation file.

vmlinuz root=/dev/sda6 ..... noapic .... crashkernel=256M

Kernel options are placed at the end of the kernel line and are separated by spaces. Examples were given on the previous page


25.6.b. Kernel Boot parameters II

Below you can see an explanation of some of the boot parameters we have displayed previously:

    root: root filesystem
    ro: mounts root device read-only on boot
    vconsole.keymap: which keyboard to use on the console
    crashkernel: how much memory to set aside for kernel crashdumps
    vconsole.font: which font to use on the console
    rhgb: for graphical boot 
    quiet: disables most log messages.
    LANG: is the system language.

By convention, there should be no intentionally hidden or secret parameters. They should all be explained in the documentation and patches to the kernel source with new parameters should always include patches to the documentation file.


25.7.a. sysctl I

The sysctl interface can be used to read and tune kernel parameters at run time. The screenshot shows you how the current values can be displayed by doing:

$ sysctl -a

Each value corresponds to a particular pseudofile residing under /proc/sys, with directory slashes being replaced by dots. For example, the following two statements are equivalent:

$ sudo sh -c 'echo 1 > /proc/sys/net/ipv4/ip_forward'

$ sudo sysctl net.ipv4.ip_forward=1

where the second form is used to set a value with the sysctl command line interface. One cannot leave spaces around the = sign in this command. Note that in the first form, we cannot just use a simple sudo with echo; the command must be done in the complicated way shown, or executed as root.


25.7.b. sysctl II

Browsing through the pseudofiles under /proc/sys will render the same information as sysctl -a. You can get full details on how to use sysctl by doing man 8 sysctl. To get information about using the sysctl() function from programs to do the same operations, do man 2 sysctl.

If settings are placed in /etc/sysctl.conf (see man sysctl.conf for details) settings can be fixed at boot time.

Note that typing 

$ sudo sysctl -p

effectuates immediate digestion of the file, setting all parameters as found; this is also part of the boot process. 

On some recent distributions based on systemd (such as RHEL 7), the actual settings file is now /usr/lib/sysctl.d/00-system, but the original file is still supported, as it is self-documented in that file.

26.1. Kernel Modules - Introduction

The Linux kernel makes extensive use of modules, which contain important software that can be loaded and unloaded as needed after the system starts. Many modules incorporate device drivers to control hardware either inside the system or attached peripherally. Other modules can control network protocols, support different filesystem types and many other purposes. Parameters can be specified when loading modules to control their behavior. The end result is great flexibility and agility in responding to changing conditions and needs.


26.2. Learning Objectives

By the end of this chapter, you should be able to:

    List the advantages of utilizing kernel modules.
    Use insmod, rmmod and modprobe to load and unload kernel modules.
    Know how to use modinfo to find out information about kernel modules. 


26.3. Advantages of Kernel Modules

Many facilities in the Linux kernel are designed to be built-in to the kernel when it is initially loaded, or to be added (or removed) later as modules as necessary. Indeed, all but the most central kernel components are integrated in such a fashion.

Such modules may or may not be device drivers. For example, they may implement a certain network protocol or filesystem rather than drive a hardware or software device. Even in cases where the functionality will virtually always be needed, incorporation of the ability to load and unload as a module facilitates development, as kernel reboots are not required to test changes.

Even with the widespread usage of kernel modules, Linux retains a monolithic kernel architecture, rather than a microkernel one. This is because once a module is loaded, it becomes a fully functional part of the kernel, with few restrictions. It communicates with all kernel sub-systems primarily through shared resources, such as memory and locks, rather than through message passing as might a microkernel.

Linux is hardly the only operating system to use modules; Solaris does it as well, as does AIX, which terms them kernel extensions. However, Linux uses them in a particularly robust fashion.

26.4. Modules Utilities

There are a number of utility programs that are used with kernel modules:

    lsmod: List loaded modules.
    insmod: Directly load modules.
    rmmod: Directly remove modules.
    modprobe: Load or unload modules, using a pre-built module database with dependency information.
    depmod: Rebuild the module dependency database; needed by modprobe and modinfo.
    modinfo: Display information about a module.


26.5.a. Modules Loading and Unloading I

Module loading and unloading must be done as the root user. If the full path name is known, one can always load the module directly with:

$ sudo /sbin/insmod <pathto>/module_name.ko

The normal filesystem location for kernel modules is under the directory tree at /lib/modules/<kernel-version>.  A kernel module always has a file extension of .ko, as in e1000e.ko, ext4.ko, or usbserial.ko.

Kernel modules are kernel version specific and must match the running kernel or they cannot be loaded. They must be compiled either when the kernel itself is compiled, or later, on a system which retains enough of the kernel source and compilation configuration to do this properly.


While the module is loaded, you can always see its status with lsmod, as in the screenshot provided.

Module removal can always be done directly with:

$ sudo /sbin/rmmod module_name

Note that it is not necessary to supply either the full path name or the .ko extension when removing a module.


26.6. modprobe

In most circumstances, modules are not loaded and unloaded with insmod and rmmod. Rather, one uses modprobe, as in:

$ sudo /sbin/modprobe module_name

$ sudo /sbin/modprobe -r module_name

with the second form being used for removal. For modprobe to work, the modules must be installed in the proper location, generally under /lib/modules/$(uname  -r) where $(uname  -r) gives the current kernel version, such as 4.14.2.


26.7. Some Considerations with Modules

There are some important things to keep in mind when loading and unloading modules:

    It is impossible to unload a module being used by one or more other modules, which one can ascertain from the lsmod listing.
    It is impossible to unload a module that is being used by one or more processes, which can also be seen from the lsmod listing. However, there are modules which do not keep track of this reference count, such as network device driver modules, as it would make it too difficult to temporarily replace a module without shutting down and restarting much of the whole network stack.
    When a module is loaded with modprobe, the system will automatically load any other modules that need to be loaded first.
    When a module is unloaded with modprobe  -r, the system will automatically unload any other modules being used by the module, if they are not being simultaneously used by any other loaded modules.


26.8. modinfo

modinfo can be used to find out information about kernel modules (whether or not they are currently loaded), as in:

$ /sbin/modinfo my_module

$ /sbin/modinfo <pathto>/my_module.ko

You can see an example in the screenshot here, which displays information about version, file name, which hardware devices the device driver module can handle, and what parameters can be supplied on loading.

Much information about modules can also be seen in the /sys pseudo-filesystem directory tree; in our example, one would look under /sys/module/e1000 and some, if not all parameters, can be read and/or written under /sys/module/e1000/parameters. We will show how to set them next.


26.9. Module Parameters

Many modules can be loaded while specifying parameter values, such as in:

$ sudo /sbin/insmod <pathto>/e1000e.ko debug=2 copybreak=256

or, for a module already in the proper system location, it is easier with:

$ sudo /sbin/modprobe e1000e debug=2 copybreak=256


26.10. Kernel Module Configuration

Files in the /etc/modprobe.d directory control some parameters that come into play when loading with modprobe. These parameters include module name aliases and automatically supplied options. One can also blacklist specific modules to avoid them being loaded. 

Settings apply to modules as they are loaded or unloaded, and configurations can be changed as needs change.

The format of files in /etc/modprobe.d is simple: one command per line, with blank lines and lines starting with # ignored (useful for adding comments). A backslash at the end of a line causes it to continue on the next line, which makes the file a bit neater.

27.1 Devices and udev - Introduction

Linux uses udev, an intelligent apparatus for discovering hardware and peripheral devices both during system boot, and later when they are connected to the system. Device Nodes are created automatically and then used by applications and operating system subsystems to communicate with and transfer data to and from devices. System administrators can control how udev operates and craft special udev rules to assure desired behavior results

27.2 Learning Objectives:

By the end of this chapter, you should be able to:

    - Explain the role of device nodes and how they use major and minor numbers.
    - Understand the need for the udev method and list its key components.
    - Describe how the udev device manager functions.
    - Identify udev rule files and learn how to create custom rules.

27.3. Device Nodes

Character and block devices have filesystem entries associated with them; network devices in Linux do not. These device nodes can be used by programs to communicate with devices, using normal I/O system calls such as open(), close(), read(), and write(). On the other hand, network devices work by transmitting and receiving packets, which must be constructed by breaking up streams of data, or reassembled into streams when received.

A device driver may manage multiple device nodes, which are normally placed in the /dev directory:

$ ls -l /dev
total 0
crw------- 1 coop audio 14, 4 Jul 9 01:54 audio
crw------- 1 root root 10, 62 Jul 9 01:54 autofs
lrwxrwxrwx 1 root root 4 Jul 9 01:54 cdrom -> scd0
lrwxrwxrwx 1 root root 4 Jul 9 01:54 cdrw -> scd0
crw------- 1 coop root 5, 1 Jul 9 06:54 console
....
lrwxrwxrwx 1 root root 4 Jul 9 01:54 dvd -> scd0
lrwxrwxrwx 1 root root 4 Jul 9 01:54 dvdwriter -> scd0
crw------- 1 root root 10, 228 Jul 9 01:54 hpet
crw-r----- 1 root kmem 1, 2 Jul 9 01:54 kmem
crw------- 1 root root 1, 11 Jul 9 01:54 kmsg
crw-r----- 1 root kmem 1, 1 Jul 9 01:54 mem
crwxrwxrwx 1 root root 1, 3 Jul 9 01:54 null
crw-rw---- 1 root root 10, 144 Jul 9 01:54 nvram
brw------- 1 coop disk 11, 0 Jul 9 01:54 scd0
....
brw-r----- 1 root disk 8, 0 Jul 9 01:53 sda
brw-r----- 1 root disk 8, 1 Jul 9 01:53 sda1

brw-r----- 1 root disk 8, 2 Jul 9 06:54 sda2
....
brw-r----- 1 root disk 8, 16 Jul 9 01:53 sdb
brw-r----- 1 root disk 8, 17 Jul 9 01:53 sdb1
brw-r----- 1 root disk 8, 18 Jul 9 01:53 sdb2
....
crw------- 1 coop audio 14, 1 Jul 9 01:54 sequencer
crw------- 1 coop audio 14, 8 Jul 9 01:54 sequencer2
crw-rw-rw- 1 root tty 5, 0 Jul 9 01:54 tty
crw-rw---- 1 root root 4, 0 Jul 9 14:54 tty0
crw------- 1 root root 4, 1 Jul 9 06:54 tty1
cr--r--r-- 1 root root 1, 9 Jul 9 01:53 urandom
....
crw-rw-rw- 1 root root 1, 5 Jul 9 01:54 zero

Device nodes can be created with:

$ sudo mknod [-m mode] /dev/name <type> <major> <minor>

e.g., mknod -m 666 /dev/mycdrv c 254 1

Device Nodes:

  |------------------------------------------------------------------------------------------|
  |                                     Application                                          |
  |                                                                                          |
  --------------------------------------------------------------------------------------------
                                / \                                         / \
                                 |                                           |
                                 |                                           |
                                 V                                           |
  |------------------------------------------------------------------|       |
  |                 Virtual File System                              |       |
  |------------------------------------------------------------------|       |
         / \                   / \         / \                               |
          |                     |           |                                |
          |                     |           |                                |
          V                     V           |                                |
  |---------------|      |---------------|  |      |----------------|        |
  | character node|      |  block node   |<-|      |   socket       |        |
  |---------------|      |---------------|         |----------------|        |
        / \                    / \                             / \           |
         |                      |                               |            |
         |                      |                               |            |
         v                      V                               V            v
  |-----------------|      |------------------|             |-----------------------------|
  | character driver|      |    file system   |             |     TCP/IP Appletalk, etc   |
  |-----------------|      |------------------|             |-----------------------------|
         / \                     / \                                      / \
          |                       |                                        |
          |                       |                                        |
          |                       v                                        v  
          |                 |------------------|             |-----------------------------|
          |                 |  block driver    |             |    network driver           |
          |                 |------------------|             |-----------------------------|
          |                        / \                                    / \
          |                         |                                      |
          |                         |                                      |
          v                         v                                      v
  |----------------------------------------------------------------------------------------------|
  |                                        Hardware                                              |
  |                                                                                              |
  ------------------------------------------------------------------------------------------------


27.4. Major and Minor Numbers

The major and minor numbers identify the driver associated with the device, with the driver uniquely reserving a group of numbers. In most cases (but not all), device nodes of the same type (block or character) with the same major number use the same driver.

If you list some device nodes, as in:

$ ls -l /dev/sda*
brw-rw---- 1 root disk 8,  0 Dec 29 06:40 /dev/sda
brw-rw---- 1 root disk 8,  1 Dec 29 06:40 /dev/sda1
brw-rw---- 1 root disk 8,  2 Dec 29 06:40 /dev/sda2
.......

The major and minor numbers appear in the same place that file size would when looking at a normal file; in the above example as 8, 1, etc. While normal users will probably never need to refer explicitly to major and minor numbers and will refer to devices by name, system administrators may have to untangle them from time to time if the system gets confused about devices, or has some hardware added at runtime.

The minor number is used only by the device driver to differentiate between the different devices it may control, or how they are used. These may either be different instances of the same kind of device, (such as the first and second sound card, or hard disk partition) or different modes of operation of a given device (such as different density floppy drive media).

Device numbers have meaning in user-space as well. Two system calls, mknod() and stat(), return information about major and minor numbers.

27.5. udev

The methods of managing device nodes became clumsy and difficult as Linux evolved. The number of device nodes lying in /dev and its subdirectories reached numbers in the 15,000 - 20,000 range in most installations during the 2.4 kernel version series. Nodes for all kinds of devices which would never be used on most installations were still created by default, as distributors could never be sure exactly which hardware would be present on a system.

Of course many developers and system administrators trimmed the list to what was actually needed, especially in embedded configurations, but this was essentially a manual and potentially error-prone task.

Note that, while device nodes are not normal files and don't take up significant space on the filesystem, having huge directories slowed down access to device nodes, especially upon first usage. Furthermore, exhaustion of available major and minor numbers required a more modern and dynamic approach to the creation and maintenance of device nodes. Ideally, one would like to register devices by name. However, major and minor numbers cannot be gotten rid of altogether, as the POSIX standard requires them. (POSIX is an acronym for Portable Operating System Interface, a family of standards designed to ensure compatibility between different operating systems.)

The udev method creates device nodes on the fly as they are needed. There is no need to maintain a ton of device nodes that will never be used. The u in udev stands for user, and indicates that most of the work of creating, removing, and modifying devices nodes is done in user-space.

udev handles the dynamical generation of device nodes and it evolved to replace earlier mechanisms such as devfs and hotplug. One nice feature is the support of persistent device naming; names need not depend on the order of device connection or plugging in. Such behavior is controlled by specification of udev rules.

27.6. udev Components

udev runs as a daemon (either udevd or systemd-udevd) and monitors a netlink socket. When new devices are initialized or removed, the uevent kernel facility sends a message through the socket, which udev receives and takes appropriate action to create or remove device nodes of the right names and properties according to the rules.

The three components of udev are:

    The libudev library which allows access to information about the devices
    The udevd or systemd-udevd daemon that manages the /dev directory
    The udevadm utility for control and diagnostics.

The cleanest way to use udev is to have a pure system; the /dev directory is empty upon the initial kernel boot, and then is populated with device nodes as they are needed. When used this way, one must boot using an initramfs image, which may contain a set of preliminary device nodes, as well as the the udev infrastructure.

27.7. udev and Hotplug

As devices are added or removed from the system, working with the hotplug sub-system, udev acts upon notification of events to create and remove device nodes. The information necessary to create them with the right names, major and minor numbers, permissions, etc., are gathered by examination of information already registered in the sysfs pseudo-filesystem (mounted at /sys) and a set of configuration files.

The main configuration file is /etc/udev/udev.conf. It contains information such as where to place device nodes, default permissions and ownership, etc. By default, rules for device naming are located in the /etc/udev/rules.d and /usr/lib/udev/rules.d directories. By reading the man page for udev one can get a lot of specific information about how to set up rules for common situations.

27.8. The udev Device Manager

When udev receives a message from the kernel about devices being added or removed, it parses the rule-setting files in /etc/udev/rules.d/*.rules and /usr/lib/udev/rules.d/*.rules to see if there are any rules relevant to the device being added or removed.

It then takes appropriate actions including: 

    Device node naming
    Device node and symbolic links creation
    Setting file permissions and ownership for the device node
    Taking other actions to initialize and make device available.

These rules are completely customizable.

27.9. udev Rule Files

udev rules files are located under /etc/udev/rules.d/<rulename>.rules with names like:

    30-usb.rules
    90-mycustom.rules 

By default, when udev reads the rules files it looks for files that have a suffix of .rules. If it finds more than one file, it reads them one by one, lexicographically, i.e., in ascending alphabetical order. The standard rule file name is generally a two digit number followed by a descriptive name (for the rules), followed by the .rules suffix.

                    |-----------------------------------------------|
                    |             Create device node in /dev        |
                    |                                               |
                    |-----------------------------------------------|
                                         / \
                                          |
                                          |
                                          |
                    |------------------------------------------------|
                    |                    udevd                       |
                    |------------------------------------------------|
                         / \                              / \
                          |                                |
                          |                                |
                          |                                |
                          |                                |
                          v                                v
        |----------------------------|                 |---------------------------|
        |     Kernel module          |                 |      Rules database       |
        |                            |                 |                           |
        |----------------------------|                 |---------------------------|

27.10. Creating udev Rules

The format for a udev rule is simple:

<match><op>value [, ...] <assignment><op>value [, ... ]

There are two separate parts defined on a single line:

    The first part consists of one or more match pairs denoted by == .  These try to match a device's attributes and/or characteristics to some value.
    The second part consists of one or more assignment key-value pairs that assign a value to a name, such as a file name, group assignment, even file permissions, etc.

If no matching rule is found, it uses the default device node name and other attributes.

27.11. Some Examples of Rues Files

Here is an example of a rules file for a Fitbit device:

$ cat /usr/lib/udev/rules.d/99-fitbit.rules

SUBSYSTEM=="usb", ATTR{idVendor}=="2687", ATTR{idProduct}=="fb01", SYMLINK+="fitbit", MODE="0666"

Some other examples: 

$ cat /usr/lib/udev/rules.d/98-kexec.rules

SUBSYSTEM=="cpu", ACTION=="online", PROGRAM="/bin/systemctl try-restart kdump.service" SUBSYSTEM=="cpu", ACTION=="offline", PROGRAM="/bin/systemctl try-restart kdump.service" SUBSYSTEM=="memory", ACTION=="add", PROGRAM="/bin/systemctl try-restart kdump.service" SUBSYSTEM=="memory", ACTION=="remove", PROGRAM="/bin/systemctl try-restart kdump.service"

$ cat /usr/lib/udev/rules.d/80-kvm.rules

KERNEL=="kvm", GROUP="kvm", MODE="0666"

$ cat /usr/lib/udev/rules.d/99-fuse.rules

KERNEL=="fuse", MODE="0666",OWNER="root",GROUP="root"

28.1 Virtualization Overview - Introduction

Virtualization entails creating (in software) an abstracted complete machine environment, under which enduser software runs unaware of the physical details of the machine it is is running on.

While there are quite a few approaches to accomplishing this mission, they generally involve a host operating system and filesystem which directly use the hardware. One or more guest systems run on top (or underneath, depending how you look at it) of the host system at a lower level of privilege. Access to hardware such as network adapters is usually done through some kind of virtual device which may access the physical device when required.

There are many uses for virtual machines. Major ones include more efficient use of hardware, software isolation, security, stability, safe development options, and the ability to run multiple operating systems at the same time without rebooting.

28.1. Learning Objectives

By the end of this chapter, you should be able to:

    - Understand the concepts behind virtualization and how it came to be widely used.
    - Understand the roles of hosts and guests.
    - Discuss the difference between emulation and virtualization.
    - Distinguish between the different types of hypervisors.
    - Be familiar with how Linux distributions use and depend on libvirt.
    - Use the qemu hypervisor.
    - Install, use and manage KVM.

28.2. What is virtualization?

In this chapter, we will be concerned with the creation, deployment, and maintenance of Virtual Machines (VMs).

Virtual Machines are a virtualized instance of an entire operating system, and may fulfill the role of a server or a desktop/workstation.\u200b

The outside world sees the VM as if it were an actual physical machine, present somewhere on the network. Applications running in the VM are generally unaware of their non-physical environment.\u200b

Other kinds of virtualization include:\u200b

    Network
    The details of the actual physical network, such as the type of hardware, routers, etc. are abstracted and need not be known by software running on it and configuring it.\u200b
    Storage
    Multiple network storage devices are configured to look like one big storage unit, such as a disk.\u200b
    Application
    An application is isolated into a standalone format, such as a container, which will be discussed later.\u200b

There are differences between physical and virtual machines which are not always easy to ignore. For example, performance tuning at a low level needs to be done (separately) on both the VM and the physical machine residing underneath it.

28.3. VIrtualization History

Virtualization\u200b has a long proud history. It was implemented originally on mainframes decades ago:

    Enables better hardware utilization
    Operating systems often progress more quickly than hardware
    It is microcode driven
    Not particularly user-friendly.

Later on, virtualization technology migrated to PCs and workstations:

    Initially, it was done using Emulation
    CPUs enhanced to support virtualization led to a boost in performance, easier configuration, and more flexibility in VM installation and migration.

From early mainframes to mini-computers, virtualization has been used for expanding limits, debugging and administration enhancements.

Today, virtualization can be found everywhere in many forms. Each of the different forms and implementations that are available provide particular advantages.\u200b

28.5. Hosts and Guests

A host is the underlying physical operating system managing one or more virtual machines.

A guest is the VM which is an instance of a complete operating system, running one or more applications. Sometimes, a guest is also called a client. In most cases, the guest should not care what host it is running on and can be migrated from one host to another, sometimes while actually running.

In fact, it is possible to convert physical machines into virtual ones, by copying the entire contents into a VM. Specialized software utilities can make this easier.

Low-level performance tuning on areas such as CPU utilization, networking throughput, memory utilization, is often best done on the host, as the guest may have only simulated qualities not directly useful.

Application tuning will be done mostly on the guest.

28.6. Emulators

The first implementations of virtualization on the PC architecture were through the use of Emulators. An application running on the current operating system would appear to another OS as a specific hardware environment. Emulators generally do not require special hardware to operate.

Qemu is one such emulator.


    |-----------| |----------| |----------|
    |    vm     | |    vm    | |   vm     |
    |-----------| |----------| |----------|

    |-------------------------------------|
    |      Dynamic Library Transition     |
    |-------------------------------------|
    
    |-------------------------------------|
    |      Private Operating System       |
    |-------------------------------------|
   
    |-------------------------------------|
    |                Hardware             |
    |-------------------------------------|

                      Emulator


28.7. Emulation vs Virtualization

An Emulator runs completely in software. Hardware constructs are replaced by software. It is useful for running virtual machines on different architectures, such as running a pretend ARM guest machine on an X86 host. Emulation is often used for developing an operating system for a new CPU, even before hardware is available. Performance is relatively slow.


28.8. Types of Virtualization Hypervisors

 The host system, besides functioning normally with respect to software that it runs, also acts as the hypervisor that initiates, terminates, and manages guests. It also called Virtual Machine Monitor (VMM).

There are two basic methods of virtualization:

    Hardware virtualization (also known as Full Virtualization)
    The guest system runs without being aware it is running as a virtualized guest, and does not require modifications to be run in this fashion. \u200b
    Para-virtualization
    The guest system is aware it is running in a virtualized environment, and has been modified specifically to work with it. 

Recent CPUs from Intel and AMD incorporate virtualization extensions to the x86 architecture that allow the hypervisor to run fully virtualized (i.e., unmodified) guest operating systems with only minor performance penalties.

The Intel extension (Intel Virtualization Technology), usually abbreviated as VT, IVT, VT-32 or VT-64, is also known under the development code name of Vanderpool. It has been available since the spring of 2005.

The AMD extension is usually called AMD-V and is still sometimes referred to by the development code name of Pacifica.

For a detailed explanation and comparison of how these two extensions work, see http://lwn.net/Articles/182080/.

You can check directly if your CPU supports hardware virtualization extensions by looking at /proc/cpuinfo; if you have an IVT-capable chip, you will see vmx in the flags field, and, if you have an AMD-V capable chip, you will see svm in the same field. You may also have to ensure the virtualization capability is turned on in your CMOS.

While the choice of operating systems tends to be more limited for para-virtualized guests, originally they tended to run more efficiently than fully virtualized guests. Recent advances in virtualization techniques have narrowed or eliminated such advantages, and the wider availability of the hardware support needed for full virtualization has made para-virtualization less advantageous and less popular. 

28.9. External and in-Kernel Hypervisors

The hypervisor can be:

    External to the host operating system kernel: VMware
    Internal to the host operating system kernel: KVM.

In this course, we will concentrate on KVM, as it is all open source, and requires no external third party hypervisor program.\u200b

28.10. Dedicated Hypervisor

Going past Emulation, the merging of the hypervisor program into a specially-designed lightweight kernel was the next step in the Virtualization deployment.

VMware ESX (and related friends) is an example of a hypervisor embedded into an operating system.


     |-----------|  |--------------|  |---------|
     |           |  |              |  |         |
     |  VM       |  |     OS       |  |   Vir   |
     | Control   |  |     Not      |  |  Aware  |         
     | Interface |  |    Virt      |  |    OS   |                        
     |    for    |  |    Aware     |  |         |
     | hypervisor|  |--------------|  |         |
     |           |  |--------------|  |         |
     |           |  |              |  |         |
     |           |  |    Para      |  |         |
     |           |  |virtualization|  |         |
     |              |   layer      |  |         |
     |           |  |--------------|  |---------|
     |           |-------------------------------|
     |-----------|                               |
     |                                           | 
     |     Hypervisor Operating System           |
     |                                           | 
     |-------------------------------------------|

     |-------------------------------------------|
     |              Hardware                     |
     |                                           | 
     |-------------------------------------------|


                  Dedicated Hypervisor


28.11. Hypervisor in the Kernel

The KVM project added hypervisor capabilities into the Linux kernel. This leveraged the facilities of the kernel and enabled the kernel to be a hypervisor.

As we have discussed, specific CPU chip functions and facilities were required and deployed for this type of virtualization.\u200b

   |---------|   |---------|                                  
   | app1    |   | app2    |                                                 
   |         |   |         |                                                       
   |---------|   |---------|                                             
   |---------|   |---------|                                            
   |         |   |         |                                                       
   |bin/libs |   |bin/libs |                         
   |---------|   |---------|                              
   |---------|   |---------|                          
   |  OS     |   |  OS     |                          
   | Image1  |   | Image2  |                      
   |         |   |         |            
   |---------|   |---------|

   |-------------------------|
   |  KVM Hypervisor         |
   |                         |
   |-------------------------|

   |-------------------------|
   |  Operating System       |
   |                         |
   |-------------------------|                                                       
  
   |-------------------------|
   |      Hardware           |
   |          |--------------|
   |          |Virtualization|
   |          | support      |
   |-------------------------|



     Hypervisor in the Kernel

28.12. libvirt

The libvirt project is a toolkit to interact with virtualization technologies. It provides management for virtual machines, virtual networks, and storage, and is available on all enterprise Linux distributions.

Many application programs interface with libvirt, and some of the most common ones are virt-manager, virt-viewer, virt-install, virsh.

The complete list of currently supported hypervisors can be found at http://www.libvirt.org:

    QEMU/KVM
    Xen
    Oracle VirtualBox
    VMware ESX
    VMware Workstation/Player
    Microsoft Hyper-V
    IBM PowerVM (phyp)
    OpenVZ
    UML (User Mode Linux)
    LXC (Linux Containers)
    Virtuozzo
    Bhyve (The BSD Hypervisor)
    Test (Used for testing).

28.13. Programs Using libvirt

There are many utilities using libvirt. The exact list will depend on your Linux distribution. A full list can be found at http://www.libvirt.org/app.html.

In this course, we will work through the use of the robust GUI, virt-manager, rather than make much use of command line utilities, which lead to more flexibility, as well as use on non-graphical servers.

28.14. What is QEMU?

QEMU stands for Quick EMUlator. It was originally written by Fabrice Bellard in 2002. (Bellard is also known for feats such as holding, at one point, the world record for calculating \u03c0, reaching 2.7 trillion digits.)

QEMU is a hypervisor that performs hardware emulation, or virtualization. It emulates CPUs by dynamically translating binary instructions between the host architecture and the emulated one.

The host and the emulated architectures may be different, or the same. There are numerous choices for both host and guest operating systems.

QEMU can also be used to emulate just particular applications, not entire operating systems.

By itself, QEMU is much slower than the host machine. But, it can be used together with KVM (Kernel Virtual Machine) to reach speeds close to those of the native host.

Guest operating systems do not require rewriting to run under QEMU. QEMU can save, pause, and restore a virtual machine at any time. QEMU is a free software licensed under the GPL.

QEMU has the capability of supporting many architectures, including: IA-32 (i386), x86-64, MIPS, SPARC, ARM, SH4, PowerPC, CRIS, MicroBlaze, etc.

The cross-compilation abilities of QEMU make it extremely useful when doing development for embedded processors.

In fact, QEMU has often been used to develop processors which have either not yet been physically produced, or released to market. 


28.15. Third Party Hypervisor Integration:

 Used by itself, QEMU is relatively slow. However, it can be integrated with third party hypervisors, and then reach near native speeds. Note that some of these systems are very close cousins of QEMU; others are more remote. To mention a few main ones:

    KVM offers particularly tight integration with QEMU. When the host and the target are the same architecture, full acceleration and high speed are delivered. KVM is native to Linux. We will discuss this in detail.
    Xen, also native to Linux, can run in hardware virtualization mode if the architecture offers it, as does x86 and some ARM variants.
    Oracle Virtual Box can use qcow2 formatted images, and has a very close relationship with QEMU.

In this course, we recommend using (and will use in labs) virt-manager to configure and run virtual machines. We will also give instructions on how to run them using qemu command line utilities. 

28.16. Image Formats

QEMU supports many formats for disk image files. However, only two are used primarily, with the rest being available for historical reasons and for conversion utilities. These two main formats are:

    - raw (default)
    This is the simplest and easiest format to export to other non-QEMU emulators. Empty sectors do not take up space.

    - qcow2COW stands for Copy On Write. There are many options. See man qemu-img for more details. 

To get a list of supported formats:

c7:/tmp> qemu-img --help | grep formats:

Supported formats: vfat vpc vmdk vhdx vdi ssh sheepdog rbd raw host_cdrom host_floppy host_device file \
qed qcow2 qcow parallels nbd iscsi gluster dmg tftp ftps ftp https http cloop bochs blkverify blkdebug

Note in particular:

    vdi: Used by Oracle Virtual Box
    vmdk: Used by VMware.

Note that qemu-img can be used to translate between formats, .e.g.:

$ qemu-img convert -O vmdk myvm.qcow2 myvm.vmdk

using default options. See the man page for full possibilities. 

28.17. VM and Linux
KVM uses the Linux kernel for computing resources, including memory management, scheduling, synchronization, and more. When running a virtual machine, KVM engages in a co-processing relationship with the Linux kernel.

In this format, KVM runs the virtual machine monitor within one or more of the CPUs, using VMX or SVM instructions. At the same time, the Linux kernel is executing on the other CPUs.

The virtual machine monitor runs the guest, which is running at full hardware speed, until it executes an instruction that causes the virtual machine monitor to take over.

At this point, the virtual machine monitor can use any Linux resource to emulate a guest instruction, restart the guest at the last instruction, or do something else.

By loading the KVM modules and starting a guest, you turn Linux into a hypervisor. The Linux personality is still there, but you also have the hardware virtual machine monitor. You can control the Virtual Machine using standard Linux resource and process control tools, such as cgroups, nice, numactl, and so on.

KVM first appeared (pre-merge) as part of a Windows Virtual Desktop product. At the time of its upstream merge in 2007, KVM required recent x86_64 processors. On x86_64 platforms, KVM is primarily (but not always) a driver for the processor's virtualization subsystem.

KVM appeared as a trio of Linux kernel modules in 2007. When paired with a modified version of QEMU (also provided at the same time), it created a hypervisor that used the Linux kernel for most of its runtime services.

Shortly after Avi Kivity, the author of KVM, submitted the source code to the Linux development community, Linus merged KVM into his Linux tree. This was surprising to a lot of folks. 

28.18. Managing KVM

There are many low level commands for creating, converting, manipulating, deploying, and maintaining virtual machine images.

Managing KVM can be done with both command line and graphical interfaces.\u200b

Command line tools include: virt-* and qemu-*. Graphical interfaces include virt-manager, kimchi, OpenStack, oVirt, etc. \u200b

As you develop more expertise, you will become practiced in using them. But, for all basic operations, virt-manager will suffice and that is what we will use. 

29.1 Containsers Overview - Introduction

Containers offer a lighter weight method to isolate an application or set of applications from other running processes.

Unlike virtual machines, each of which constitutes a complete operating system, multiple containers can run simultaneously on one system, which can be either a virtualized one or a physical one. A very common method of deploying containers is to use docker, which we will discuss in some detail.

29.2. Learning Objectives

By the end of this chapter, you should be able to:

    - Understand the basic parameters and methods that define containers.
    - Understand the difference between containers and virtual machines.
    - Be familiar with docker and know the steps necessary to use it properly.
    - Use the major commands associated with containers and docker.

29.3. Container Basics

Further integration between the hypervisor and the Linux kernel allowed the creation of operating system-level virtual machines, or Containers. Containers share many facilities in the Linux kernel, and make use of some recent kernel additions, such as namespaces and cgroups. Containers are very lightweight and reduce the overhead associated with having whole virtual machines.

The first flavor of containers was the OS container. This type of container runs an image of an operating system with the ability to run init processes and spawn multiple applications.

LXC (Linux Containers) is one example. 


           --------------    --------------  ---------------
           |            |    |            |  |             |
           |  Container |    |  Container |  |  Container  |
           |     OS     |    |     OS     |  |     OS      |
           |            |    |            |  |             |
           |____________|    |____________|  |_____________|
           _________________________________________________
           | ____________________________________________  |
           | |        Kernel Namespace Facilities        | |
           | |___________________________________________| |
           |                                               |
           |             Operating System                  |
           |_______________________________________________|

           -------------------------------------------------
           |                                               |
           |                Hardware                       |
           |_______________________________________________|

                              Containers


28.4. Application Virtualization

In an effort to further reduce the overhead associated with virtual machines, application virtualization is rising in popularity. Application virtualization runs one application for each container. Many single application containers are typically initialized on a single machine. Using smaller components creates a greater flexibility and reduces overhead normally associated with virtualization.

Docker is one such project. 

             
           --------------    --------------  ---------------
           |            |    |            |  |             |
           |    App1    |    |    App2    |  |    App3     |
           |            |    |            |  |             |
           |            |    |            |  |             |
           |____________|    |____________|  |_____________|

           --------------    --------------  ---------------
           |            |    |            |  |             |
           |libs & bins |    |libs & bins |  |libs & bins  |
           |            |    |            |  |             |
           |            |    |            |  |             |
           |____________|    |____________|  |_____________|


           _________________________________________________
           |                                               |
           |                                               |
           |                                               |
           |                                               |
           |             Docker   Engine                   |
           |_______________________________________________|

           ________________________________________________
           |                                               |
           |                                               |
           |                                               |
           |                                               |
           |             Operating System                  |
           |_______________________________________________|

           -------------------------------------------------
           |                                               |
           |                Hardware                       |
           |_______________________________________________|


                       Application Virtualization

29.5. Containers vs. Virtual Machines

Both Virtual Machines and Containers satisfy important needs. For a while, each facility had its day in the sun, and was seen as the way to go for almost everything.

Both have long histories:

    Mainframe computers have had software partitioning and virtual machines for decades, in rather specialized ways.
    Operating systems have had chroot and BSD Jail implementations for many years, that share a basic isolation motivation with containers. 

If a number of different services and applications need to be tightly integrated, a virtual machine functioning as a service may be the best solution.

If the applications being run were written expecting a complete operating system environment with a wide range of services and other libraries and applications, virtual machines may be best.

Virtual machines run a complete operating system, and can run many services and applications. Virtual machines use more resources than a container. \u200bContainers usually run one thing. Containers are more portable, and can be run inside a VM. Containers are harder to secure. They usually start faster. Multiple containers share one OS kernel, while each VM has its own.

Scaling workloads is different for containers and virtual machines. Orchestration systems such as Kubernetes or Mesos can decide on the proper quantity of containers needed, do load balancing, replicate images and remove them, etc., as needed.

Overall, virtual machines are still often the best solution.

29.6. Docker

Docker is an application-level virtualization using many individual images to build up the necessary services to support the target application. These images are packaged into containers - they are components in containers. Images may contain:

    - Application code
    - Runtime libraries
    - System tools
    - Or just about anything required for an application.

Images may reside on a Docker Hub or a registry server.

The Docker website, http://www.docker.com, has documentation, tutorials, and training information.

One of the most compelling features of Docker is that an application can be packaged up with all of its dependent code and services and deployed as a single unit with the minimum of overhead. This deployment can be easily repeated as often as desired. This reduces the requirement of building up a server with layered services to support the end application. 

29.7. Docker Steps

Starting up a Docker containerized application may include only a few steps:

    - Install the Docker service package with your favorite tool

    - Start the Docker service

    - Search for an appropriate image from Docker Hub or your private repository

    - Pull the image

    - Run the image

    - And finally, test the application. 

The steps detailed above are just a very minimal example of testing a Docker application.

There are, of course, many, many options that may be used, including functions that create an image, set system variables or configuration parameters, and then, store the result as a new image. In some cases, a writable image is required, rather than a non-writable one.

Most of the Docker commands have individual man pages. Examples include: docker(1), docker-search(1), docker-pull(1), docker-create(1), and docker-run(1). 

29.8. docker Command

 The docker command has more than 40 sub-commands, some with 50 or more options. To learn more about the docker command, you can always do:

$ docker <command> --help

The many docker sub-commands tend to be somewhat self-documenting. Often confused are run, create and exec. The ps command will list running containers, or all containers, if you include the -all option.

docker run will start a new container and execute a command within. Common options are -t to attach to a tty, and -d to run the container in the background.

The docker create command creates a container. It has many options for configuring container settings and attachments.

If the container is already running, and you want to execute something inside of it, you can use the docker exec command. It also

accepts the -t -d options.

The docker images command will show images in various outputs. The docker rmi command will remove images and delete untagged

parents by default.

You can also leverage shell functions to operate upon all containers. For example, to remove all stopped containers, you can do:

$ docker rm $(ps -a -q)

30.1. User Account Management - Introduction

30.2. Learning Objectives

By the end of this chapter, you should be able to:

    - Explain the purpose of individual user accounts and list their main attributes.
    - Create new user accounts and modify existing account properties, as well as remove or lock accounts.
    - Understand how user passwords are set, encrypted and stored, and how to require changes in passwords over time for security purposes.
    - Explain how restricted shells and restricted accounts work.
    - Understand the role of the root account and when to use it.

30.3. User Accounts

Linux systems provide a multi-user environment which permits people and processes to have separate simultaneous working environments.

The purposes of having individual user accounts include:

    Providing each user with their own individualized private space
    Creating particular user accounts for specific dedicated purposes
    Distinguishing privileges among users.

One special user account is for the root user, who is able to do anything on the system. To avoid making costly mistakes, and for security reasons, the root account should only be used when absolutely necessary.

Normal user accounts are for people who will work on the system. Some user accounts (like the daemon account) exist for the purpose of allowing processes to run as a user other than root.

In the next section, we will continue with a discussion of group management, where subsets of the users on the system can share files, privileges, etc., according to common interests.

30.4. Attributes of a User Account

Each user on the system has a corresponding line in the /etc/passwd file that describes their basic account attributes. (We will talk about passwords as well as this file later). For example:

....

beav:x:1000:1000:Theodore Cleaver:/home/beav:/bin/bash

warden:x:1001:1001:Ward Cleaver:/home/warden:/bin/bash

dobie:x:1002:1002:Dobie Gillis:/home/dobie:/bin/bash

....

The seven elements here are:

    User name
    The unique name assigned to each user.
    User password
    The password assigned to each user.
    User identification number (UID)
    A unique number assigned to the user account. The UID is used by the system for a variety of purposes, including a determination of user privileges and activity tracking.
    Group identification number (GID)
    Indicates the primary, principal, or default group of the user.
    Comment or GECOS information
    A defined method to use the comment field for contact information (full name, email, office, contact number). (Don't worry about what GECOS means, it is a very old term.)
    Home directory
    For most users, this is a unique directory that offers a working area for the user. Normally, this directory is owned by the user, and except for root will be found on the system somewhere under /home.
    Login shell
    Normally, this is a shell program such as /bin/bash or /bin/csh. Sometimes, however, an alternative program is referenced here for special cases. In general, this field will accept any executable.

30.5. Creating User Accounts with useradd


The command:

$ sudo useradd stephane

will create an account for user stephane, using default algorithms for assigning user and group id, home directory, and shell choice.

Specifically, the useradd command above causes the following steps to execute:

    The next available UID greater than UID_MIN (specified in /etc/login.defs) by default is assigned as stephane's UID.
    A group called stephane with a GID=UID is also created and assigned as stephane's primary group.
    A home directory /home/stephane is created and owned by stephane.
    stephane's login shell will be /bin/bash.
    The contents of /etc/skel is copied to /home/stephane. By default, /etc/skel includes startup files for bash and for the X Window system.
    An entry of either !! or ! is placed in the password field of the /etc/shadow file for stephane's entry, thus requiring the administrator to assign a password for the account to be usable.

The defaults can easily be overruled by using options to useradd as in:

$ sudo useradd -s /bin/csh -m -k /etc/skel -c "Bullwinkle J Moose" bmoose

where explicit non-default values have been given for some of the user attributes.

30.6.a.  Modifying and Deleting User Accounts I


The root user can remove user accounts using userdel:

$ sudo userdel isabelle

All references to the user isabelle will be erased from /etc/passwd, /etc/shadow, and /etc/group.

While this removes the account, it does not delete the home directory (usually /home/isabelle) in case the account may be re-established later. If the -r option is given to userdel the home directory will also be obliterated. However, all other files on the system owned by the removed user will remain.

usermod can be used to change characteristics of a user account, such as group memberships, home directory, login name, password, default shell, user id, etc.

Usage is pretty straightforward. Note that usermod will take care of any modifications to files in the /etc directory as necessary.

30.6.b. 


sudo usermod --help
Usage: usermod [options] LOGIN

Options:
  -c, --comment COMMENT         new value of the GECOS field
  -d, --home HOME_DIR           new home directory for the user account
  -e, --expiredate EXPIRE_DATE  set account expiration date to EXPIRE_DATE
  -f, --inactive INACTIVE       set password inactive after expiration
                                to INACTIVE
  -g, --gid GROUP               force use GROUP as new primary group
  -G, --groups GROUPS           new list of supplementary GROUPS
  -a, --append                  append the user to the supplemental GROUPS
                                mentioned by the -G option without removing
                                him/her from other groups
  -h, --help                    display this help message and exit
  -l, --login NEW_LOGIN         new value of the login name
  -L, --lock                    lock the user account
  -m, --move-home               move contents of the home directory to the
                                new location (use only with -d)
  -o, --non-unique              allow using duplicate (non-unique) UID
  -p, --password PASSWORD       use encrypted password for the new password
  -R, --root CHROOT_DIR         directory to chroot into
  -s, --shell SHELL             new login shell for the user account
  -u, --uid UID                 new UID for the user account
  -U, --unlock                  unlock the user account
  -v, --add-subuids FIRST-LAST  add range of subordinate uids
  -V, --del-subuids FIRST-LAST  remove range of subordinate uids
  -w, --add-subgids FIRST-LAST  add range of subordinate gids
  -W, --del-subgids FIRST-LAST  remove range of subordinate gids
  -Z, --selinux-user SEUSER     new SELinux user mapping for the user account

30.7.a. Locked Accounts I

Linux ships with some system accounts that are locked, which means they can run programs, but can never login to the system and have no valid password associated with them. For example, /etc/passwd has entries like:

bin:x:1:1:bin:/bin:/sbin/nologin

daemon:x:2:2:daemon:/sbin:/sbin/nologin

The nologin shell returns the following if a locked user tries to login to the system:

This account is currently not available.

or whatever message may be stored in /etc/nologin.txt.

Such locked accounts are created for special purposes, either by system services or applications; if you scan /etc/passwd for users with the nologin shell, you can see who they are on your system.

30.7.b. Locked Accounts II

It is also possible to lock the account of a particular user, as in:

$ sudo usermod -L stephane

which means the account stays on the system but logging in is impossible. Unlocking can be done with the -U option.

A customary practice is to lock a user's account whenever they leave the organization or is on an extended leave of absence.

Another way to lock an account is to use chage to change the expiration date of an account to a date in the past:

$ sudo chage -E 2014-09-11 isabelle

The actual date is irrelevant as long as it is in the past. We will discuss chage shortly.

Another approach is to edit the /etc/shadow file and replace the user's hashed password with !! or some other invalid string.

30.8. User IDs and /etc/passwd

We have already seen how /etc/passwd contains one record (one line) for each user on the system, as in

beav:x:1000:1000:Theodore Cleaver:/home/beav:/bin/bash

rsquirrel:x:1001:1001:Rocket J Squirrel:/home/rsquirrel:/bin/bash

and we have already discussed the fields in here. Each record consists of a number of fields separated by colons (:). The fields are the attributes we discussed earlier.

If /etc/shadow is not used, the password field contains the hashed password. If it is used, it contains a place holder ("x").

The convention most Linux distributions have used is that any account with a user ID less than 1000 is considered special and belongs to the system; normal user accounts start at 1000. The actual value is defined as UID_MIN and is defined in /etc/login.defs.

Historically, Red Hat-derived distributions used UID_MIN=500, not 1000, but, with RHEL 7 they adopted the more common value of 1000.

If a User ID is not specified when using useradd, the system will incrementally assign UIDs starting at UID_MIN.

Additionally, each user gets a Primary Group ID which, by default, is the same number as the UID. These are sometimes called User Private Groups (UPG).

It is bad practice to edit /etc/passwd, /etc/group or /etc/shadow directly; either use appropriate utilities such as usermod, or use the vipw special editor to do so as it is careful about file locking, data corruption, etc.

30.9. /etc/shadow

The file /etc/shadow contains one record (one line) for each user, as in:

daemon:*:16141:0:99999:7:::
.....
beav:$6$iCZyCnBJH9rmq7P.$RYNm10Jg3wrhAtUnahBZ/mTMg.RzQE6iBXyqaXHvxxbKTYqj.d
       9wpoQFuRp7fPEE3hMK3W2gcIYhiXa9MIA9w1:16316:0:99999:7:::

The colon-separated fields are:

    username: unique user name
    password: the hashed (sha512) value of the password
    lastchange: days since Jan 1, 1970 that password was last changed
    mindays: minimum days before password can be changed
    maxdays: maximum days after which password must be changed
    warn: days before password expires that the user is warned
    grace: days after password expires that account is disabled
    expire: date that account is/will be disabled
    reserved: reserved field.

The username in each record must match exactly that found in /etc/passwd, and also must appear in the identical order.

All dates are stored as the number of days since Jan. 1, 1970 (the epoch date).

The password hash is the string "$6$" followed by an eight character salt value, which is then followed by a $ and an 88 character (sha512) password hash.

30.10. Why Use /etc/shadow?

Use of /etc/shadow enables password aging on a per user basis. At the same time, it also allows for maintaining greater security of hashed passwords.

The default permissions of /etc/passwd are 644 (-rw-r--r--); anyone can read the file. This is unfortunately necessary because system programs and user applications need to read the information contained in the file. These system programs do not run as the user root and, in any event, only root may change the file.

Of particular concern are the hashed passwords themselves. If they appear in /etc/passwd, anyone may make a copy of the hashed passwords and then make use of utilities such as Crack and John the Ripper to guess the original cleartext passwords given the hashed password. This is a security risk!

/etc/shadow has permission settings of 400 (-r--------), which means that only root can access this file. This makes it more difficult for someone to collect the hashed passwords.

Unless there is a compelling good reason not to, you should use the /etc/shadow file.

30.11. Password Management

Passwords can be changed with passwd; a normal user can change only their own password, while root can change any password. When you type your password it is not shown; echoing back to the screen is suppressed.

By default, the password choice is examined by pam_cracklib.so, which furthers making good password choices.

A normal user changing their password:

$ passwd

Changing password for clyde

(current) UNIX password: <clyde's password>

New UNIX password: <clyde's-new-password>

Retype new UNIX password: <clyde's-new-password>

passwd: all authentication tokens updated successfully

Also, note that when root changes a user's password, root is not prompted for the current password:

$ sudo passwd kevin

New UNIX password:  <kevin's-new-password>

Retype new UNIX password: <kevin's-password>

passwd: all authentication tokens updated successfully

Note that normal users will not be allowed to set bad passwords, such as ones that are too short, or based on dictionary words. However, root is allowed to do so.

30.12.a. chage: Password Aging I

It is generally considered important to change passwords periodically. This limits the amount of time a cracked password can be useful to an intruder and also can be used to lock unused accounts. The downside is users can find this policy annoying and wind up writing down their ever-changing passwords and thus making them easier to steal.

The utility that manages this is chage:

chage [-m mindays] [-M maxdays] [-d lastday] [-I inactive] [-E expiredate] [-W warndays] user

Examples:

$ sudo chage -l stephane
$ sudo chage -m 14 -M 30 kevlin
$ sudo chage -E 2012-4-1 isabelle
$ sudo chage -d 0 clyde

30.12.b. chage: Password Aging II

 Only the root user can use chage. The one exception to this is that any user can run chage -l to see their aging.

 To force a user to change their password at their next login, do:

$ sudo chage -d 0 USERNAME

30.13. Restricted shell

Under Linux one can use a restricted shell, which can be invoked as:

$ bash -r

(Some distributions may define an rbash command to the same effect.)

A restricted shell functions in a more tightly controlled environment than a standard shell, but otherwise functions normally. In particular, it:

    Prevents the user from using cd to change directories.
    Prevents the user from redefining the following environment variables: SHELL, ENV, and PATH.
    Does not permit the user to specify the absolute path or executable command names starting from /.
    Prevents the user from redirecting input and/or output.

Note that there are other restrictions; the best way to see them all is to do man bash and search for RESTRICTED SHELL.

Because the restricted shell executes $HOME/.bash_profile without restriction, the user must have neither write nor execute permission on the /home directory.

30.14. Restricted Accounts

There are times when granting access to a user is necessary, but should be limited in scope. Setting up a restricted user account can be useful in this context. A restricted account:

    Uses the restricted shell
    Limits available system programs and user applications
    Limits system resources
    Limits access times
    Limits access locations.

From the command line, or from a script, a restricted shell may be invoked with /bin/bash -r. However, flags may not be specified in the /etc/passwd file. A simple way to get around this restriction would be to do one of the following:

$ cd /bin ; sudo ln -s bash rbash

$ cd /bin ; sudo ln bash rbash

$ cd /bin ; sudo cp bash rbash

and then, use /bin/bash as the shell in /etc/passwd.

When setting up such an account, one should avoid inadvertently adding system directories to the PATH environment variable; this would grant the restricted user the ability to execute other system programs, such as an unrestricted shell.

Restricted accounts are also sometimes referred to as limited accounts.  

30.15. The root Account

The root account should only be used for administrative purposes when absolutely necessary and never used as a regular account. Mistakes can be very costly, both for integrity and stability, and system security.

By default, root logins through the network are generally prohibited for security reasons. One can permit Secure Shell logins using ssh, which is configured with /etc/ssh/sshd_config, and PAM (Pluggable Authentication Modules), which we will discuss later, through the pam_securetty.so module and the associated /etc/securetty file. Root login is permitted only from the devices listed in /etc/securetty.

It is generally recommended that all root access be through su, or sudo (causing an audit trail of all root access through sudo). Note that some distributions (such as Ubuntu), by default actually prohibit logging in directly to the root account.

PAM can also be used to restrict which users are allowed to su to root. It might also be worth it to configure auditd to log all commands executed as root.

30.16.a. SSH I

One often needs to login through the network into a remote system, either with the same user name or another. Or one needs to transfer files to and from a remote machine. In either case, one wants to do this securely, free from interception.

SSH (Secure SHell) exists for this purpose. It uses encryption based on strong algorithms. Assuming the proper ssh packages are installed on a system, one needs no further setup to begin using ssh.

To sign onto a remote system:

$ whoami
student

$ ssh farflung.com
student@farflung.com's password: (type here)
$

where we are assuming there is a student account on farflung.com. To log in as a different user:

$ ssh root@farflung.com
root@farflung.com's password: (type here)

or

$ ssh -l root farflung.com
root@farflung.com's password: (type here)

30.16.b. SSH II

To copy files from one system to another:

$ scp file.txt farflung.com:/tmp
$ scp file.tex student@farflung.com/home/student
$ scp -r some_dir farflung.com:/tmp/some_dir

(We have omitted the request for a password to save space; if you configure properly with encryption keys as we will discuss next, you will not need to supply a password.)

To run a command on multiple machines simultaneously:

$for machines in node1 node2 node3

do (ssh $machines some_command &)

done

30.17.a. SSH Configuration Files I

One can configure SSH further to expedite its use, in particular to permit logging in without a password. User-specific configuration files are created under every user's home directory in the hidden .ssh directory:

 $ ls -l ~/.ssh
total 20
-rw-r--r-- 1 hilda hilda 1172 Sep 27  2014 authorized_keys
-rw------- 1 hilda hilda  207 Aug  9  2011 config
-rw------- 1 hilda hilda 1675 Dec  8  2010 id_rsa
-rw-r--r-- 1 hilda hilda  393 Dec  8  2010 id_rsa.pub
-rw-r--r-- 1 hilda hilda 1980 Apr 28 07:36 known_hosts

which contains:

    id_rsa: the user's private encryption key
    id_rsa.pub: the user's public encryption key
    authorized_keys: A list of public keys that are permitted to login
    known_hosts: A list of hosts from which logins have been allowed in the past
    config: A configuration file for specifying various options.

30.17.b. SSH Configuration Files II

First, a user has to generate their private and public encryption keys with ssh-keygen:

$ ssh-keygen

Generating public/private rsa key pair.
Enter file in which to save the key (/home/hilda/.ssh/id_rsa):
Enter passphrase (empty for no passphrase):
Enter same passphrase again: 
Your identification has been saved in /home/hilda/.ssh/id_rsa
Your public key has been saved in /home/hilda/.ssh/id_rsa.pub
The key fingerprint is:
76:da:d3:51:1e:c8:2d:3b:34:28:46:b2:2b:db:d1:c4 hilda@c7
The key's randomart image is:
+--[ RSA 2048]----+
|      . .        |
|       =   o o   |
|      . E . * +  |
|       = . . * . |
|    . o S . + .  |
|     + o + . o   |
|    . . . o .    |
|           .     |
|                 |
+-----------------+

This will also generate the public key, \u0303/.ssh/id_rsa.pub.

30.17.c. SSH Configuration Files III

The public key can be given to any machine with which you want to permit password-less access. It should also be added to your authorized_keys file, together with all the public keys from other users who have accounts on your machine and you want to permit password-less access to their accounts.

The known_hosts file is gradually built up as ssh accesses occur. If the system detects changes in the users who are trying to log in through ssh it will warn you of them and afford the opportunity to deny access. Note that the authorized_keys file contains information about users and machines:

$ cat authorized_keys

ssh-rsa AAAAB3NzaC1yc2EAAAADAQ
...0000aSd...hilda@sbc

while the known_hosts only contains information about computer nodes:

$ cat known_hosts

192.30.252.129 ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSw
....BK6Tb...==

You can examine the man pages to see what kinds of options can go into the ssh configuration file, config.

30.18. Remote Graphical Login

 Login into the remote machine with full graphical desktop. Often, you may use VNC (Virtual Network Computing) to connect to a system. A common implementation is tigervnc.

To test this, first make sure that you have the vnc packages installed:

$ sudo yum install tigervnc tigervnc-server

$ sudo zypper install tigervnc tigervnc-server

$ sudo apt-get install tigervnc tigervnc-server

using the right package management system command.

Start the server as a normal user with:

$ vncserver

You can test with:

$ vncviewer localhost:2

(You may have to play with numbers other than 2, such as 1,3,4..., depending on what you are running at the moment, and how your machine is configured.)

To view from a remote machine, it is just slightly different:

$ vncviewer -via student@some_machine localhost:2

If you get a rather strange message about having to authenticate because of 'color profile', and no passwords work, you have to kill the colord daemon on the server machine, as in:

$ sudo systemctl stop colord

31.1. Group Management - Introduction

Linux systems form collections of users called groups, whose members share some common purpose. To further that end, they share certain files and directories and maintain some common privileges; this separates them from others on the system, sometimes collectively called the world. Using groups aids collaborative projects enormously.

31.2. Learning Objectives

By the end of this chapter, you should be able to:

    -Explain why it is useful to have Linux users belong to one or more groups.
    - Use utilities such as groupadd, groupdel, groupmod, and usermod to create, remove and manipulate groups and their membership.
    - Describe User Private Groups.
    - Explain the concept of group membership

31.3. Groups

Users belong to one or more groups under Linux. Purposes include:

    Allowing users to share a work area (directories, files, etc.)
    Setting up file permissions to allow access to group members, but not the entire world
    Permitting certain specified users to access resources they would not be allowed to otherwise.

Groups are defined in /etc/group, which has the same role for groups as /etc/passwd has for users.  Each line of the file looks like:

groupname:password:GID:user1,user2,...

where:

    groupname is the name of the group
    password is the password place holder. Group passwords may be set, but only if the /etc/gshadow file exists
    GID is the group identifier. Values between 0 and 99 are for system groups. Values between 100 and GID_MIN (as defined in /etc/login.defs and usually the same as UID_MIN) are considered special. Values over GID_MIN are for UPG (User Private Groups)
    user1,user2,... is a comma-separated list of users who are members of the group. The user need not be listed here if this group is the user's principal group.

31.4. Group Management

Group accounts may be managed and maintained with:

    groupadd:  Add a new group.
    groupdel:  Remove a group.
    groupmod:  Modify a group's properties.
    usermod:  Modify a user's group memberships (add or remove).

One can also edit /etc/group directly, but it is better to use the vigr utility, which is generally symbolically linked to the vipw utility mentioned earlier.

These group manipulation utilities modify /etc/group and (if it exists) /etc/gshadow, and may only be executed by root:

Examples:

$ sudo groupadd -r -g 215 staff

$ sudo groupmod -g 101 blah

$ sudo groupdel newgroup

$ sudo usermod -G student,group1,group2 student

Note:  Be very careful with the usermod -G command; the group list that follows is the complete list of groups, not just the changes. Any supplemental groups left out will be gone! Non-destructive use should utilize the -a option, which will preserve pre-existing group memberships when adding new ones.

31.5. User Private Groups

Linux uses User Private Groups (UPG).

The idea behind UPGs is that each user will have his or her own group. However, UPGs are not guaranteed to be private; additional members may be added to someone's private group in /etc/group.

By default, users whose accounts are created with useradd have: primary GID = UID and the group name is also identical to the user name.

As specified in /etc/profile, the umask is set to 002 for all users created with UPG. Under this scheme, user files are thus created with permissions 664 (rw-rw-r--) and directories with 775 (rwxrwxr-x). We will discuss umask in the next section.

31.6. Group Membership

A Linux user has one primary group; this is listed in /etc/passwd and will also be listed in /etc/group. A user may belong to between 0 and 15 secondary groups.

The primary group is the GID that is used whenever the user creates files or directories. Membership in other, secondary, groups grants the user additional permissions.

Group membership can be identified by running:

$ groups [user1 user2 ...]

$ id -Gn [user1 user2 ...]

With no arguments, either command reports on the current user. Note that the default groups can differ by distribution:

On Centos:

[student@CentOS7 ~]$ groups

student

[student@CentOS7 ~]$ 

On Ubuntu:

student@ubuntu:~$ groups

student adm cdrom sudo dip plugdev lpadmin sambashare libvirt

student@ubuntu:~$ 

32.1. File Permissions and Ownership - Introduction

32.2. Learning Objectives

By the end of this chapter, you should be able to:

    - Explain the concepts of owner, group, and world.
    - Set file access rights (read, write, and execute) for each category.
    - Authenticate requests for file access, respecting proper permissions. 
    - Use chmod to change file permissions, chown to change user ownership, and chgrp  to change group ownership.
    - Understand the role of umask in establishing desired permissions on newly created files.
    - Use ACLs to extend the simpler user, group, world and read, write, execute model.

32.3. Owner, Gruop and World

When you do an ls -l as in:

$ ls -l a_file

-rw-rw-r-- 1 coop aproject 1601 Mar 9 15:04  a_file

after the first character (which indicates the type of the file object) there are nine more which indicate the access rights granted to potential file users. These are arranged in three groups of three:

    owner:  the user who owns the file (also called user)
    group:  the group of users who have access
    world:  the rest of the world (also called other).

In the above listing, the user is coop and the group is aproject.

32.4. File Access Rights

Each of the triplets can have each of the following sets:

    r:  read access is allowed
    w:  write access is allowed
    x:  execute access is allowed.

If the permission is not allowed, a - appears instead of one of these characters.

In addition, other specialized permissions exist for each category, such as the setuid/setgid permissions.

Thus, in the preceding example, the user coop and members of the group aproject have read and write access, while anyone else has only read access.

32.5. File Permissions and Security and Authentication

These file access permissions are a critical part of the Linux security system. Any request to access a file requires comparison of the credentials and identity of the requesting user to those of the owner of the file.

This authentication is granted depending on one of these three sets of permissions, in the following order:

    If the requester is the file owner, the file owner permissions are used.
    Otherwise, if the requester is in the group that owns the files, the group permissions are examined.
    If that doesn't succeed, the world permissions are examined.

32.6. Changing Permissions: chmod

Changing file permissions is done with chmod. You can only change permissions on files you own, unless you are the superuser.

There are a number of different ways to use chmod. For instance, to give the owner and world execute permission, and remove the group write permission:

$ ls -l a_file

-rw-rw-r-- 1 coop coop 1601 Mar  9 15:04 a_file

$ chmod uo+x,g-w a_file

$ ls -l a_file

-rwxr--r-x 1 coop coop 1601 Mar  9 15:04 a_file

where u stands for user (owner), o stands for other (world), and g stands for group.

32.7.a. chmod: Numerical Syntax for Permissions I

The symbolic syntax can be difficult to type and remember, so one often uses the octal shorthand, which lets you set all the permissions in one step. This is done with a simple algorithm, and a single digit suffices to specify all three permission bits for each entity. This digit is the sum of:

    4 if the read permission is desired
    2 if the write permission is desired
    1 if execute permission is desired.

Thus, 7 means read/write/execute, 6 means read/write, and 5 means read/execute.

When you apply this with chmod, you have to give a value for each of the three digits, such as in

$ chmod 755 a_file
$ ls -l a_file
-rwxr-xr-x 1 coop coop 1601 Mar 9 15:04 a_file

32.7.b. chmod: Numerical Syntax for Permissions I

Permissions can be represented either as a bitmap, usually written in octal, or in a symbolic form. Octal bitmaps usually look like 0755 while symbolic representations look like u+rwx,g+rwx,o+rx.

32.8. Changing User and Group File Ownership: chmod and chgrp

Changing file ownership is done with chown and changing the group is done with chgrp.

Only the superuser can change ownership on files. Likewise, you can only change group ownership to groups that you are a member of.

Changing the group ownership of the file is as simple as doing:

$ chgrp aproject a_file

and changing the ownership is as simple as

$ chown coop a_file

You can change both at the same time with:

$ chown coop:aproject a_file

where you separate the owner and the group with a colon (or a period).

All three of these programs take the -R option, which stands for recursive. For example:

$ chown -R coop:aproject ./

$ chown -R coop:aproject subdir

will change the owner and group of all files in the current directory and all its subdirectories in the first command, and in subdir and all its subdirectories in the second command.

32.9. umask

The default permissions given when creating a file are read/write for owner, group and world (0666), and for a directory it is read/write/execute for everyone (0777). However, if you do the following:

$ touch afile
$ mkdir adir
$ ls -l | grep -e afile -e adir
drwxrwxr-x 2 coop coop 4096 Sep 16 11:18 adir
-rw-rw-r-- 1 coop coop    0 Sep 16 11:17 afile

you will notice the actual permissions have changed to 664 for the file and 775 for the directory. They have been modified by the current umask whose purpose is to show which permissions should be denied. The current value can be shown by:

$ umask
0002

which is the most conventional value set by system administrators for users. This value is combined with the file creation permissions to get the actual result; i.e.,

0666 & ~002 = 0664; i.e., rw-rw-r--

You can change the umask at any time with the umask command, as in

$ umask 0022

32.11. Filesystem ACLs

Linux contains a full implementation of  POSIX ACLs (Access Control Lists) which extends the simpler user, group, world and read, write, execute model.

Particular privileges can be granted to specific users or groups of users when accessing certain objects or classes of objects. Files and directories can be shared without using 777 permissions.

While the Linux kernel enables the use of ACLs, it still must be implemented as well in the particular filesystem. All major filesystems used in modern Linux distributions incorporate the ACL extensions, and one can use the option -acl when mounting. A default set of ACLs is created at system install. 

32.12. Getting and Setting ACLs

To see ACLs:

$ getfacl file|directory

Example:

 $ getfacl file1

To set ACLs:

 $ setfacl options permissions file|directory

Examples:

$ setfacl -m u:isabelle:rx /home/stephane/file1

$ setfacl -x u:isabelle    /home/stephane/file

Note that new files inherit the default ACL (if set) from the directory they reside in. Also note that mv and cp -p preserve ACLs. 

To remove an ACL:

$ setfacl -x u:isabelle /home/stephane/file1

To set the default on a directory:

$ setfacl -m d:u:isabelle:rx somedir

33.1. Pluggable Authentication Modules - Introduction

Pluggable Authentication Modules provide a uniform mechanism to ensure that users and applications are properly identified and authenticated. Conditional rules can be applied to limit the scope of permissions and control can be established over what to do in case of either success or failure. PAM can also work with LDAP to centralize authentication throughout a network.

33.2. Learning Objectives

By the end of this chapter, you should be able to:

    - Explain the basic concepts that motivate the use of PAM.
    - List the steps involved in the authentication process.
    - Use and modify PAM configuration files.
    - Know how to interpret PAM rules and create new ones.
    - Apply LDAP to use and administer distributed directory services over the network.

33.3 PAM: A Unified Approach to Authentication

Historically, authentication of users was performed individually by individual applications; i.e., su, login, and ssh would each authenticate and establish user accounts independently of each other.

Most modern Linux applications have been written or rewritten to exploit PAM (Pluggable Authentication Modules) so that authentication can be done in one uniform way, using libpam.

This library of modules provides enormous flexibility and consistency with respect to authentication, password, session, and account services.

PAM incorporates the following components:

    PAM-aware applications
    Configuration files in /etc/pam.d/ 
    PAM modules in the libpam* libraries, which can be found in different locations depending on the Linux distribution.

Each PAM-aware application, or service, may be configured with respect to PAM by an individual configuration file in /etc/pam.d.

33.4. Authentication Process

Several steps are involved in authentication:

   - A user invokes a PAM-aware application, such as login, ssh, or su.
   - The application calls libpam.
   - The library checks for files in /etc/pam.d; these delineate which PAM modules to invoke, including system-auth.
   - Each referenced module is executed in accordance with the rules of the relevant configuration file for that application.

33.5. PAM Configuration Files

Each file in /etc/pam.d corresponds to a service and each (non-commented) line in the file specifies a rule. The rule is formatted as a list of space-separated tokens, the first two of which are case insensitive:

type control module-path module-arguments

As an example, the screenshot here shows what are the contents of /etc/pam.d/su on a RHEL 7 system. Notice that there is a stack here; su will require loading of system-auth etc.


#
# The PAM configuration file for the Shadow `su' service
#

# This allows root to su without passwords (normal operation)
auth       sufficient pam_rootok.so

# Uncomment this to force users to be a member of group root
# before they can use `su'. You can also add "group=foo"
# to the end of this line if you want to use a group other
# than the default "root" (but this may have side effect of
# denying "root" user, unless she's a member of "foo" or explicitly
# permitted earlier by e.g. "sufficient pam_rootok.so").
# (Replaces the `SU_WHEEL_ONLY' option from login.defs)
# auth       required   pam_wheel.so

# Uncomment this if you want wheel members to be able to
# su without a password.
# auth       sufficient pam_wheel.so trust

# Uncomment this if you want members of a specific group to not
# be allowed to use su at all.
# auth       required   pam_wheel.so deny group=nosu

# Uncomment and edit /etc/security/time.conf if you need to set
# time restrainst on su usage.
# (Replaces the `PORTTIME_CHECKS_ENAB' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user's mail spool file.
# See comments in /etc/login.defs
#
# "nopen" stands to avoid reporting new mail when su'ing to another user
session    optional   pam_mail.so nopen

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session

33.6. PAM Rules

The module type specifies the management group the module is to be associated with:

    auth:  Instructs the application to prompt the user for identification (username, password, etc). May set credentials and grant privileges.
    account:  Checks on aspects of the user's account, such as password aging, access control, etc.
    password:  Responsible for updating the user authentication token, usually a password.
    session:  Used to provide functions before and after the session is established (such as setting up environment, logging, etc.).

The control flag controls how the success or failure of a module affects the overall authentication process:

    required:  Must return success for the service to be granted. If part of a stack, all other modules are still executed. Application is not told which module or modules failed.
    requisite:  Same as required, except a failure in any module terminates the stack and a return status is sent to the application.
    optional:  Module is not required. If it is the only module, then its return status to application may cause failure.
    sufficient:  If this module succeeds, then no subsequent modules in the stack are executed. If it fails, then it doesn't necessarily cause the stack to fail, unless it is the only one in the stack.

There are other control flags, such as include and substack. Please see man pam.d for details.

module-path gives the file name of the library to be found in /lib*/security, in either absolute or relative path form.

module-arguments can be given to modify the PAM module's behavior.

33.7. LDAP Authentication

LDAP (Lightweight Directory Access Protocol) is an industry standard protocol for using and administering distributed directory services over the network, and is meant to be both open and vendor-neutral.

When using LDAP for centralized authentication, each system (or client) connects to a centralized LDAP server for user authentication. Using TLS makes it a secure option and is recommended.

LDAP uses PAM and system-config-authentication or authconfig-tui. One has to specify the server, search base DN (domain name) and TLS (Transport Layer Security). Also required is openldap-clients, pam ldap and nss-pam-ldapd.

When you configure a system for LDAP authentication, five files are changed:

/etc/openldap/ldap.conf

/etc/pam_ldap.conf

/etc/nslcd.conf

/etc/sssd/sssd.conf

/etc/nsswitch.conf

You can edit these files manually or use one of the utility programs available (system-config-authentication or authconfig-tui).

35.1. Network Devices and COnfiguration - Introduction

  Network devices such as Ethernet and wireless connections require careful configuration, especially 
    when there are multiple devices of the same type. The question of consistent and persistent device 
    naming can become tricky in such circumstances. Recently, the adoption of new schemes has made the 
    naming more predictable. A number of important utilities are used to bring devices up and down, 
    configure their properties, establish routes, etc., and system administrators must become adept at their use.

35.2. Learning Objectives

    By the end of this chapter, you should be able to:

    - Identify network devices and understand how the operating system names them and binds them to specific duties.
    - Use the ip utility to display and control devices, routing, policy-based routing, and tunnelling. 
    - Use the older ifconfig to configure, control, and query network interface parameters from either the command line or from system configuration scripts.
    - Use Network Manager (nmtui and nmcli) to configure network interfaces in a distribution-independent manner.  
    - Know how to set default routes and static routes.
    - Configure name resolution as well as run diagnostic utilities.

35.3. Network Devices

    Unlike block and character devices, network devices are not associated with special device files, also known as device nodes. Rather than having associated entries in the /dev directory, they are known by their names.

These names consist of a type identifier followed by a number as in:

    - eth0, eth1, eno1,eno2 etc. for Ethernet devices.
    - wlan0, wlan1, wlan2, wlp3s0, wlp3s2,  etc. for wireless devices.
    - br0,  br1, br2 etc. for bridge interfaces.
    - vmnet0,  vmnet1,   vmnet2 etc. for virtual devices for communicating with virtual clients.

Sometimes multiple virtual devices can be associated with single physical devices.

35.4. Problems with Network Device Names

    The classic device naming conventions described earlier encountered difficulties, particularly when multiple interfaces of the same type were present. For example, suppose one has two network cards; one would be named eth0 and the other eth1. However, which physical device should be associated with each name?

The simplest method would be to have the first device found be eth0, the second eth1 etc. Unfortunately, probing for devices is not deterministic for modern systems, and devices may be located or plugged in an unpredictable order. Thus, one might wind up with the Internet interface swapped with the local interface. Even if hardware doesn't change, the order in which interfaces are located has been known to vary with kernel version and configuration.

Many system administrators have solved this problem in a simple manner, by hardcoding associations between hardware (MAC) addresses and device names in system configuration files and startup scripts. While this method has worked for years it requires manual tuning and had other problems, such as when MAC addresses were not fixed; this can happen in both embedded and virtualized systems. 

35.5. Predicatable Network Interface Device Names

    The Predictable Network Interface Device Names (PNIDN) is strongly correlated with the use of udev and integration with systemd. There are now 5 types of names that devices can be given:

    1. Incorporating Firmware or BIOS provided index numbers for on-board devices:
    Example: eno1
    2. Incorporating Firmware or BIOS provided PCI Express hotplug slot index numbers:
    Example: ens1
    3. Incorporating physical and/or geographical location of the hardware connection:
    Example: enp2s0
    4. Incorporating the MAC address:
    Example: enx7837d1ea46da
    5. Using the old classic method:
    Example: eth0

35.6. Examples of the New Naming Scheme

    For example, on a machine with two onboard PCI network interfaces that would have been eth0 and eth1:

$ ifconfig | grep enp

enp2s0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500 enp4s2: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500

These names are correlated with the physical locations of the hardware on the PCI system:

02:00.0 Ethernet controller: Marvell Technology Group Ltd. 88E8056 PCI-E Gigabit Ethernet Controller (rev 12)

04:02.0 Ethernet controller: Marvell Technology Group Ltd. 88E8001 Gigabit Ethernet Controller (rev 14)

The triplet of numbers at the beginning of each line from the lspci output is the bus, device (or slot), and function of the device; hence it reveals the physical location.

Likewise, for a wireless device that previously would have been simply named wlan0:

$ ifconfig grep wl

wlp3s0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500

$ lspci | grep Centrino

03:00.0 Network controller: Intel Corporation Centrino Advanced-N 6205 [Taylor Peak] (rev 34)

We see the same pattern. It is easy to turn off the new scheme and go back to the classic names. We'll leave that as a research project. In what follows we will mostly follow the classic names for definiteness and simplicity.

35.7.a. ip 1

 ip is the preferred  command line utility as compared to the venerable ifconfig we discuss next, as it is more versatile as well as more efficient because it uses netlink sockets rather than ioctl system calls.

ip can be used for a wide variety of tasks. It can be used to configure, control and query devices and interface parameters, as well as manipulate routing, policy-based routing, and tunneling.

The basic syntax is:

ip [ OPTIONS ] OBJECT { COMMAND | help }

ip [ -force ] -batch filename

where the second form can read commands from a designated file.

ip is a multiplex utility; the OBJECT argument describes what kind of action is going to be performed. The possible COMMANDS depend on which OBJECT is selected.

35.7.b. ip II

                        Main ip OBJECTs
     OBJECT	                        Function
    ========================================================================
    address	                        IPv4 or IPv6 protocol device address
    link        	                Network Devices
    maddress	                    Multicast Address
    monitor	                        Watch for netlink messages
    route	                        Routing table entry
    rule	                        Rule in the routing policy database
    tunnel	                        Tunnel over IP

35.8.a. Examples of Using ip I

    The ip utility can be used in many ways, such as:

    -   Show information for all network interfaces:
            $ ip link
    -   Show information for the eth0 network interface:
            $ ip -s link show eth0
    -   Set the IP address for eth0:
            $ sudo ip addr add 192.168.1.7 dev eth0
    -   Bring eth0 down:
            $ sudo ip link set eth0 down
    -   Set the MTU to 1480 bytes for eth0:
            $ sudo ip link set eth0 mtu 1480
    -   Set the networking route:
            $ sudo ip route add 172.16.1.0/24 via 192.168.1.5

35.8.b. Examples of Using ip II

35.9.a. ifconfig I

    ifconfig is a system administration utility long found in UNIX-like operating systems used to configure, control, and query network interface parameters from either the command line or from system configuration scripts. It has been superseded by ip and some Linux distributions no longer install it by default. Here are some usage examples:

    -   Display information about all interfaces:
            $ ifconfig
    -   Display information about only eth0:
            $ ifconfig eth0
    -   Set the IP address to 192.168.1.50 on interface eth0:
            $ sudo ifconfig eth0 192.168.1.50
    -   Set the netmask to 24-bit:
            $ sudo ifconfig eth0 netmask 255.255.255.0
    -   Bring interface eth0 up:
            $ sudo ifconfig eth0 up
    -   Bring interface eth0 down:
            $ sudo ifconfig eth0 down

35.9.b. ifconfig II

    Set the MTU (Maximum Transfer Unit) to 1480 bytes for interface eth0:

    $ sudo ifconfig eth0 mtu 1480

35.10. NIC Configuration Files

    While network interfaces can be configured on the fly using either the ip or ifconfig utilities, these settings are not persistent. Thus, a number of  Linux distribution-dependent files store persistent network interface and device configuration information.

Each distribution has its own set of files and/or directories. Depending on your version, these might be:

Red Hat

/etc/sysconfig/network

/etc/sysconfig/network-scripts/ifcfg-ethX

/etc/sysconfig/network-scripts/ifcfg-ethX:Y

/etc/sysconfig/network-scripts/route-ethX

Debian

/etc/network/interfaces

 SUSE

/etc/sysconfig/network

When using systemd, it is preferable to use Network Manager, rather than try to configure the underlying text files. In fact, in new Linux distributions many of these files are non-existent, empty or much smaller and are there only for backward compatibility reasons.

35.11. Network Manager

    Once upon a time, network connections were almost all wired (Ethernet) and did not change unless there was a significant change to either the hardware, the software, or the network configuration. During system boot, files in /etc were consulted to establish all device configuration.

However, modern systems often have dynamic configurations:

    Networks may change as a device is moved from place to place.
    Wireless devices may have a large choice of networks to hook into.
    Devices may change as hardware such as wireless devices, are plugged in or turned on and off.

The previously discussed configuration files were created to deal with more static situations and are very distribution dependent.

Network Manager still uses configuration files, but the administrator can avoid directly manipulating them, and its use is hopeefully almost the same on different systems.

35.12. Network Manager Interfaces
    
    GUI (Graphical User Interface)

If you are using your laptop in a hotel room or a coffee shop, you are probably going to use whatever graphical interface your Linux distribution's desktop offers. You can use this to select between different networks, configure security and passwords, turn devices off and on etc.

nmtui
If you are making a configuration change on your system that is likely to last for a while, you are likely to use nmtui as it has almost no learning curve and will edit the underlying configuration files for you.

nmcli

If you need to run scripts that change the network configuration, you will want to use nmcli. Or, if you are a command line junkie, you may want to use this instead of nmtui.

If the GUI is properly done, you should be able to accomplish any task using any of these three methods. However, we will focus on nmtui and nmcli because they are essentially distribution independent and hide any differences in underlying configuration files.

35.13. nmtui

    nmtui is rather straightforward to use. You can navigate with either the arrow keys or the tab key.

Besides activating or editing connections, you also set the system hostname. However, some operations, such as this, cannot be done by normal users and you will be prompted for the root password to go forward. 

35.14. nmtui Wireless Configuration

35.15. nmcli

    nmcli is the command line interface to Network Manager. One can issue direct commands, but it also has an interactive mode.

For many details and examples, you can visit https://fedoraproject.org/wiki/Networking/CLI  or you can type: 

$ man nmcli-examples 

We will explore the use of nmcli in lab exercises. 

35.16. Routing

    Routing is the process of selecting paths in a network along which to send network traffic. The routing table is a list of routes to other networks managed by the system. It defines paths to all networks and hosts, sending remote traffic to routers.

To see the current routing table, one can use route or ip:  

35.17.a. Default Route I

    The default route is the way packets are sent when there is no other match in the routing table for reaching the specified network.

It can be obtained dynamically using DHCP. However, it can also be manually configured (static). With nmcli it can be done via:

$ sudo nmcli con mod virbr0 ipv4.routes 192.168.10.0/24 \
              +ipv4.gateway 192.168.122.0
$ sudo nmcli con up virbr0

or one can modify configuration files directly. On Red Hat-based systems, one can modify /etc/sysconfig/network putting in the line:

GATEWAY=x.x.x.x

or alternatively in /etc/sysconfig/network-scripts/ifcfg-ethX on a device-specific basis in the configuration file for the individual NIC. On Debian-based systems, the equivalent is putting:

gateway=x.x.x.x

in /etc/network/interfaces.

35.17.b. Default Route II

    On either system you can set the default gateway at runtime with:

$ sudo route add default gw 192.168.1.10 enp2s0
$ route
Kernel IP routing table
Destination   Gateway      Genmask       Flags Metric Ref Use Iface
default       192.168.1.10 0.0.0.0       UG    0      0     0 enp2s0
default       192.168.1.1  0.0.0.0       UG    1024   0     0 enp2s0
172.16.132.0  0.0.0.0      255.255.255.0 U     0      0     0 vmnet1
192.168.1.0   0.0.0.0      255.255.255.0 U     0      0     0 enp2s0
192.168.113.0 0.0.0.0      255.255.255.0 U     0      0     0 vmnet8

Note that this might wipe out your network connection! You can restore either by resetting the network, or in the above example by doing:

$ sudo route add default gw 192.168.1.1 enp2s0

These changes are not persistent and will not survive a system restart.

25.18.a. Static Routes I

    Static routes are used to control packet flow when there is more than one router or route. They are defined for each interface and can be either persistent or non-persistent.

When the system can access more than one router, or perhaps there are multiple interfaces, it is useful to selectively control which packets go to which router.

Either the route or ip command can be used to set a non-persistent route as in:

$ sudo ip route add 10.5.0.0/16 via 192.168.1.100
$ route
Destination  Gateway      Genmask        Flags Metric Ref Use Iface
default      192.168.1.1  0.0.0.0        UG    0      0     0 eth0
10.5.0.0     quad         255.255.0.0    UG    0      0     0 eth0
192.168.1.0  *            255.255.255.0  U     1      0     0 eth0


35.18.b. Static Routes II

    A persistent route can be set by editing /etc/sysconfig/network-scripts/route-ethX as shown by: 

$ cat /etc/sysconfig/network-scripts/route-eth0
10.5.0.0/16 via 172.17.9.1

On a Debian-based system you need to add lines to /etc/network/interfaces such as:

iface eth1 inet dhcp
    post-up route add -host 10.1.2.51 eth1
    post-up route add -host 10.1.2.52 eth1

On a SUSE-based system you need to add to or create a file such as /etc/sysconfig/network/ifroute-eth0 with lines like:

# Destination Gateway Netmask Interface [Type] [Options]

192.168.1.150 192.168.1.1 255.255.255.255 eth0
10.1.1.150 192.168.233.1.1 eth0
10.1.1.0/24 192.168.1.1 - eth0

where each field is separated by tabs.

35.19. Name Resolution

    Name resolution is the act of translating hostnames to the IP addresses of their hosts. For example, a browser or email client will take training.linuxfoundation.org and resolve the name to the IP address of the server (or servers) that serve training.linuxfoundation.org in order to transmit to and from that location.

There are two facilities for doing this translation:

    Static name resolution (using /etc/hosts).
    Dynamic name resolution (using DNS servers).

From the command line:

$ [dig | host | nslookup] linuxfoundation.org

    dig: generates the most information and has many options
    host: more compact
    nslookup: older.

One sometimes also requires reverse resolution: converting an IP address to a host name

35.20. /etc/hosts

   /etc/hosts holds a local database of hostnames and IP addresses. It contains a set of records (each taking one line) which map IP addresses with corresponding hostnames and aliases.

A typical /etc/hosts file looks like:

127.0.0.1     localhost localhost.localdomain localhost4 localhost4.localdomain4
::1           localhost localhost.localdomain localhost6 localhost6.localdomain6

192.168.1.100 hans hans7 hans64
192.168.1.150 bethe bethe7 bethe64
192.168.1.2 hp-printer
192.168.1.10 test32 test64 oldpc

Such static name resolution is primarily used for local, small, isolated networks. It is generally checked before DNS is attempted to resolve an address; however, this priority can be controlled by /etc/nsswitch.conf. 

35.21. DNS

    If name resolution cannot be done locally using /etc/hosts, then the system will query a DNS (Domain Name Server) server.

DNS is dynamic and consists of a network of servers which a client uses to look up names. The service is distributed; any one DNS server has only information about its zone of authority; however, all of them together can cooperate to resolve any name.

The machine's usage of DNS is configured in /etc/resolv.conf, which historically has looked like:

search example.com aps.org
nameserver 192.168.1.1
nameserver 8.8.8.8

which:

    Can specify particular domains to search
    Defines a strict order of nameservers to query
    May be manually configured or updated from a service such as DHCP (Dynamic Host Configuration Protocol).

Most modern systems will have an /etc/hosts.resolv file generated automatically, such as:

# Generated by NetworkManager
192.168.1.1

which was generated by NetworkManager invoking DHCP on the primary network interface. 


                                    __________________________________
                                    |  user requests wikipedia.org   |
                                    |                                |
                                    ----------------------------------
                                                    |
                                                    |
                                                   \ /
                                    __________________________________
                          found     |        look in hosts           |
                     ---------------|                                |<-----|--| returns page
                     |              ----------------------------------      |  |
                     |                              |                       |  |
                     |               Not found      |                       |  |
                     |                             \ /                      |  |
                     | queries DNS  ___________________________________     |  |
                     | serer of     |      user's DNS server          |     |  |
                     | wikipedia.org|                                 |     |  |
                     |      --------|                                 |-----|  |   
                     |      |   |-> -----------------------------------        | 
returns IP address          |   |                  |                           |
of DNS server of--------------->|                  |   not found so            |
wikipedia.org               |   |                 \ /     query                |
                     |      |   |   ___________________________________        |
                     |      |   |   |         DNS server for .org     |        |
                     |      |   |   |           domain                |        |
                     |      |   ----|_________________________________|        |
                     |      |                       |                          |
                     |      |                       |                          |
                     |      |                      \ /                         |
                     |      |                                                  |
                     |      |       ------------------------------------       |
                     |      |       |         DNS server wikipedia.org |       |
                     |       ------>|                                  |--------
                     |              |                                  |
                     -------------->|__________________________________|       

35.22.a. Network Diagnostic Utilities I

    A number of basic network utilities are in every system administrator's toolbox, including:

    ping
    Send 64-byte test packets to designated network hosts and (if it finds them) tries to report back on the time required to reach it (in milliseconds), any lost packets, and some other parameters. Note that the exact output will vary according to the host being targeted, but you can at least see that the network is working and the host is reachable.
    traceroute
    Is used to display a network path to a destination. It shows the routers packets flow through to get to a host, as well as the time it takes for each hop.
    mtr
    Combines the functionality of ping and traceroute and creates a continuously updated display, like top.
    dig
    Is useful for testing DNS functionality. Note that one can also use host or nslookup, older programs that also try to return DNS information about a host.

Note that some recent distributions (such as RHEL 7) require root privilege (as with sudo) in order to run the first three diagnostic utilities.

Examples:

$ ping -c 10 linuxfoundation.org

$ traceroute linuxfoundation.org

$ mtr linuxfoundation.org

35.22.b. Network Diagnostic Utilities II

35.22.c. Network Diagnostic Utilities III


36.1. Firewalls - Introduction

     Firewalls are used to control both incoming and outgoing access to your systems and local network, and are an essential security facility in modern networks, where intrusions and other kinds of attacks are a fact of life on any computer connected to the internet. One can control the level of trust afforded on traffic across particular interfaces, and/or with particular network addresses.

36.2. Learning Objectives

    By the end of this chapter, you should be able to:

    Understand what firewalls are and why they are necessary.
    Know what tools are available both at the command line and using graphical interfaces.
    Discuss about firewalld and the firewall-cmd programs.
    Know how to work with zones, sources, services and ports.
    

36.3. What is a firewall?

    A firewall is a network security system that monitors and controls all network traffic. It applies rules on both incoming and outgoing network connections and packets and builds flexible barriers (i.e., firewalls) depending on the level of trust of a given connection.

Firewalls can be hardware or software based. They are found both in network routers, as well as in individual computers, or network nodes. Many firewalls also have routing capabilities.

Early firewalls (dating back to the late 1980's) were based on packet filtering; the content of each network packet was inspected and was either dropped, rejected, or sent on. No consideration was given about the connection state; what stream of traffic the packet was part of.

The next generation of firewalls were based on stateful filters which also examine the connection state of the packet; is it a new connection, part of an already existing one, or part of none. Denial of service attacks can bombard this kind of firewall to try and overwhelm it. 

The third generation of firewalls is called Application Layer Firewalls, and are aware of the kind of application and protocol the connection is using. They can block anything which should not be part of the normal flow.

36.4. Packet Filtering

    Almost all firewalls are based on Packet Filtering.

Information is transmitted\u200b across networks in the form of packets, and each one of these packets has:

    - Header
    - Payload
    - Footer.

The header and footer contain information about destination and source addresses, what kind of packet it is, and which protocol it obeys, various flags, which packet number this is in a stream, and \u200ball sorts of other metadata about transmissions. The actual data is in the payload.

Packet filtering intercepts packets at one or more stages in the network transmission, including application, transport, network, and datalink.

A firewall establishes a set of rules by which each packet may be:

    - Accepted or rejected based on content, address, etc.\u200b
    - Mangled in some way
    - Redirected to another address
    - Inspected for security reasons
    - Etc.

Various utilities exist for establishing rules and actions to be taken as the result of packet filtering.

36.5. Frewall Generations

    Early firewalls (dating back to the late 1980's) were based on packet filtering: the content of each network packet was inspected and was either dropped, rejected, or sent on. No consideration was given about the connection state: what stream of traffic the packet was part of.

The next generation of firewalls were based on stateful filters, which also examine the connection state of the packet, to see if it is a new connection, \u200bpart of an already existing one, or part of none. Denial of service attacks can bombard this kind of firewall to try and overwhelm it.

The third generation of firewalls is called Application Layer Firewalls, and are aware of the kind of application and protocol the connection is using. They can block anything which should not be part of the normal flow.\u200b

36.6. Firewall Interfaces and Tools

    Configuring your system's firewall can be done by:

    - Using relatively low-level tools from the command line, combined with editing various configuration files in the /etc subdirectory tree:

      - iptables

      - firewall-cmd

      - ufw

    - Using robust graphical interfaces:

      - system-config-firewall

      - firewall-config

      - gufw

      - yast

We will work with the lower-level tools for the following reasons:

    - They change less often than the graphical ones.
    - They tend to be have a larger set of capabilities.
    - They tend to be quite different and each confined to GUI. They vary little from distribution to distribution, while the only one family of distributions.

The disadvantage is they can seem more difficult to learn at first. In the following we will concentrate on the use of the modern firewalld package, which includes both firewall-cmd and firewall-config. For distributions which don't have it by default (such as RHEL 6) it can be installed from source rather easily, as we will do if necessary in an exercise.

36.7. Why We Are Not Woring with iptables

    Most firewall installations today are actually using the iptables package on the user side. This currently interfaces the same kernel firewall implementation code as firewalld, which we will discuss in more detail. 

We have decided not to teach iptables because it requires much more time to get to useful functionality.

However, iptables is discussed in detail in the next course in the Linux Foundation system administrator sequence: LFS311 - Advanced Linux System Administration and Networking/LFS211 - Linux Networking and Administration.

36.8. firewalld

    firewalld is the Dynamic Firewall Manager. It utilizes network/firewall zones which have defined levels of trust for network interfaces or connections. It supports both IPv4 and IPv6 protocols.

In addition, it separates runtime and permanent (persistent) changes to configuration, and also includes interfaces for services or applications to add firewall rules.

Configuration files are kept in /etc/firewalld and /usr/lib/firewalld; the files in /etc/firewalld override those in the other directory and are the ones a system administrator should work on.

The command line tool is actually firewall-cmd which we will discuss. We recommend that before getting any further, you run:

$ firewall-cmd --help

Usage: firewall-cmd [OPTIONS...]
....
Status Options
   --state                 Return and print firewalld state
   --reload                Reload firewall and keep state information

   --complete-reload       Reload firewall and loose state information
   --runtime-to-permanent  Create permanent from runtime configuration
....

which runs about 200 lines, so it is too long to include here.

However, you will see that almost all options are rather obvious as they are well named. As a service, firewalld replaces the older iptables. It is an error to run both services, firewalld and iptables, at the same time.


36.9.a. firewalld Service Status I

    firewalld is a service which needs to be running to use and configure the firewall, and is enabled/disabled, or started or stopped in the usual way:

$ sudo systemctl [enable/disable] firewalld
$ sudo systemctl [start/stop] firewalld

You can show the current state in either of the following ways:

$ sudo systemctl status firewalld
firewalld.service - firewalld - dynamic firewall daemon
    Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled)
    Active: active (running) since Tue 2015-04-28 12:00:59 CDT; 5min ago
 Main PID: 777 (firewalld)
    CGroup: /system.slice/firewalld.service
             777 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid
Apr 28 12:00:59 CentOS7 systemd[1]: Started firewalld - dynamic firewall daemon.

$ sudo firewall-cmd --state
running

36.9.b firewalld Service Status II

    Note that if you have more than one network interface when using IPv4, you have to turn on ip forwarding. You can do this at runtime by doing either of:

$ sudo sysctl net.ipv4.ip_forward=1
$ echo 1 > /proc/sys/net/ipv4/ip_forward (needs to be run as root to get echo to work properly)

However, this is not persistent. To do that you have to add the following line to /etc/sysctl.conf:

net.ipv4.ip_forward=1

and then reboot or type:

$ sudo sysctl -p

to read in the new setting without rebooting.

36.10.a. Zones I

    firewalld works with zones, each of which has a defined level of trust and a certain known behavior for incoming and outgoing packets. Each interface belongs to a particular zone (normally, it is NetworkManager which informs firewalld which zone is applicable), but this can be changed with firewall-cmd or the firewall-config GUI.

The zones are:

    - drop
        All incoming packets are dropped with no reply. Only outgoing connections are permitted.
    - block
        All incoming network connections are rejected. The only permitted connections are those from within the system.
    - public
        Do not trust any computers on the network; only certain consciously selected incoming connections are permitted.
    - external
        Used when masquerading is being used, such as in routers. Trust levels are the same as in public.
    - dmz (Demilitarized Zone)
        Used when access to some (but not all) services are to be allowed to the public. Only particular incoming connections are allowed.

39.10.b. Zones II

    The zones are (continued):

    - work
        Trust (but not completely) connected nodes to be not harmful. Only certain incoming connections are allowed.
    - home
        You mostly trust the other network nodes, but still select which incoming connections are allowed.
    - internal
        Similar to the work zone.
    - trusted
        All network connections are allowed.

On system installation, most, if not all Linux distributions, will select the public zone as default for all interfaces.

The differences between some of the zones we mentioned are not obvious, and we do not need to go into that much detail here, but note that one should not use a more open zone than necessary.

36.11.a. Zone Management I

    Get the default zone:

$ sudo firewall-cmd --get-default-zone
public

Obtain a list of zones currently being used:

$ sudo firewall-cmd --get-active-zones
public
  interfaces: eno16777736

List all available zones:

$ sudo firewall-cmd --get-zones
block dmz drop external home internal public trusted work

To change the default zone to trusted and then change it back!

$ sudo firewall-cmd --set-default-zone=trusted
success
$ sudo firewall-cmd --set-default-zone=public
success

To assign an interface temporarily to a particular zone:

$ sudo firewall-cmd --zone=internal --change-interface=eno1

success

36.11.b. Zone Management II

    To assign an interface to a particular zone permanently:

$ sudo firewall-cmd --permanent --zone=internal --change-interface=eno1
success

which creates the file /etc/firewalld/zones/internal.xml.

To ascertain the zone associated with a particular interface:

$ sudo firewall-cmd --get-zone-of-interface=eno1
public

Finally, to get all details about a particular zone:

$ sudo firewall-cmd --zone=public --list-all
public (default, active)
  interfaces: eno16777736
  sources:
  services: dhcpv6-client ssh
  ports:
  masquerade: no
  forward-ports:
  icmp-blocks:
  rich rules:

36.12. Source Management

    Any zone can be bound not just to a network interface, but also to particular network addresses. A packet is associated with a zone if:

    It comes from a source address already bound to the zone; or if not,
    It comes from an interface bound to the zone.

Any packet not fitting the above criteria is assigned to the default zone (i.e, usually public).

To assign a source to a zone (permanently):

$ sudo firewall-cmd --permanent --zone=trusted --add-source=192.168.1.0/24
success

This says anyone with an IP address of 192.168.1.x will be added to the trusted zone.

Note that you can remove a previously assigned source from a zone by using the --remove-source option, or change the zone by using --change-source.

You can list the sources bound to a zone with:

$ sudo firewall-cmd --permanent --zone=trusted --list-sources
192.168.1.0/24

In both of the above commands, if you leave out the --permanent option, you get only the current runtime behavior.


36.13.a. Service and Port Management I

    So far, we have assigned particular interfaces and/or addresses to zones, but we haven't delineated what services and ports should be accessible within a zone.

To see all the services available:

$ sudo firewall-cmd --get-services
RH-Satellite-6 amanda-client bacula bacula-client dhcp dhcpv6 dhcpv6-client dns ftp \
high-availability http https imaps ipp ipp-client ipsec kerberos kpasswd ldap ldaps \
libvirt libvirt-tls mdns mountd ms-wbt mysql nfs ntp openvpn pmcd pmproxy pmwebapi \
pmwebapis pop3s postgresql proxy-dhcp radius rpc-bind samba samba-client smtp ssh \
telnet tftp tftp-client transmission-client vnc-server wbem-https

or, to see those currently accessible in a particular zone:

$ sudo firewall-cmd --list-services --zone=public
dhcpv6-client ssh

To add a service to a zone:

$ sudo firewall-cmd --permanent --zone=home --add-service=dhcp
success
$ sudo firewall-cmd --reload

The second command, with --reload, is needed to make the change effective. It is also possible to add new services by editing the files in /etc/firewalld/services.

36.13.b. Service and Port Management II

    Port management is very similar to service management:

$ sudo firewall-cmd --zone=home --add-port=21/tcp
success
$ sudo firewall-cmd --zone=home --list-ports
21/tcp

where by looking at /etc/services we can ascertain that port 21 corresponds to ftp:

$ grep " 21/tcp" /etc/services
ftp                21/tcp


                                                                                Chpt 37

37.1. System Startup and Shutdown - Introduction

37.2. Learning Objectives

    By the end of this chapter, you should be able to:

    - Explain the boot process.
    - Identify several types of boot loaders.
    - Describe what the BIOS does.
    - Identify the relevant configuration files.
    - Describe how the system shuts down and reboots.


37.3. Understanding the Boot Sequence

    The basic steps in the boot sequence are:

        1. The BIOS/UEFI locates and executes the boot program, or boot loader.
        2. The boot loader loads the kernel.
        3. The kernel starts the init process (pid=1).
        4. init manages system initialization, using systemd, Upstart or the older SysVinit startup scripts.

When power is applied to the computer, the computer can only perform the operations the BIOS (Basic Input Output System) orders it to do.

First, the BIOS runs the POST (Power On Self Test), which checks the memory and hardware and then searches a specific location or device for a boot program. Typically, the boot program is found in the device's MBR (Master Boot Record). Control of the computer is then transferred to this boot program (usually GRUB).

The boot program then loads the kernel into the memory and executes it. On x86 platforms (and many others), the kernel first has to decompress itself in place. It then performs hardware checks, gains access to important peripheral hardware, and eventually runs the init process. This first process continues the system startup,  managing either systemd or Upstart., or running appropriate init scripts if SysVinit is being used.

Newer computers are moving to UEFI, a replacement for BIOS, which performs many of the same functions.
