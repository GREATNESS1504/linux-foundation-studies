Data distinctions:
    - Shareable vs non-shareable
        -- lock file:- non-shared; home directories:- shared
    - Variable vs static

Main Directory Layout 1:
    -------------------------------------------------------------------------------------------
    Directory       |        In FHS? |          Purpose
    -------------------------------------------------------------------------------------------
        /                   Yes         Primary directory of the entire file system hierarchy.
        /bin                Yes         Essentially executable programs that must be available in "single user mode".
        /boot               Yes         Files needed to boot the system such as the kernel, initrd or inittramfs images, and
                                        boot configuration files and bootloader programs
        /dev                Yes         Devie Nodes, used to interact with hardware and software devices.
        /etc                Yes         System wide configuration files.
        /home               Yes         User home directories including personal settings, files, etc.
        /lib                Yes         Libraries required by executable binaries in /bin and /sbin.
        /lib64              Yes         64-bit libraries required by executable binaries in /bin and /sbin, for systems which can
                                        run both 32-bit and 64-bit programs
        /media              Yes         Mount points for removable media such as CDs, DVDs, USB sticks etc.
        /mnt                Yes         Temporarily mounted filesystems
        /opt                Yes         Optional application software packages
        /proc               Yes         Virtual pseudo-filesystem giving information about the system and processes running
                                        on it. Can be used to alter system parameters.
        /sys                No          Virtual pseudo-filesystem giving information about the system and processes running
        /root               Yes         Home directory for the root user
                                        on it. Can be used to alter parameters. Similar to a device tree and is part of the Unified Device Model
        /sbin               Yes         Essential system binaries
        /srv                Yes         Site-specific data served up by the system. Seldom used.
        /tmp                Yes         Temporary files; on many distributiona lost across a reboot and may be a ramdisk in memory
        /usr                Yes         Multi-user applications, utilities and data; theoritically read-only.
        /var                Yes         Variable data that changes during system operation.

Main Directory Layout II:

extra compoents of FHS specific to certain distributions include:

/misc: for miscellaneous data, 
/tftpboot: used for booting using tftp

Special folders:
/bin:  
        - executables programs and scripts needed by both system adm ins and non-privileged users,
        - needed in single user mode
        - may contain executable used directoy by scripts
        - may not include any subdirectories
        - programs which must exists in /bin, include:
            - cat, chgrp, chmod, cp, date, dd, df, dmesg, echo, false, hostname, kill, ln, login, mkdir
                mknode, more, mount, mv ps, pwd, rm, rmdir, sed, sh, stty, su, sync, true, umount and uname. 
            - Optinally test, csh, ed, tar, cpio, gunzip, zcat, netstat and ping

/boot:
        - Essential files for booting the system must be in the /boot directory and its subdirectories, two very important ones are:
            - vmlinuz:- compressed linuz kernel
            - initramfs:- the initial RAM Filesystem, which is mounted before the real root filesystem becomes available.
        - Non-essential files include:
            - config:- used when compiling the kernel, here for booking keeping
            - System.map:- the kernel "sysmbol table", which is very useful for debugging.
            - Master boot sectors, other data.

/dev:

        - special device files also known as device nodes.
        - Note:- Network devices don't device nodes and are referenced by name only, e.g.: eth1, wlan0.

/etc:

        - machine specific configuration files.
        - others include: /etc/init.d, contains start up and shutdown scripts when using System V initialization

/lib and /lib64:

        - kernel modules:- /lib/modules/<kernel-version-number>
        - PAM:- /lib/security

/media:

        - on RHEL and SUSE removable media pops up under /run/media

/mnt:
        - Common use for it is mounting of:

            -- NFS, Samba, CIFS, AFS

/proc:
        - The kernel exposes some important data structures through /proc entries.
        - Additionally each active process on the system has its own subdirectory that gives detailed information about the 
            state of the process, the resources it's using, and its history.
        - importsnt pseudo-files like /proc/interrupts, /proc/meminfo, /proc/mounts, and 
            /proc/partitions, gives an up-to-the-moment glimpse of the system hardware.
        - /proc/filesystem, /proc/sys:- provide system configuration information an interfaces.

/sys:
        - used both to gather information about the system, and modify its behaviour while running.

/sbin:
        - contains binaries essential for booting, restoring, and/or repairing inaddition to those binaries in the
            /bin directory. 
        - programs that must be there include:
            -- fdisk, fsck, getty, halt, ifconfig, init, mkfs, mkswap, reboot, route, swapon, update

/tmp:
        - preventing use of this location to create large files systems we issue the followinf command:
            -- systemctl mask tmp.mount, then reboot
/usr:
        - secondary file hierarchy
        - used for files which are not needed for system booting
        - typically contain read-only data
        - contents:- /usr/bin, /usr/etc, /usr/games, /usr/include (Header files to compile applications), /usr/lib
                        /usr/lib64, /usr/local(third-level hierarchy for machine local files), /usr/sbin, /usr/share
                        /usr/src, /usr/tmp
/run:
        - store transient files: those that contain runtime information, which may need to be written early in system startup but don't need 
            to be preserved when rebooting.


Processes, Programs and Threads:
--------------------------------

A process is an executing program and associated resources, including environment, open files, signal handlers, etc. The same program may be executing more than once simultaneously, and thus, be responsible for multiple processes.

At the same time, two or more tasks, or threads of execution, can share various resources, such as their entire memory spaces (or just particular memory areas), open files, etc. When there is an everything shared circumstance, one speaks of a multi-threaded process.

In other operating systems, there may be a big distinction between full heavy weight processes and light weight ones; strictly speaking, the heavy weight process may include a number of light weight processes, or just one of them.

In Linux, the situation is quite different. Each thread of execution is considered individually, the difference between heavy and light having to do only with sharing of resources and somewhat faster context switching between threads of execution.

Unlike some other operating systems, Linux has always done an exceptionally fast job of creating, destroying, and switching between processes. Thus, the model adopted for multi-threaded applications resembles multiple processes; each thread is scheduled individually and normally, as if it were a stand-alone process. This is done instead of involving more levels of complication, such as having a separate method of scheduling among the threads of a process, as well as having a scheduling method between different processes.

At the same time, Linux respects POSIX and other standards for multi-threaded processes; e.g., each thread returns the same process ID (called the thread group ID internally), while returning a distinct thread ID (called the process ID internally). This can lead to confusion for developers, but should be invisible to administrators. 

2.23: /tmp

Putting files here can be disabled with the command:

   $ sudo systemctl mask tmp.mount

2.24.a. /usr 1

- secondary filesystem hierarchy
- used for files not needed for system booting
- contains binaries not needed in single user mode

2.26.a. /run 1

- store transient files: those have information that may be needed to be written early in system startup
- pseudo-filesystem existing only in memory

2.27. Examine main Consumers of Storage



3.5:Processes:-

A process is an instance of a program in execution. It may be in a number of different states, such as running or sleeping. Every process has a pid (Process ID), a ppid (Parent Process ID), and a pgid (Process Group ID). In addition, every process has program code, data, variables, file descriptors, and an environment.

init is usually the first user process run on a system, and thus becomes the ancestor of all subsequent processes running on the system, except for those initiated directly from the kernel (which show up with [] around their name in a ps listing).

If the parent process dies before the child, the ppid of the child is set to 1; i.e., the process is adopted by init. (Note: in recent Linux systems using systemd, the ppid will be set to 2, which corresponds to an internal kernel thread known as kthreadd, which has taken over from init the role of adopter of orphaned children.)

A child process which terminates (either normally or abnormally) before its parent, which has not waited for it and examined its exit code, is known as a zombie (or defunct) process. Zombies have released almost all resources and remain only to convey their exit status. One function of the init process is to check on its adopted children and let those who have terminated die gracefully. Hence, it is sometimes known as the zombie killer, or more grimly, the child reaper.

Processes are controlled by scheduling, which is completely preemptive. Only the kernel has the right to preempt a process; they cannot do it to each other.

For historical reasons, the largest PID has been limited to a 16-bit number, or 32768. It is possible to alter this value by changing /proc/sys/kernel/pid_max, since it may be inadequate for larger servers. As processes are created, eventually they will reach pid_max, at which point they will start again at PID = 300.

3.6:Process Attributes:-

All processes have certain attributes:

    The program being executed
    Context (state)
    Permissions
    Associated resources.

Every process is executing some program. At any given moment, the process may take a snapshot of itself by trapping the state of its CPU registers, where it is executing in the program, what is in the process' memory, and other information. This is the context of the process.

Since processes can be scheduled in and out when sharing CPU time with others (or have to be put to sleep while waiting for some condition to be fulfilled, such as the user to make a request or data to arrive), being able to store the entire context when swapping out the process and being able to restore it upon execution resumption is critical to the kernel's ability to do context switching.

3.7.a:Controlling Processes with ulimit:-

ulimit is a built-in bash command that displays or resets a number of resource limits associated with processes running under a shell. You can see what running ulimit with the -a argument gives us in the screenshot on this page.

Note: If you run this command as root, you will get a somewhat different output.

3.7.b:

A system administrator may need to change some of these values in either direction:

    To restrict capabilities so an individual user and/or process cannot exhaust system resources, such as memory, cpu time or the maximum number of processes on the system.
    To expand capabilities so a process does not run into resource limits; for example, a server handling many clients may find that the default of 1024 open files makes its work impossible to perform.

There are two kinds of limits:

    Hard: The maximum value, set only by the root user, that a user can raise the resource limit to.
    Soft: The current limiting value, which a user can modify but cannot exceed the hard limit.

One can set any particular limit by doing:

$ ulimit [options] [limit]

as in

$ ulimit -n 1600

which would increase the maximum number of file descriptors to 1600.

Note that the changes only affect the current shell. To make changes that are effective for all logged-in users, one needs to modify /etc/security/limits.conf, a very nicely self-documented file, and then reboot.

3.8:Process permissions and setuid:-

Every process has permissions based on which specific user invoked it. In addition, it may also have permissions based on who owns its program file.

As we will explain later in the local security section, programs which are marked with an s execute bit have a different effective user id than their real user id. These are referred to as setuid programs. They run with the user id of the user who owns the program; non-setuid programs run with the permissions of the user who runs them. setuid programs owned by root can be a well-known security problem. 

The passwd program is an example of a setuid program. Any user can run it. When a user executes this program, the process must run with root permission in order to be able to update the write-restricted /etc/passwd and /etc/shadow files where the user passwords are maintained.

3.9:More on Process States:

Processes can be in one of several possible states, the main ones being:

    -->Running
    The process is either currently executing on a CPU or CPU core or sitting in the run queue, eagerly awaiting a new time slice. It will resume running when the scheduler decides it is now deserving to occupy the CPU, or when another CPU becomes idle and the scheduler migrates the process to that CPU.
    -->Sleeping (i.e., Waiting)
    The process is waiting on a request (usually I/O) that it has made and cannot proceed further until the request is completed. When the request is completed, the kernel will wake up the process and put it back on the run queue and it will be given a time slice on a CPU when the scheduler decides to do so.
   -->Stopped
    The process has been suspended. This state is commonly experienced when a programmer wants to examine the executing program's memory, CPU registers, flags, or other attributes. Once this is done, the process may be resumed. This is generally done when the process is being run under a debugger or the user hits Ctrl-Z.
    -->Zombie
    The process enters this state when it terminates, and no other process (usually the parent) has inquired about its exit state; i.e., reaped it. Such a process is also called a defunct process. A zombie process has released all of its resources, except its exit state and its entry in the process table. If the parent of any process dies, the process is adopted by init (PID = 1) or kthreadd (PID = 2).


3.10: Execution Modes:-

At any given time, a process (or any particular thread of a multi-threaded process) may be executing in either user mode or system mode, which is usually called kernel mode by kernel developers.

What instructions can be executed depends on the mode and is enforced at the hardware, not software, level.

The mode is not a state of the system; it is a state of the processor, as in a multi-core or multi-CPU system each unit can be in its own individual state.

In Intel parlance, user mode is also termed Ring 3 and system mode is termed Ring 0.

3.11: User Mode:-

Except when executing a system call (described in the next section), processes execute in user mode, where they have lesser privileges than in kernel mode.

When a process is started, it is isolated in its own user space to protect it from other processes. This promotes security and creates greater stability. This is sometimes called process resource isolation.

Each process executing in user mode has its own memory space, parts of which may be shared with other processes; except for the shared memory segments, a user process is not able to read or write into or from the memory space of any other process.

Even a process run by the root user or as a setuid program runs in user mode, except when jumping into a system call, and has only limited ability to access hardware. 


 ------------------                                               -------------------
|                 |                                               |   Kernel        |
|                 |     System Call                               |   Mode          |
| User Mode       |---------------------------------------------->|                 |
|                 |<----------------------------------------------|                 |
|                 |        Return                                 |                 |
-------------------                                               -------------------                    


3.12: Kernel Mode:-

In kernel (system) mode, the CPU has full access to all hardware on the system, including peripherals, memory, disks, etc. If an application needs access to these resources, it must issue a system call, which causes a context switch from user mode to kernel mode. This procedure must be followed when reading and writing from files, creating a new process, etc.  

Application code never runs in kernel mode, only the system call itself which is kernel code. When the system call is complete, a return value is produced and the process returns to user mode with the inverse context switch.

There are other times when the system is in kernel mode that have nothing to do with processes, such as when handling hardware interrupts or running the scheduling routines and other management tasks for the system.

3.13: Daemons:-

A daemon process is a background process whose sole purpose is to provide some specific service to users of the system:

    Daemons can be quite efficient because they only operate when needed.
    Many daemons are started at boot time.
    Daemon names often (but not always) end with d.
    Some examples include httpd and systemd-udevd.
    Daemons may respond to external events (systemd-udevd) or elapsed time (crond).
    Daemons generally have no controlling terminal and no standard input/output devices.
    Daemons sometimes provide better security control.

When using SysVinit, scripts in the /etc/init.d directory start various system daemons. These scripts invoke commands as arguments to a shell function named daemon, defined in the /etc/init.d/functions file.

3.14: Creating Processes in a Command Shell:-

What happens when a user executes a command in a command shell interpreter, such as bash?

    A new process is created (forked from the user's login shell).
    A wait system call puts the parent shell process to sleep.
    The command is loaded onto the child process's space via the exec system call. In other words, the code for the command replaces the bash program in the child process's memory space.
    The command completes executing, and the child process dies via the exit system call.
    The parent shell is re-awakened by the death of the child process and proceeds to issue a new shell prompt. The parent shell then waits for the next command request from the user, at which time the cycle will be repeated.

If a command is issued for background processing (by adding an ampersand -&- at the end of the command line), the parent shell skips the wait request and is free to issue a new shell prompt immediately, allowing the background process to execute in parallel. Otherwise, for foreground requests, the shell waits until the child process has completed or is stopped via a signal.

Some shell commands (such as echo and kill) are built into the shell itself, and do not involve loading of program files. For these commands, no fork or exec are issued for the execution.

3.15: Kernel-Created Processes:-

Not all processes are created, or forked from user parents. The Linux kernel directly creates two kinds of processes on its own initiative. These are:

    Internal kernel processes:
    These take care of maintenance work, such as making sure buffers get flushed out to disk, that the load on different CPUs is balanced evenly, that device drivers handle work that has been queued up for them to do, etc. These processes often run as long as the system is running, sleeping except when they have something to do. 
    External user processes
    These are processes which run in user space like normal applications but which the kernel started. There are very few of these and they are usually short lived.

It is easy to see which processes are of this nature; when you run a command such as

$ ps -elf

to list all processes on the system while showing the parent process IDs, they will all have  PPID = 2, which refers to kthreadd, the internal kernel thread whose job is to create such processes, and their names will be encapsulated in square brackets, such as [ksoftirqd/0].

3.16: Process Creating and Forking:-

An average Linux system is always creating new processes. This is often called forking; the original parent process keeps running while the new child process starts.

When most computers had only single processors, they were usually configured so the parent would initially pause while the child started to run; there is a UNIX expression:  "Children come first."  However, with modern multi-CPU systems, both will tend to run simultaneously on different CPUs.

Often rather than just a fork, one follows it with an exec, where the parent process terminates and the child process inherits the process ID of the parent. The term fork and exec is used so often, people think of it sometimes as one word.

Older UNIX systems often used a program called spawn, which is similar in many ways to fork and exec, but differs in details. It is not part of the POSIX standard, and is not a normal part of Linux.

To see how new processes may start, consider a web server that handles many clients. It may launch a new process every time a new connection is made with a client. On the other hand, it may simply start only a new thread as part of the same process; in Linux, there really isn't much difference on a technical level between creating a full process or just a new thread, as each mechanism takes about the same time and uses roughly the same amount of resources.

As another example, the sshd daemon is started when the init process executes the sshd init script, which then is responsible for launching the sshd daemon. This daemon process listens for ssh requests from remote users.

When a request is received, sshd creates a new copy of itself to service the request. Each remote user gets their own copy of the sshd daemon running to service their remote login. The sshd process will start the login program to validate the remote user. If the authentication succeeds, the login process will fork off a shell (say bash) to interpret the user commands, and so on. 

3.17.a.: Using nice to Set Priorities:-

Process priority can be controlled through the nice and renice commands. Since the early days of UNIX, the idea has been that a nice process lowers its priority to yield to others. Thus, the higher the niceness is, the lower the priority.

The niceness value can range from -20 (the highest priority) to +19 (the lowest priority). The normal way to run nice is as in:

$ nice -n 5 command [ARGS]

which would increase the niceness by 5. This is equivalent to doing:

$ nice -5 command [ARGS] 

3.17.b.: Using nice to Set Priorities:-

If you do not give a nice value, the default is to increase the niceness by 10. If you give no arguments at all, you report your current niceness. So, for example:

$ nice
0
$ nice cat &
[1] 24908
$ ps -l
F S UID   PID  PPID C PRI NI ADDR SZ WCHAN  TTY          TIME CMD
0 S 500  4670  4603 0 80   0 - 16618 wait   pts/0    00:00:00 bash
0 S 500 24855  4670 0 80   0 - 16560 wait   pts/0    00:00:00 bash
0 T 500 24908 24855 0 90  10 - 14738 signal pts/0    00:00:00 cat
0 R 500 24909 24855 0 80   0 - 15887 -      pts/0    00:00:00 ps

Note that increasing the niceness of a process does not mean it won't run; it may even get all the CPU time if there is nothing else with whitch to compete.

If you supply such a large increment or decrement that you try to step outside the -20 to 19 range, the increment value will be truncated.

3.18: Modifying the Nice Value:-

By default, only a superuser can decrease the niceness; i.e., increase the priority. However, it is possible to give normal users the ability to decrease their niceness within a predetermined range, by editing /etc/security/limits.conf.

To change the niceness of an already running process, it is easy to use the renice command, as in:

$ renice +3 13848

which will increase niceness by 3 of the process with pid  =  13848. More than one process can be done at the same time and there are some other options, so see man renice. 

See 'man nice'

3.20.: Static and Shared Libraries:-

Programs are built using libraries of code, developed for multiple purposes and used and reused in many contexts.

There are two types of libraries:

    Static
    The code for the library functions is inserted in the program at compile time, and does not change thereafter, even if the library is updated.
    Shared
    The code for the library functions is loaded into the program at run time, and if the library is changed later, the running program runs with the new library modifications.

Using shared libraries is more efficient because they can be used by many applications at once; memory usage, executable sizes, and application load time are reduced.

Shared Libraries are also called DLLs (Dynamic Link Library).

3.21.: Shared Libraries Versions:-

Shared libraries need to be carefully versioned. If there is a significant change to the library and a program is not equipped to handle it, serious problems can be expected. This is sometimes known as DLL Hell.

Therefore, programs can request a specific major library version rather than the latest one on the system. However, usually the program will always use the latest minor version available.

Some application providers will use static libraries bundled into the program to avoid these problems. However, if there are improvements or bugs and security holes fixed in the libraries, they may not make it into the applications in a timely fashion.

Shared libraries have the extension .so. Typically, the full name is something like libc.so.N  where N is a major version number.

Under Linux, shared libraries are carefully versioned. For example:

c7:/usr/lib64>ls -lF libgdbm.so*

lrwxrwxrwx 1 root root 16 Apr 9 2015 libgdbm.so -> libgdbm.so.4.0.0*

lrwxrwxrwx 1 root root 16 Apr 9 2015 libgdbm.so.4 -> libgdbm.so.4.0.0*

-rwxr-xr-x 1 root root 36720 Jan 24 2014 libgdbm.so.4.0.0*

c7:/usr/lib64>

so a program that just asks for libgdm  gets  libgdm.so  and the others for specific major and minor versions.

3.22.a.: Finding Shared Libraries:-

A program which uses shared libraries has to be able to find them at runtime.

ldd can be used to ascertain what shared libraries an executable requires. It shows the soname of the library and what file it actually points to.

3.22.b.: Finding Shared Libraries:-

ldconfig is generally run at boot time (but can be run anytime), and uses the file /etc/ld.so.conf, which lists the directories that will be searched for shared libraries. ldconfig must be run as root and shared libraries should only be stored in system directories when they are stable and useful.

Besides searching the data base built up by ldconfig, the linker will first search any directories specified in the environment variable LD_LIBRARY_PATH, a colon separated list of directories, as in the PATH variable. So, you can do:

$ LD_LIBRARY_PATH=$HOME/foo/lib

$ foo [args]

or

$ LD_LIBRARY_PATH=$HOME/foo/lib foo [args]

4.3: What Are Signals?

Signals are one of the oldest methods of Inter-Process Communication (IPC) and are used to notify processes about asynchronous events (or exceptions).

By asynchronous, we mean the signal-receiving process may:

    Not expect the event to occur.
    Expect the event, but not know when it is most likely to occur.

For example, if a user decides to terminate a running program, it could send a signal to the process through the kernel to interrupt and kill the process.

There are two paths by which signals are sent to a process:

    From the kernel to a user process, as a result of an exception or programming error.
    From a user process (using a system call) to the kernel which will then send it to a user process. The process sending the signal can actually be the same as the one receiving it.

Signals can only be sent between processes owned by the same user or from a process owned by the superuser to any process.

When a process receives a signal, what it does will depend on the way the program is written. It can take specific actions, coded into the program, to handle the signal or it can just respond according to system defaults. Two signals (SIGKILL and SIGSTOP) cannot be handled and will always terminate the program.



4.4.a.: Types of Signals:-

There are a number of different types of signals, and the particular signal which is dispatched indicates what type of event (or exception) occurred. Generally, signals are used to handle two things:

    Exceptions detected by hardware (such as an illegal memory reference)
    Exceptions generated by the environment (such as the premature death of a process from the user's terminal).

To see a list of the signals in Linux, along with their numbers, do kill -l, as reflected in this screenshot.

The signals from SIGRTMIN on are termed real-time signals and are a relatively recent addition. They have no predefined purpose, and differ in some important ways from normal signals; they can be queued up and are handled in a FIFO (First In First Out) order.

The meaning attached to the signal type indicates what event caused the signal to be sent. While users can explicitly send any signal type to one of their processes, the meaning attached may no longer be implied by the signal number or type, and can be used in any way that the process desires.

Typing man 7 signal will give further documentation.

Signal                          Value   DefaultAction           POSIX?          Meaning
SIGHUP                          1       Terminate               Yes             Hangup  detected on controlling terminal or death of controlling  process.
SIGINT                          2       Terminate               Yes             Interrupt  from   keyboard.
SIGQUIT                         3       Cordump                 Yes             Quit from keyboard.
SIGILL                          4       Coredump                Yes             Illegal Instruction.
SIGTRAP                         5       Coredump                No              Trace/breakpoint trap for debugging.
SIGABRT
SIGIOT                          6       Coredump                Yes             Abnormal termination.
SIGBUS                          7       Coredump                Yes             Bus error.
SIGFPE                          8       Coredump                Yes             Floating point exception.
SIGKILL                         9       Terminate               Yes             Kill signal (can not be caught or ignored).
SIGUSR1                         10      Terminate               Yes             User-definedsignal 1.
SIGSEGV                         11      Coredump                Yes             Invalid memory reference.
SIGUSR2                         12      Terminate               Yes             User-defined signal 2.
SIGPIPE                         13      Terminate               Yes             Broken pipe: write to pipe with no readers.
SIGALRM                         14      Terminate               Yes             Timer  signal from alarm.
SIGTERM                         15      Terminate               Yes             Process termination.
SIGSTKFLT                       16      Terminate               No              Stack fault on math co-processor.
SIGCHLD                         17      Ignore                  Yes             Child stopped or terminated.
SIGCONT                         18      Continue                Yes             Continue if stopped.
SIGSTOP                         19      Stop                    Yes             Stop process (can not be caught or ignored).
SIGTSTP                         20      Stop                    Yes             Stop types at tty.
SIGTTIN                         21      Stop                    Yes             Background process requires tty input.
SIGTTOU                         22      Stop                    Yes             Background process requires tty output.
SIGURG                          23      Ignore                  No              Urgent condition on socket (4.2 BSD).
SIGXCPU                         24      Coredump                Yes             CPU time limit exceeded (4.2 BSD).
SIGXFSZ                         25      Coredump                Yes             File size limit exceeded (4.2 BSD).
SIGVTALRM                       26      Terminate               No              Virtual alarm clock (4.2 BSD).
SIGPROF                         27      Terminate               No              Profile alarm clock (4.2 BSD).
SIGWINCH                        28      Ignore                  No              Window resize signal (4.3 BSD, Sun).
SIGIO
SIGPOLL                         29      Terminate               No              I/O now possible (4.2 BSD) (System V).
SIGPWR                          30      Terminate               No              Power Failure (System V).
SIGSYS
SIGUNUSED                       31      Terminate               No              Bad System Called. Unused signal.

4.5: kill:-

A process cannot send a signal directly to another process; it must ask the kernel to send the signal by executing a system call. Users (including the superuser) can send signals to other processes from the command line or scripts by using kill as in:

$ kill 1991

$ kill -9 1991

$ kill -SIGKILL 1991

where we are sending a signal to the process with PID = 1991. If a signal number is not given (as in the first example), the default is to send SIGTERM (15), a terminate signal that can be handled; the program can take elusive action or clean up after itself, rather than just die immediately. If this signal is ignored, the user can usually send a SIGKILL (9), which cannot be ignored, to terminate with extreme prejudice.

The name kill is really a bad name, a misnomer that survives for historical reasons. Although it is often used to kill (terminate) processes, the command's real function is to send any and all signals to processes, even totally benign informative ones.

4.6.: killall and pkill:-

killall kills all processes with a given name, assuming the user has sufficient privilege. It uses a command name rather than a process ID, and can be done as in:

$ killall bash

$ killall -9 bash

$ killall -SIGKILL bash

pkill sends a signal to a process using selection criteria:

$ pkill [-signal] [options] [pattern]

For example:

$ pkill -u libby foobar

will kill all of libby's processes with a name of foobar.

Another example:

$ pkill -HUP rsyslogd

makes rsyslog re-read its configuration file.

5.1. Package Management Systems

- APT: Advanced Packageing Tool
- RPM: Redhat Package Management

- Levels:
    - Low level:
        - rpm
        - dpkg
    - Higher level:
        - yum, dnf, zypper
        - apt-get apt

5.3. Software Packaging Concepts:

- Allows for automating installations, upgrading, configuring and removing software packages in a known predictable, consistent manner.
- These systems:
    - gather and compress associated software files into single package (archive), which may require one or more packages to be installed first
    - allow for easy software installation or removal,
    - can verify file integrity via an internal database
    - can authenticate the origin of the packages.
    - facilitate upgrades
    - group packages by logical features
    - manage dependencies between packages

5.4. Why Use Packages:

Software package management systems are widely seen as one of the biggest advancements Linux brought to enterprise IT environments. By keeping track of files and metadata in an automated, predictable and reliable way, system administrators can use package management systems to make their installation processes scale to thousands of systems without requiring manual work on each individual system. Features include:

    Automation:  No need for manual installs and upgrades.
    Scalability:  Install packages on one system, or 10,000 systems.
    Repeatability and predictability.
    Security and auditing.

5.5. Package Types

Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. ackages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. Packages come in several different types:

    Binary packages contain files ready for deployment, including executable files and libraries. These are architecture-dependent and must be compiled for each type of machine.
    Source packages are used to generate binary packages; one should always be able to rebuild a binary package (for example, by using rpmbuild --rebuild on RPM-based systems) from the source package. One source package can be used for multiple architectures.
    Architecture-independent packages contain files and scripts that run under script interpreters, as well as documentation and configuration files.
    Meta-packages are essentially groups of associated packages that collect everything needed to install a relatively large subsystem, such as a desktop environment, or an office suite, etc.

Binary packages are the ones that system administrators have to deal with most of the time.

On 64-bit systems that can run 32-bit programs, one may have two binary packages installed for a given program, perhaps one with x86_64 or amd64 in its name, and the other with i386 or i686 in its name.

Source packages can be helpful in keeping track of changes and source code used to come up with binary packages. They are usually not installed on a system by default, but can always be retrieved from the vendor. 


5.6. Available Package Management Systems:

There are two very common package management systems:

    RPM (Red Hat Package Manager)
    This system is used by all Red Hat-derived distributions, such as Red Hat Enterprise Linux, CentOS, Scientific Linux and CentOS, as well as by SUSE and its related community openSUSE distribution.
    dpkg (Debian Package)
    This system is used by all Debian-derived distributions ,including Debian, Ubuntu and Linux Mint.

There are other package management systems, such as portage/emerge used by Gentoo, pacman used by Arch, and specialized ones used by Embedded Linux systems and Android.

Another ancient system is just to supply packages as tarballs without any real management or clean removal strategies; this approach still marks Slackware, one of the oldest Linux distributions.

But most of the time, it is either RPM or dpkg and these are the only ones we will consider in this course.


5.7. Packaging Tool Levels and Varieties

There are two levels to packaging systems:

    Low Level Utility
    This simply installs or removes a single package, or a list of packages, each one of which is individually and specifically named. Dependencies are not fully handled, only warned about:
    - If another package needs to be installed, first installation will fail.
    - If the package is needed by another package, removal will fail.
    The rpm and dpkg utilities play this role for the packaging systems that use them.
    High Level Utility
    This solves the dependency problems:
    - If another package or group of packages needs to be installed before software can be installed, such needs will be satisfied.
    - If removing a package interferes with another installed package, the administrator will be given the choice of either aborting, or removing all affected software.
    The yum, dnf, and zypper utilities (and more recently, PackageKit) take care of the dependency resolution for rpm systems, and apt-get and apt-cache and other utilities take care of it for dpkg systems.

In this course, we will only discuss the command line interface to the packaging systems; while the graphical frontends used by each Linux distribution can be useful, we would like to be less tied to any one interface and have more flexibility. 

5.8. Package Soures

Every distribution has one or more package repositories where system utilities go to obtain software and to update with new versions. It is the job of the distribution to make sure all packages in the repositories play well with each other.

There are always other, external repositories, which can be added to the standard distribution-supported list. Sometimes, these are closely associated with the distribution, and only rarely produce significant problems; an example would be the EPEL (Extra Packages for Enterprise Linux) set of version-dependent repositories, which fit well with RHEL since their source is Fedora and the maintainers are close to Red Hat.

However, some external repositories are not very well constructed or maintained. For example, when a package is updated in the main repository, dependent packages may not be updated in the external one, which can lead to one form of dependency hell. 

5.11. Available Source Control Systems

There is no shortage of available products, both proprietary and open; a brief list of products released under a GPL license includes:

 
Product 	URL
==========================
RCS	        http://www.gnu.org/software/rcs
CVS	        http://ximbiot.com/cvs/wiki 
Subversion	http://subversion.tigris.org 
git	        http://www.kernel.org/pub/software/scm/git
GNU Arch	http://www.gnu.org/software/gnu-arch 
Monotone	http://www.monotone.ca
Mercurial	http://mercurial-scm.org/
PRCS	    http://prcs.sourceforge.net

 

We will focus only on git, a widely used product which arose from the Linux kernel development community. git has risen to a dominant position in use for open source projects in a remarkably short time, and is often used even in closed source environments.


5.12 The Linux Kernel and the Birth of git

The Linux kernel development system has special needs in that it is widely distributed throughout the world, with literally thousands of developers involved. Furthermore it is all done very publicly, under the GPL license.

For a long time, there was no real source revision control system. Then, major kernel developers went over to the use of BitKeeper (see http://www.bitkeeper.com), a commercial project which granted a restricted use license for Linux kernel development.

However, in a very public dispute over licensing restrictions in the spring of 2005, the free use of BitKeeper became unavailable for Linux kernel development.

The response was the development of git, whose original author was Linus Torvalds. The source code for git can be obtained from http://www.kernel.org/pub/software/scm/git/, and full documentation can be found at http://www.kernel.org/pub/software/scm/git/docs/.

5.13. How git works

Technically, git is not a source control management system in the usual sense, and the basic units it works with are not files. It has two important data structures: an object database and a directory cache.

The object database contains objects of three varieties:

    Blobs: Chunks of binary data containing file contents
    Trees: Sets of blobs including file names and attributes, giving the directory structure
    Commits: Changesets describing tree snapshots.

The directory cache captures the state of the directory tree.

By liberating the controls system from a file-by-file-based system, one is better able to handle changesets which involve many files.

git is always under rapid development and graphical interfaces to it are also under speedy construction. For example, see http://www.kernel.org/git/. One can easily browse particular changes, as well as source trees.

Sites such as http://www.github.com now host literally millions of git repositories, both public and private. There are a host of easy-to-find articles, books, online tutorials, etc., on how to profitably use git.


6.2. Laerning Objectives

By the end of this chapter, you should be able to:

    Understand how the RPM system is organized and what major operations the rpm program can accomplish.
    Explain the naming conventions used for both binary and source rpm files.
    Know how to query, verify, install, uninstall, upgrade and freshen packages.
    Grasp why new kernels should be installed rather than upgraded.
    Know how to use rpm2cpio to copy packaged files into a cpio archive, as well as to extract the files without installing them.


6.3. RPM

RPM (the Red Hat Package Manager) was developed (unsurprisingly) by Red Hat. All files related to a specific task are packaged into a single rpm file, which also contains information about how and where to install and uninstall the files. New versions of software lead to new rpm files which are then used for updating.

rpm files also contain dependency information. Note that unless given a specific URL to draw from, rpm in itself does not retrieve packages over the network and installs only from the local machine using absolute or relative paths.

rpm files are usually distribution-dependent; installing a package on a different distribution than it was created for can be difficult, if not impossible. 


6.4. Advantages of Using RPM

For system administrators, RPM makes it easy to:

    Determine what package (if any) any file on the system is part of.
    Determine what version is installed.
    Install and uninstall (erase) packages without leaving debris behind.
    Verify that a package was installed correctly; this is useful for both troubleshooting and system auditing.
    Distinguish documentation files from the rest of the package and optionally decide not to install them to save space.
    Use ftp or HTTP to install packages over the Internet.

For developers RPM offers advantages as well:

    Software often is made available on more than one operating system. With RPM the original full and unmodified source is used as the basis, but a developer can separate out the changes needed to build on Linux.
    More than one architecture can be built using only one source package.

6.5. Package File Names

RPM package file names are based on fields that represent specific information, as documented in the RPM standard  (http://www.rpm.org/)

    - The standard naming format for a binary package is:
    <name>-<version>-<release>.<distro>.<architecture>.rpm
    sed-4.2.1-10.el6.x86_64.rpm
    - The standard naming format for a source package is:
    <name>-<version>-<release>.<distro>.src.rpm
    sed-4.2.1-10.el6.src.rpm

Note that the distro field often actually specifies the repository that the package came from, as a given installation may use a number of different package repositories as we shall discuss when we discuss yum and zypper which work above RPM.

6.6. Database Directory

/var/lib/rpm is the default system directory which holds RPM database files in the form of  Berkeley DB hash files. The database files should not be manually modified; updates should be done only through use of the rpm program.

An alternative database directory can be specified with the --dbpath option to the rpm program. One might do this, for example, to examine an RPM database copied from another system.

You can use the --rebuilddb option to rebuild the database indices from the installed package headers; this is more of a repair, and not a rebuild from scratch.

6.7. Helper Programs and Modifying Settings

Helper programs and scripts used by RPM reside in /usr/lib/rpm. There are quite a few; for example on a RHEL 7 system: 

$ ls /usr/lib/rpm | wc -l

73

where wc is reporting the number of lines of output.

You can create an rpmrc file to specify default settings for rpm. By default, rpm looks for:

    /usr/lib/rpm/rpmrc
    /etc/rpmrc
    ~/.rpmrc

in the above order. Note all these files are read; rpm does not stop as soon as it finds that one exists. An alternative rpmrc file can be specified using the --rcfile option.

6.8.a. Queries I

All rpm inquiries include the -q option, which can be combined with numerous sub-options, as in:

    Which version of a package is installed?
    $ rpm -q bash
    Which package did this file come from?
    $ rpm -qf /bin/bash
    What files were installed by this package?
    $ rpm -ql bash
    Show information about this package.
    $ rpm -qi bash
    Show information about this package from the package file, not the package database.
    $ rpm -qip foo-1.0.0-1.noarch.rpm
    List all installed packages on this system.
    $ rpm -qa 

6.8.b. Queries II

A couple of other useful options are --requires and --whatprovides:

    Return a list of prerequisites for a package:
    $ rpm -qp --requires foo-1.0.0-1.noarch.rpm
    Show what installed package provides a particular requisite package:
    $ rpm -q --whatprovides libc.so.6 

6.9.a. Verifying Pacakages I

The -V option to rpm allows you to verify whether the files from a particular package are consistent with the system's RPM database. To verify all packages installed on the system:

$ rpm -Va
missing   /var/run/pluto
....
S.5....T. c /etc/hba.conf
S.5....T. /usr/share/applications/defaults.list
....L.... c /etc/pam.d/fingerprint-auth
....L.... c /etc/pam.d/password-auth
....
.M....... /var/lib/nfs/rpc_pipefs
....
.....UG.. /usr/local/bin
.....UG.. /usr/local/etc

showing just a few items. (Note this command can take a long time, as it examines all files owned by all packages.)

Output is generated only when there is a problem. 


6.9.b. Verifying Packages II

Each of the characters displayed on the previous page denotes the result of a comparison of attribute(s) of the file to the value of
those attribute(s) recorded in the database. A single . (period) means the test passed, while a single ? (question mark) indicates the test could not be performed (e.g. file permissions prevent reading). Otherwise, the character denotes failure of the corresponding verification test:

    S: file size differs
    M: file permissions and/or type differs
    5: MD5 checksum differs
    D: device major/minor number mismatch
    L: symbolic link path mismatch
    U: user ownership differs
    G: group ownership differs
    T: modification time differs
    P: capabilities differ

Note that many of these verification tests do not indicate a problem. For example, many configuration files are modified as the system evolves.

6.9.c. Verifying Packages III

If you specify one or more package names as an argument, you examine only that package as in the following examples:

    No output when everything is OK:
    $ rpm -V bash
    Output indicating that a file's size, checksum, and modification time have changed:
    $ rpm -V talk
    S.5....T in.ntalkd.8
    Output indicating that a file is missing:
    $ rpm -V talk
    missing /usr/bin/talk

6.10. Installing Packages

Installing a package is as simple as:

$ sudo rpm -ivh foo-1.0.0-1.noarch.rpm

where the -i is for install, -v is for verbose, and -h just means print out hash marks while doing to show progress.

RPM performs a number of tasks when installing a package:

    Performs dependency checks:
    Necessary because some packages will not operate properly unless one or more other packages are also installed.
    Performs conflict checks:
    Include attempts to install an already-installed package or to install an older version over a newer version.
    Executes commands required before installation:
    The developer building a package can specify that certain tasks be performed before or after the install.
    Deals intelligently with configuration files:
    When installing a configuration file, if the file exists and has been changed since the previous version of the package was installed, RPM saves the old version with the suffix .rpmsave. This allows you to integrate the changes you have made to the old configuration file into the new version of the file. This feature depends on properly created RPM packages.
    Unpacks the files from packages and installs them with correct attributes:
    In addition to installing files in the right place, RPM also sets attributes such as permissions, ownership, and modification (build) time.
    Executes commands required after installation:
    Performs any post-install tasks required for setup or initialization
    Updates the system RPM database:
    Every time RPM installs a package, it updates information in the system database. It uses this information when checking for conflicts.

6.11.a. Uninstalling Packages I

The -e option causes rpm to uninstall (erase) a package. Normally, rpm -e fails with an error message if the package you are attempting to uninstall is either not actually installed, or is required by other packages on the system. A successful uninstall produces no output.

$ sudo rpm -e system-config-lvm

package system-config-lvm is not installed


6.11.b. Uninstalling Packages II

You can use the --test option along with -e to determine whether the uninstall would succeed or fail, without actually doing the uninstall. If the operation would be successful, rpm prints no output. Add the -vv option to get more information.

Remember the package argument for the erase is the package name, not the rpm file name.

Important (but obvious) note: Never remove (erase/uninstall) the rpm package itself. The only way to fix this problem is to re-install the operating system, or by booting into a rescue environment.

6.13. Upgrading Packages

Upgrading replaces the original package (if installed) as in:

$ sudo rpm -Uvh bash-4.2.45-5.el7_0.4.x86_64.rpm

You can give a list of package names, not just one.

When upgrading, the already installed package is removed after the newer version is installed. The one exception is the configuration files from the original installation, which are kept with a .rpmsave extension.

If you use the -U option and the package is not already installed, it is simply installed and there is no error.

The -i option is not designed for upgrades; attempting to install a new RPM package over an older one fails with error messages, because it tries to overwrite existing system files.

However, different versions of the same package may be installed if each version of the package does not contain the same files: kernel packages and library packages from alternative architectures are typically the only packages that would be commonly installed multiple times.

If you want to downgrade with rpm -U (that is, to replace the current version with an earlier version), you must add the --oldpackage option to the command line.

6.14. Freshening Packages

The command:

$ sudo rpm -Fvh *.rpm

will attempt to freshen all the packages in the current directory. The way this works is:

    If an older version of a package is installed, it will be upgraded to the newer version in the directory.
    If the version on the system is the same as the one in the directory, nothing happens.
    If there is no version of a package installed, the package in the directory is ignored. 

Freshening can be useful for applying a lot of patches (i.e., upgraded packages) at once.


6.15. Upgrading the Kernel

When you install a new kernel on your system, it requires a reboot (one of the few updates that do) to take effect. You should not do an upgrade (-U) of a kernel: an upgrade would remove the old currently running kernel.

This in and of itself won't stop the system, but if, after a reboot, you have any problems, you will no longer be able to reboot into the old kernel, since it has been removed from the system. However, if you install (-i), both kernels coexist and you can choose to boot into either one; i.e., you can revert back to the old one if need be.

To install a new kernel do:

$ sudo rpm -ivh kernel-{version}.{arch}.rpm

filling in the correct version and architecture names.

When you do this, the GRUB configuration file will automatically be updated to include the new version; it will be the default choice at boot, unless you reconfigure the system to do something else.

Once the new kernel version has been tested, you may remove the old version if you wish, though this is not necessary. Unless you are short on space, it is recommended that you keep one or more older kernels available.


6.16. Using rpm2cpio

Suppose you have a need to extract files from an rpm but do not want to actually install the package?

The rpm2cpio program can be used to copy the files from an rpm to a cpio archive, and also extract the files if so desired.

Create the cpio archive with:

$ rpm2cpio foobar.rpm > foobar.cpio

To list files in an rpm:

$ rpm2cpio foobar.rpm | cpio -t

but a better way is to do:

$  rpm -qilp foobar.rpm

To extract onto the system:

$ rpm2cpio bash-4.2.45-5.el7_0.4.x86_64.rpm |  cpio -ivd bin/bash

$ rpm2cpio foobar.rpm | cpio --extract --make-directories


7.1. DPKG - Introduction

The Debian Package Manager (DPKG) is used by all Debian-based distributions to control the installation, verification, upgrade, and removal of software on Linux systems. The low-level dpkg program can perform all these operations, either on just one package, or on a list of packages. Operations which would cause problems (such as removing a package that another package depends on, or installing a package when the system needs other software to be installed first) are blocked from completion.


7.2. learning Objectives

By the end of this chapter, you should be able to:

    Discuss the DPKG packaging system and its uses.
    Explain the naming conventions used for both binary and source deb files.
    Know what source packages look like.
    Use querying and verifying operations on packages.
    Install, upgrade, and uninstall Debian packages.

7.3. DPKG Essentials

DPKG (Debian Package) is the packaging system used to install, remove, and manage software packages under Debian Linux and other distributions derived from it. Like RPM, it is not designed to directly retrieve packages in day-to-day use, but to install and remove them locally.

Package files have a .deb suffix and the DPKG database resides in the /var/lib/dpkg directory.

Like rpm, the dpkg program has only a partial view of the universe: it knows only what is installed on the system, and whatever it is given on the command line, but knows nothing of the other available packages, whether they are in some other directory on the system, or out on the Internet. As such, it will also fail if a dependency is not met, or if one tries to remove a package other installed packages need. 


7.4. Package File Names

Debian package file names are based on fields that represent specific information. The standard naming format for a binary package is:

<name>_<version>-<revision_number>_<architecture>.deb

as in:

logrotate_3.8.7-1_amd64.deb

on Debian, and

logrotate_3.8.7-1ubuntu1_amd64.deb

on Ubuntu. Note that, for historical reasons, the 64-bit x86 platform is called amd64 rather than x86_64, and distributors such as Ubuntu manage to insert their name in the package name.


7.5.a. Source Packages I

In the Debian packaging system, a source package consists of at least three files:

    An upstream tarball, ending with .tar.gz. This is the unmodified source as it comes from the package maintainers.
    A description file, ending with .dsc, containing the package name and other metadata, such as architecture and dependencies.
    A second tarball that contains any patches to the upstream source, and additional files created for the package, and ends with a name .debian.tar.gz or .diff.gz, depending on distribution.

7.6. DPKG Queries

Here are some examples of queries you can make:

    List all packages installed:
    $ dpkg -l
    One can also specify a package name.
    List files installed in the wget package:
    $ dpkg -L wget
    Show info about an installed package:
    $ dpkg -s wget
    Show info about a package file:
    $ dpkg -I webfs_1.21+ds1-8_amd64.deb
    List files in a package file:
    $ dpkg -c webfs_1.21+ds1-8_amd64.deb
    Show what package owns /etc/init/networking.conf:
    $ dpkg -S /etc/init/networking.conf
    Show the status of a package:
    $ dpkg -s wget
    Verify the installed package's integrity:
    $ dpkg -V package
    Without arguments, this will verify all packages on the system. See the man page to interpret the output. Note: only recent versions of dpkg (1.17+) support this option.


7.7. Installing/Upgrading/Uninstalling Packages

The command:

$ sudo dpkg -i foobar.deb

would be used for either installing or upgrading the foobar package.

If the package is not currently installed, then it will be installed. If the package is newer than the one currently installed, then it will be upgraded.

The command:

$ sudo dpkg -r package

is used to remove all of an installed package except for its configuration files. The command:

$ sudo dpkg -P package

is used to remove all of an installed package including its configuration files.  (Note that -P stands for purge.)

8.1. yum - Intro

The yum program provides a higher level of intelligent services for using the underlying rpm program. It can automatically resolve dependencies when installing, updating and removing packages. It accesses external software repositories, synchronizing with them and retrieving and installing software as needed.


8.2. Learning Objectives

By the end of this chapter, you should be able to: 

    Discuss package installers and their characteristics.
    Explain what yum is.
    Configure yum to use repositories.
    Discuss the queries yum can be used for.
    Verify, install, remove, and upgrade packages using yum.

8.3. Package Installers

The lower-level package utilities such as rpm and dpkg deal with the details of installing specific software package files and managing already installed software.

The higher-level package management systems (such as yum, dnf, apt and zypper) work with databases of available software and incorporate the tools needed to find, install, update, and uninstall software in a highly intelligent fashion. They:

    Can use both local and remote repositories as a source to install and update binary as well as source software packages.
    Are used to automate the install, upgrade, and removal of software packages.
    Resolve dependencies automatically.
    Save time because there is no need to either download packages manually or search out dependency information separately.

The software repositories are provided by distributions and other independent software providers. The package installers maintain databases of available software derived from catalogs kept by the repositories. Unlike the low-level package tools, they have the ability to find and install dependencies automatically, a critical feature.

In this section we will talk about yum and dnf; we will get to zypper and apt next.


8.4. What is yum?

yum provides a frontend to rpm. Its primary task is to fetch packages from multiple remote repositories and resolve dependencies among packages. It is used by the majority (but not all) distributions that use rpm, including RHEL, CentOS, Scientific Linux and Fedora.

yum caches information and databases to speed up performance. To remove some or all cached information, one can run the command:

$ yum clean [ packages | metadata | expire-cache | rpmdb | plugins | all ]

yum has a number of modular extensions (plugins) and companion programs that can be found under /usr/bin/yum* and /usr/sbin/yum*.

We will concentrate on the command line use of yum and not consider the graphical interfaces distributions provide.


8.5. Configuring yum to Use Repositories

Repository configuration files are kept in /etc/yum.repos.d/ and have a .repo extension. For example, on one RHEL 7 system we have:

    ls -l /etc/yum.repos.d

Note that on RHEL 6 there is no redhat.repo file. RHEL 6 and earlier versions handled the distribution-supplied repos in a somewhat different manner, although RHEL clones like CentOS used conventional repos for the main distribution packages.


8.6. Repository Files

A very simple repository file might look like:

[repo-name]

name=Description of the repository

baseurl=http://somesystem.com/path/to/repo

enabled=1

gpgcheck=1

More complicated examples can be found in /etc/yum.repos.d and it would be a good idea to examine them.

One can toggle the use of a particular repository on or off by changing the value of enabled to 0 or 1, or using the --disablerepo=somerepo and --enablerepo=somerepo options when using yum. One can (but should not) also turn off integrity checking with the gpgcheck variable.


8.7.a. Queries I

Like rpm, yum can be used for queries such as searches; however, it can search not just what is present on the local system, it can also inquire about remote repositories. Some examples:

    Search for packages with keyword in name:

    $ sudo yum search keyword
    $ sudo yum list "*keyword*"

    These two commands give somewhat different information. The first one tells more about the packages, while the second one makes it clearer what is installed and what else is available.
    Display information about a package:

    $ sudo yum info package

    Information includes size, version, what repository it came from, a source URL, and a longer description. Wildcards can be given, as in yum info "libc*", for this and most yum commands. Note that the package need not be installed, unlike queries made with rpm -q.


8.7.b. Queries II

More yum examples:

    List all packages, or just those installed, available, or updates that have not yet been installed:

    $ sudo yum list [installed | updates | available ]
    Show information about package groups installed or available, etc.:

    $ sudo yum grouplist [group1] [group2]
    $ sudo yum groupinfo group1 [group2]
    Show packages that contain a certain file name:

    $ sudo yum provides

    as in

    $ sudo yum provides "/logrotate.conf"

    Please note the need to use at least one / in the file name, which can be confusing.

8.8. Verify Packages

Package verification requires installation of the yum-plugin-verify package. So, you might have to do:

$ sudo yum install yum-plugin-verify

Note that this is a yum plugin, not an executable. There are many other plugins available for yum, which extend the possible set of commands and arguments it can take:

    To verify a package, giving the most information:
    $ sudo yum verify [package]
    To mimic rpm -V exactly:
    $ sudo yum verify-rpm [package]
    To list all differences, including configuration files:
    $ sudo yum verify-all [package]

Without arguments, the above commands will verify all packages installed on the system.

By default, the verification commands ignore configuration files which may change through normal and safe usage. There are some other options: see man yum-verify.

8.9.a. Installing/Removing/Upgrading Packages I

Here are some examples of commonly performed operations:

    Install one or more packages from repositories, resolving and installing any necessary dependencies:

    $ sudo yum install package1 [package2]
    Install from a local rpm:

    $ sudo yum localinstall package-file

    This is not quite the same as

    $ rpm -i package-file

    because it will attempt to resolve dependencies by accessing remote repositories.

8.9.b. Installing/Removing/Upgrading Packages II

Here are some more examples of commonly performed operations:

    Install a specific software group from a repository, resolving and installing any necessary dependencies for each package in the group:

    $ sudo yum groupinstall group-name

    or

    $ sudo yum install @group-name 
    Remove packages from the system:

    $ sudo yum remove package1 [package2]

    One must be careful with package removal, as yum will not only remove requested packages, but all packages that depend on them! This may not be what you want, so never run yum remove with the -y option, which assumes automatic confirmation of removal.
    Update a package from a repository:

    $ sudo yum update [package]

    If no package name is given, all packages are updated.



8.9.c. Installing/Removing/Upgrading Packages III

During installation (or update), if a package has a configuration file which is updated, it will rename the old configuration file with an .rpmsave extension. If the old configuration file will still work with the new software, it will name the new configuration file with an .rpmnew extension. You can search for these filename extensions (almost always in the /etc subdirectory tree) to see if you need to do any reconciliation, by doing:

$ sudo find /etc -name "*.rpm*"

This is the same behavior the more naked underlying rpm utility exhibits, but we mention it here for reference.

8.10.a. Additional Commands I

 There is no shortage of additional capabilities for yum, according to what plugins are installed. You can list them all with:

$ sudo yum list "yum-plugin*"

In particular:

    Show a list of all enabled repositories:

    $ sudo yum repolist
    Initiate an interactive shell in which to run multiple YUM commands:

    $ sudo yum shell [text-file]

    If text-file is given, yum will read and execute commands from that file instead of from the terminal.

8.11.b. Additional Commands II

Some more examples of yum commands are:

    Download packages, but do not install them; just store them under the /var/cache/yum directory, or another directory you can specify:

    $ sudo yum install --downloadonly package

    or you can type "d" instead of "y" or "n" when prompted after issuing an install command. The package(s) will be downloaded under /var/cache/yum in a location depending on the repository from which the download proceeds, unless the --downloaddir= option is used. Any other necessary packages will also be downloaded to satisfy dependencies.
    You can view the history of yum commands, and, with the correct options, even undo or redo previous commands:

    $ sudo yum history

8.11. dnf

dnf is intended to be a next generation replacement for yum. However, it has yet to be adopted by any major Enterprise distribution; Fedora is a test bed for RHEL and it is rarely used directly in Enterprise deployments.

Furthermore, you can gradually learn to use dnf on Fedora systems because it accepts the subset of yum commands that take care of the majority of day-to-day tasks, and points out at each use of yum that has a dnf equivalent.

To learn more, see https://docs.fedoraproject.org/en-US/Fedora/24/html/System_Administrators_Guide/part-Package_Management.html.

9.1. zypper - Introduction

For use on SUSE-based systems, the zypper program provides a higher level of intelligent services for using the underlying rpm program, and plays the same role as yum on Red Hat-based systems. It can automatically resolve dependencies when installing, updating and removing packages. It accesses external software repositories, synchronizing with them and retrieving and installing software as needed.

9.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain what zypper is.
    Discuss the queries zypper can be used for.
    Install, remove and ugrade packages using zypper.


9.3. What is zypper?

zypper is the command line tool for installing and managing packages in SUSE Linux and openSUSE. It is very similar to yum in its functionality and even in its basic command syntax, and also works with rpm packages.

zypper retrieves packages from repositories, installs, removes and updates while resolving any dependencies encountered. It is equivalent in practice to yum and apt-get in that it can retrieve packages from a repository and can also resolve dependencies. 

9.4. zypper Queries

Here are some examples of commonly performed operations involving querying:

    Show a list of available updates:

    $ zypper list-updates
    List available repositories:

    $ zypper repos
    Search repositories for string:

    $ zypper search <string>
    List information about package:

    $ zypper info <package>
    Search repositories to ascertain what packages provide a file:

    $ zypper search --provides <file> 

9.5.a. Installing/Removing/Upgrading I

Here are some examples of commonly performed operations:

    Install or update package(s):

    $ sudo zypper install package
    Do not ask for confirmation when installing or upgrading:

    $ sudo zypper --non-interactive install <package>

    This is useful for scripts and is equivalent to running yum -y.


9.5.a. Installing/Removing/Upgrading I

Here are some more examples of commonly performed operations:

    Update all installed packages:

    $ sudo zypper update

    Giving package names as an argument will update only those packages and any required dependencies. Do this without asking for confirmation:

    $ sudo zypper --non-interactive update
    Remove a package from the system:

    $ sudo zypper remove <package>

    Like with yum, one has to be careful with the removal command, as any package that needs the package being removed would be removed as well.


9.6. Additional zypper Commands

Sometimes, a number of zypper commands must be run in a sequence. To avoid re-reading all the databases for each command, you can run zypper in shell mode as in:

$ sudo zypper shell
> install bash
...
> exit

Because zypper supports the readline library, you can use all the same command line editing functions in the zypper shell available in the bash shell.

To add a new repository:

$ sudo zypper addrepo URI alias

which is located at the supplied URI and will use the supplied alias.

To remove a repository from the list:

$ sudo zypper removerepo alias

using the alias of the repo you want to delete.

9.7 Using YasT Demo

Video presentation


10.1. APT - Introduction

For use on Debian-based systems, the APT (Advanced Packaging Tool) set of programs provides a higher level of intelligent services for using the underlying dpkg program, and plays the same role as yum on Red Hat-based systems. The main utilities are apt-get and apt-cache. It can automatically resolve dependencies when installing, updating and removing packages. It accesses external software repositories, synchronizing with them and retrieving and installing software as needed.

10.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain what APT is.
    Use apt-cache to perform queries.
    Install, remove, and upgrade packages using apt-get.

10.3. What is APT?

APT is not a program in itself: it stands for Advanced Packaging Tool, which includes a number of utilities, such as apt-get and apt-cache. These, of course, in turn, invoke the lower-level dpkg program.

The APT system works with Debian packages whose files have a .deb extension. There are many distributions that have descended from Debian (including Ubuntu and Linux Mint) which have adopted the Debian packaging system with no essential modification. In fact, it is not uncommon to use a repository on more than one Debian-based Linux distribution.

Once again, we are going to ignore graphical interfaces (on your computer) such as synaptic or the Ubuntu Software Center, or other older frontends to APT, such as aptitude.

However, excellent Internet-based resources can be found at http://packages.debian.org and http://packages.ubuntu.com. These databases let you search for packages, examine their contents, and download.

10.4. apt-get

apt-get is the main APT command line tool for package management. It can be used to install, manage and upgrade individual packages or the entire system. It can even upgrade the distribution to a completely new release, which can be a difficult task.

There are even (imperfect) extensions that let apt-get work with rpm files. 

Like yum and zypper it works with multiple remote repositories.

10.5. Queries Using apt-cache

Queries are done using the apt-cache utility:

    Search the repository for a package named apache2:

    $ apt-cache search apache2
    Display basic information about the apache2 package:

    $ apt-cache show apache2
    Display more detailed information about the apache2 package:

    $ apt-cache showpkg apache2
    List all dependent packages for apache2:

    $ apt-cache depends apache2
    Search the repository for a file named apache2.conf:

    $ apt-file search apache2.conf
    List all files in the apache2 package:

    $ apt-file list apache2

    Find package that provides the file specified as argument
    $ apt-file find <file-name>

10.6.a. Installing/Removing/Upgrading I

The apt-get program is the work horse of installing, removing, and upgrading packages:

    Synchronize the package index files with their repository sources. The indexes of available packages are fetched from the location(s) specified in /etc/apt/sources.list:

    $ sudo apt-get update
    Install new packages or update an already installed package:

    $ sudo apt-get install [package]
    Remove a package from the system without removing its configuration files:

    $ sudo apt-get remove [package]
    Remove a package from the system, as well as its configuration files:

    $ sudo apt-get --purge remove [package]
    Apply all available updates to packages already installed:

    $ sudo apt-get upgrade

10.6.b. Installing/Removing/Upgrading II

The apt-get program is the work horse of installing, removing and upgrading packages (continued):

    Do a smart upgrade that will do a more thorough dependency resolution and remove some obsolete packages and install new dependencies:

    $ sudo apt-get dist-upgrade

    This will not update to a whole new version of the Linux distribution as is commonly misunderstood.
    Note that you must update before you upgrade, unlike with yum, where the update argument does both steps, it updates the repositories and then upgrades the packages. This can be confusing to habitual yum users on Debian-based systems.
    Get rid of any packages not needed anymore, such as older Linux kernel versions:

    $ sudo apt-get autoremove
    Clean out cache files and any archived package files that have been installed:

    $ sudo apt-get clean

    This can save a lot of space.

11.1. System Monitoring - Introduction

11.2. Learning Objectives

By the end of this chapter, you should be able to:

    Recognize and use available system monitoring tools.
    Use the /proc and /sys pseudo-filesystems.
    Use sar to gather system activity and performance data and create reports that are readable by humans.

11.3.a. Available Monitoring Tools I

Linux distributions come with many standard performance and profiling tools already installed. Many of them are familiar from other UNIX-like operating systems, while some were developed specifically for Linux.

Most of these tools make use of mounted pseudo-filesystems, especially /proc and /sys, both of which we have already discussed when examining filesystems and kernel configuration. We will look at them both.

While there are also a number of graphical system monitors that hide many of the details, we will consider only the command line tools in this course.

Before considering some of the main utilities in some detail, you can see a summary on the next few pages, broken down by type; please note that some of the utilities have overlapping domains of coverage. 

11.3.b. Available Monitoring Tools II

                Process and Load Monitoring Utilities

 
Utility	        Purpose	                                                    Package
=======================================================================================
top	        Process activity, dynamically updated	                        procps
uptime	    How long the system is running and the average load	            procps
ps	        Detailed information about processes	                        procps
pstree	    A tree of processes and their connections  	                    psmisc (or pstree)
mpstat	    Multiple processor usage	                                    sysstat
iostat	    CPU utilization and I/O statistics	                            sysstat
sar	        Display and collect information about system activity	        sysstat
numastat	Information about NUMA (Non-Uniform Memory Architecture)	    numactl
strace	    Information about all system calls a process makes 	            strace



 11.3.c. Available Monitoring Tools III

Below you will find a summary of the main memory and I/O monitoring utility tools:

 

 

Memory Monitoring Utilities 

 
Utility    	Purpose 	                                                            Package 
=================================================================================================
free	    Brief summary of memory usage                                           procps 
vmstat 	    Detailed virtual memory statistics and block I/O, dynamically updated 	procps 
pmap 	    Process memory map 	                                                    procps 

 

 

I/O Monitoring Utilities

 
Utility	        Purpose	                                                                    Package
=====================================================================================================
iostat	        CPU utilization and I/O statistics	                                        sysstat
sar	            Display and collect information about system activity	                    sysstat
vmstat	        Detailed virtual memory statistics and block I/O, dynamically updated 	    procps

11.3.d. Available Monitoring Tools IV

Below you will find a summary of the main network monitoring utility tools

 

 

Network Monitoring Utilities

 
Utility	            Purpose	                                            Package
======================================================================================
netstat	            Detailed networking statistics	                    netstat
iptraf	            Gather information on network interfaces	        iptraf
tcpdump	            Detailed analysis of network packets and traffic	tcpdump
wireshark	        Detailed network traffic analysis	                wireshark

11.4. The /proc and /sys Psuedo-filesystems

The /proc and /sys pseudo-filesystems contain a lot of information about the system. Furthermore, many of the entries in these directory trees are writable and can be used to change system behavior; in most cases, this requires a root user.

These are pseudo-filesystems because they exist totally in memory; if you look at the disk partition when the system is not running, there will be only an empty directory which is used as a mount point.

Furthermore, the information displayed is gathered only when it is looked at; there is no constant or periodic polling to update entries. 

11.5. /proc Basics

The /proc pseudo-filesystem has a long history; it has roots in other UNIX operating system variants, and, originally, was developed to display information about processes on the system, each of which has its own subdirectory in /proc with all important process characteristics available.

Over time, it grew to contain a lot of information about system properties, such as interrupts, memory, networking, etc, in a somewhat anarchistic way. It is still extensively used, and we will often refer to it.

11.7.a. /proc/sys I

Most of the tunable system parameters can be found in the subdirectory tree rooted at /proc/sys:


total 0
dr-xr-xr-x 1 root root 0 Apr 24 09:14 abi/
dr-xr-xr-x 1 root root 0 Apr 24 09:14 debug/
dr-xr-xr-x 1 root root 0 Apr 24 09:14 dev/
dr-xr-xr-x 1 root root 0 Apr 24 08:25 fs/
dr-xr-xr-x 1 root root 0 Apr 24 08:25 kernel/
dr-xr-xr-x 1 root root 0 Apr 24 09:14 net/
dr-xr-xr-x 1 root root 0 Apr 24 09:14 sunrpc/
dr-xr-xr-x 1 root root 0 Apr 24 08:25 vm/

11.7.b. /proc/sys II

Each of these subdirectories contains information, as well as knobs that can be tuned (with care):

    abi/
    Contains files with application binary information; rarely used.
    debug/
    Debugging parameters; for now, just some control of exception reporting.
    dev/
    Device parameters, including subdirectories for cdrom, scsi, raid, and parport.
    fs/
    Filesystem parameters, including quota, file handles used, and maximums, inode and directory information, etc.
    kernel/
    Kernel parameters. There are many important entries here.
    net/
    Network parameters. There are subdirectories for ipv4, netfilter, etc.
    vm/
    Virtual memory parameters. There are many important entries here.

11.7.c. /proc/sys III

Viewing and changing the parameters can be done with simple commands. For example, the maximum number of threads allowed on the system can be seen by looking at:

$ ls -l /proc/sys/kernel/threads-max
$ cat /proc/sys/kernel/threads-max
129498

We then can modify the value and verify the change was effected:

$ sudo bash -c 'echo 100000 > /proc/sys/kernel/threads-max'
$ cat /proc/sys/kernel/threads-max
100000

Remember from our discussion of sysctl the same effect is accomplished by:

$ sudo sysctl kernel.threads-max=100000

Viewing the value can be done as a normal user, while changing it requires superuser privilege.

11.8. /sys Basics

The /sys pseudo-filesystem is an integral part of what is termed the Unified Device Model. Conceptually, it is based on a device tree and one can walk through it and see the buses, devices, etc. It also now contains information which may or may not be strictly related to devices, such as kernel modules.

It has a more tightly defined structure than does /proc. Most entries contain only one line of text, although there are exceptions, unlike its antecedent, which has many multi-line entries whose exact contents have been known to change between kernel versions. Thus, the interface is hopefully more stable.

There are system properties which have display entries in both /proc and /sys; for compatibility with widely used system utilities, the older forms are only gradually being whittled down. 

11.9.a. A Survey of /sys I

Support for the sysfs virtual filesystem is built into all modern kernels, and it should be mounted under /sys. However, the unified device model does not require mounting sysfs in order to function.

Let's take a look at what can be found using the 3.18 kernel; we warn you that the exact layout of this filesystem has a tendency to mutate. Doing a top level directory command yields:

$ ls -F /sys
block/ bus/ class/ dev/ devices/ firmware/ fs/ kernel/ module/ power/

which displays the basic device hierarchy. The device model sysfs implementation also includes information not strictly related to hardware.

11.9.b. A Survey of /sys II

Network devices can be examined with:

$ ls -lF /sys/class/net

11.10.a. sar I

sar stands for the Systems Activity Reporter. It is an all-purpose tool for gathering system activity and performance data and creating reports that are readable by humans.

On Linux systems, the backend to sar is sadc (system activity data collector), which actually accumulates the statistics. It stores information in the /var/log/sa directory, with a daily frequency by default, but which can be adjusted. Data collection can be started from the command line, and regular periodic collection is usually started as a cron job stored in /etc/cron.d/sysstat.

sar then reads in this data (either from the default locations or by use of a file specified with the -f option), and then produces a report.

sar is invoked via:

$ sar [ options ] [ interval ] [ count ]

where the report is repeated after interval seconds a total of count times (which defaults to 1). With no options, it gives a report on CPU usage.


11.10.b. sar II

Here is a list of the major sar options, or modes, each one of which has its own sub-options:

 

                    sar Options
 Option   	    Meaning
==========================================================================
-A	            Almost all information
-b	            I/O and transfer rate statistics (similar to iostat)
-B	            Paging statistics including page faults
-x	            Block device activity (similar to iostat -x)
-n	            Network statistics
-P	            Per CPU statistics (as in sar -P ALL 3)
-q	            Queue lengths (run queue, processes and threads)
-r	            Swap and memory utilization statistics
-R	            Memory statistics
-u	            CPU utilization (default)
-v	            Statistics about inodes and files and file handles
-w	            Context switching statistics
-W	            Swapping statistics, pages in and out per second


12.1. Process Monitoring - Introduction

Keeping track of running (and sleeping) processes is an essential system administration task. The ps program has been a main tool for doing so in UNIX-based operating systems for decades.

However, because the utility has a long and complicated history of being used differently in more than one operating system variety, it has a large assortment of options that can be applied with often confusing combinations. Another trusty tool is provided by top, which interactively monitors the system's state.

12.2. Learning Objectives

 By the end of this chapter, you should be able to:

    Use ps to view characteristics and statistics associated with processes.
    Identify different ps output fields and customize the ps output.
    Use pstree  to get a visual description of the process ancestry and multi-threaded applications.
    Use top to view system loads interactively.

12.3. MOnitoring Tools

In this section, we will concentrate on process monitoring. In order to do this, Linux administrators make use of many utilities, such as ps, pstree and top, all of which have long histories in UNIX-like operating systems.

Once again, let us review the list of some of the main tools for process monitoring:

 

Process and Load Monitoring Utilities

 
Utility	            Purpose	                                                    Packag
===============================================================================================
top	                Process activity, dynamically updated	                    procps
uptime	            How long the system is running and the average load	        procps
ps	                Detailed information about processes	                    procps
pstree	            A tree of processes and their connections  	                psmisc (or pstree)
mpstat	            Multiple processor usage	                                sysstat
iostat	            CPU utilization and I/O statistics	                        sysstat
sar	                Display and collect information about system activity	    sysstat
numastat	        Information about NUMA (Non-Uniform Memory Architecture)	numactl
strace	            Information about all system calls a process makes 	        strace

12.4. Viewing Process State with ps

ps is a workhorse for displaying characteristics and statistics associated with processes, all of which are garnered from the /proc directory associated with the process.

This command utility has existed in all UNIX-like operating system variants, and that diversity is reflected in the complicated potpourri of options that the Linux version of ps accepts, which fall into three categories:

    UNIX options, which must be preceded by -, and which may be grouped.
    BSD options, which must not be preceded by -, and which may be grouped.
    GNU long options, each of which must be preceded by --.

Having all these possible options can make life rather confusing. Most system administrators tend to use one or two standard combinations for their daily use.


12.6.a. ps Output Fields I

Most of the fields in the preceding example are self-explanatory. Of the others:

    VSZ is the process' virtual memory size in KB.
    RSS is the resident set size; the non-swapped physical memory a task is using in KB.
    STAT describes the state of the process; in our example we see only S for sleeping, or R for running. The additional character in the state (where it exists) can be:
    - < for high priority (not nice)
    - N for low priority (nice)
    - L for having pages locked in memory
    - s for session leader
    - l for multi-threaded
    - + for being in the foreground process group.



You can see a typical usage with the UNIX option format in the screenshot provided. Note that it is now showing the Parent Process ID (PPID) and the niceness (NI). You may observe that many processes show PPID=2 in this example (taken from RHEL 7 and using systemd) an internal kernel process, kthreadd, which is designed to adopt children when the parent process dies. In older kernels and systems, you would see PPID=1 for sbin/init, but it is really the same thing going on.


12.7.b. UNIX Option Format for pa II

Some common selection options in the UNIX format are:

    -A or -e
    Select all processes
    -N
    Negate selection (means do the opposite)
    -C
    Select by command name
    -G
    Select by real group ID (also supports names)
    -U 
    Select by real user ID (also supports names).

12.8. Customizing the ps Output

If you use the -o option, followed by a comma-separated list of field identifiers, you can print out a customized list of ps fields:

    pid: Process ID number
    uid: User ID number
    cmd: Command with all arguments
    cputime: Cumulative CPU time
    pmem: Ratio of the process's resident set size to the physical memory on the machine, expressed as a percentage.

You can see an example in the screenshot provided. You can consult the ps man page for many other output options.

12.9. Using pstree

pstree gives a visual description of the process ancestry and multi-threaded applications:

$ pstree -aAp 2408

bash,2408

|-emacs,24998 pmonitor.tex

|  |-{emacs},25002

|  '-{emacs},25003

|-evince,18036 LFS201-SLIDES.pdf

|  |-{evince},18040

|  |-{evince},18046

|  '-{evince},18047

Consult the man page for pstree for an explanation of many options; in the above we have chosen just to show information for pid=2408.

Note that one of its child processes (evince, pid=18036) has three children of its own. Another way to see that is:

$ ls -l /proc/18036/task 

total 0

dr-xr-xr-x 5 coop coop 0 Sep 11 07:15 18036

dr-xr-xr-x 5 coop coop 0 Sep 11 07:15 18040

dr-xr-xr-x 5 coop coop 0 Sep 11 07:15 18046

dr-xr-xr-x 5 coop coop 0 Sep 11 07:15 18047

12.10. Viewing System Loads with top

When one wants to know what the system is spending its time on, the first tool one often uses is top. The screenshot shows you what you can see when using top without arguments.

By default, top refreshes itself every 3.0 seconds.

12.11.a. top Options I

top is an ancient utility and has a ton of options, as well as interactive commands triggered when certain keys are pressed. For example, if one hits 1, each CPU is shown separately, and if one hits i only active processes are shown. You can see what doing both gives us in the screenshot.

12.11.b. top Options II

Ony has a lot of control over how processes are sorted and which fields are displayed; there are many others besides the defaults. For example, hitting h or ? gives a brief list of interactive commands and q exits. 

Furthermore, one can kill a task by hitting k, or renice it (change its priority) with r.

Doing man top will give you extensive documentation on configuration possibilities, options, and interactive possibilities.

Note that there are popular alternatives to the standard top program, some of which have more visual interfaces and/or additional information, such as htop, ntop and atop. And most Linux distributions have a graphical system monitor (such as gnome-system-monitor or ksysguard) which has a top-like display window that can be shown.

 
13.1. Memory: Monitoring Usage and Tunning - Introduction

Over time, systems have become more demanding of memory resources at the same time RAM prices have decreased and performance has improved. Yet, it is often the case that bottlenecks in overall system performance and throughput are memory-related; the CPUs and the I/O subsystem can be waiting for data to be retrieved from or written to memory. There are many tools for monitoring, debugging and tuning a system's behavior with regard to its memory.

13.2. Learning Objectives

By the end of this chapter, you should be able to:

    List the primary (inter-related) considerations and tasks involved in memory tuning.
    Know how to use entries in /proc/sys/vm, and decipher /proc/meminfo.
    Use vmstat to display information about memory, paging, I/O, processor activity, and processes' memory consumption.
    Understand how the OOM-killer decides when to take action and selects which processes should be exterminated to open up some memory.

13.3. Memory Tunning Considerations

Tuning the memory sub-system can be a complex process. First of all, one has to take note that memory usage and I/O throughput are intrinsically related, as, in most cases, most memory is being used to cache the contents of files on disk.

Thus, changing memory parameters can have a large effect on I/O performance, and changing I/O parameters can have an equally large converse effect on the virtual memory sub-system.

When tweaking parameters in /proc/sys/vm, the usual best practice is to adjust one thing at a time and look for effects. The primary (inter-related) tasks are:

    Controlling flushing parameters; i.e., how many pages are allowed to be dirty and how often they are flushed out to disk.
    Controlling swap behavior; i.e., how much pages that reflect file contents are allowed to remain in memory, as opposed to those that need to be swapped out as they have no other backing store.
    Controlling how much memory overcommission is allowed, since many programs never need the full amount of memory they request, particularly because of copy on write (COW) techniques.

Memory tuning can often be subtle, and what works in one system situation or load may be far from optimal in other circumstances.

13.4. Memory Monitoring Tools

Here is a list of some important basic tools for monitoring and tuning memory in Linux:


                    Memory Monitoring Utilities

 
Utility    	Purpose	                                                                    Package
===================================================================================================
free	    Brief summary of memory usage	                                            procps
vmstat	    Detailed virtual memory statistics and block I/O, dynamically updated     	procps 
pmap 	    Process memory map 	                                                        procps 

 13.5.a. /proc/sys/vm I

The /proc/sys/vm directory contains many tunable knobs to control the Virtual Memory system. Exactly what appears in this directory will depend somewhat on the kernel version. Almost all of the entries are writable (by root).

Remember that these values can be changed either by directly writing to the entry, or using the sysctl utility. Furthermore, by modifying /etc/sysctl.conf, values can be set at boot time.

You can find full documentation for the /proc/sys/vm directory in the kernel source (or kernel documentation package on your distribution), usually under Documentation/sysctl/vm.txt.

13.5.b. /proc/sys/vm II

/proc/sys/vm Entries

  
Entry	                    Purpose 
admin_reserve_kbytes	    Amount of free memory reserved for privileged users
block_dump            	    Enables block I/O debugging
compact_memory 	            Turns on or off memory compaction (essentially defragmentation) when configured into the kernel
dirty_background_bytes 	    Dirty memory threshold that triggers writing uncommitted pages to disk
dirty_background_ratio 	    Percentage of total pages at which kernel will start writing dirty data out to disk
dirty_bytes 	            The amount of dirty memory a process needs to initiate writing on its own
dirty_expire_centisecs 	    When dirty data is old enough to be written out in hundredths of a second)
dirty_ratio	                Percentage of pages at which a process writing will start writing out dirty data on its own
dirty_writeback_centisecs 	Interval in which periodic writeback daemons wake up to flush. If set to zero, there is no automatic periodic writeback
drop_caches 	            Echo 1 to free page cache, 2 to free dentry and inode caches, 3 to free all. Note only clean cached pages are dropped; do sync first to flush dirty pages
extfrag_threshold	        Controls when the kernel should compact memory
hugepages_treat_as_movable 	Used to toggle how huge pages are treated
hugetlb_shm_group 	        Sets a group ID that can be used for System V huge pages
laptop_mode 	            Can control a number of features to save power on laptops
legacy_va_layout 	        Use old layout (2.4 kernel) for how memory mappings are displayed
lowmen_reserve_ratio 	    Controls how much low memory is reserved for pages that can only be there; i.e., pages which can go in high memory instead will do so. Only important on 32-bit systems with high memory
max_map_count 	            Maximum number of memory mapped areas a process may have. The default is 64 K
min_free_kbytes 	        Minimum free memory that must be reserved in each zone
mmap_min_addr 	            How much address space a user process cannot memory map. Used for security purposes, to avoid bugs where accidental kernel null dereferences can overwrite the first pages used in an application
nr_hugepages 	            Minimum size of hugepage pool
nr_pdflush_hugepages 	    Maximum size of the hugepage pool = nr_hugepages *nr_overcommit_hugepages 
nr_pdflush_threads 	        Current number of pdflush threads; not writeable
oom_dump_tasks 	            If enabled, dump information produced when oom-killer cuts in
oom_kill_allocating_task	If set, the oom-killer kills the task that triggered the out of memory situation, rather than trying to select the best one
overcommit_kbytes 	        One can set either overcommit_ratio or this entry, but not both
overcommit_memory	        If 0, kernel estimates how much free memory is left when allocations are made. If 1, permits all allocations until memory actually does run out. If 2, prevents any overcommission
overcommit_ratio 	        If overcommit_memory = 2 memory commission can reach swap plus this percentage of RAM
page-cluster 	            Number of pages that can be written to swap at once, as a power of two. Default is 3 (which means 8 pages)
panic_on_oom 	            Enable system to crash on an out of memory situation
percpu_pagelist_fraction	Fraction of pages allocated for each cpu in each zone for hot-pluggable CPU machines
scan_unevictable_pages 	    If written to, system will scan and try to move pages to try and make them reclaimable
stat_interval 	            How often vm statistics are updated (default 1 second) by vmstat
swappiness	                How aggressively should the kernel swap
user_reserve_kbytes	        If overcommit_memory is set to 2 this sets how low the user can draw memory resources
vfs_cache_pressure	        How aggressively the kernel should reclaim memory used for inode and dentry cache. Default is 100; if 0 this memory is never reclaimed due to memory pressure


13.6.a. vmstat I

vmstat is a multi-purpose tool that displays information about memory, paging, I/O, processor activity and processes. It has many options. The general form of the command is: 

$ vmstat [options] [delay] [count]

If delay is given in seconds, the report is repeated at that interval count times; if count is not given, vmstat will keep reporting statistics forever, until it is killed by a signal, such as Ctl-C.

If no other arguments are given, you can see what vmstat displays, where the first line shows averages since the last reboot, while succeeding lines show activity during the specified interval.

$ vmstat 2 4

13.6.b. vmstat II

vmstat Fields 

 
Field 	            Subfield 	            Meaning 
============================================================================================
Processes	        r 	                    Number of processes waiting to be scheduled in
Processes	        b	                    Number of processes in uninterruptible sleep 
memory 	            swpd 	                Virtual memory used (KB) 
memory 	            free 	                Free (idle) memory (KB) 
memory 	            buff 	                Buffer memory (KB) 
memory 	            cache 	                Cached memory (KB) 
swap 	            si 	                    Memory swapped in (KB) 
swap 	            so 	                    Memory swapped out (KB) 
I/O 	            bi 	                    Blocks written to devices (blocks/sec) 
I/O	                bo 	                    Blocks read from devices (blocks/sec) 
system 	            in 	                    Interrupts/second 
system 	            cs 	                    Context switches/second 
CPU 	            us 	                    CPU time running user code (percentage) 
CPU 	            sy 	                    CPU time running kernel (system) code (percentage)
CPU 	            id 	                    CPU time idle (percentage)
CPU  	            wa 	                    Time waiting for I/O (percentage) 
CPU 	            st 	                    Time "stolen" from virtual machine (percentage) 

13.6.c. vmstat III

If the option -S m is given, memory statistics will be in MB instead of KB.

With the -a option, vmstat displays information about active and inactive memory, where active memory pages are those which have been recently used; they may be clean (disk contents are up to date) or dirty (need to be flushed to disk eventually). By contrast, inactive memory pages have not been recently used and are more likely to be clean and are released sooner under memory pressure:

$ vmstat -a 2 4

Memory can move back and forth between active and inactive lists, as they get newly referenced, or go a long time between uses.

13.6.e. vmstat V

To get a table of disk statistics use the -d option:


$ vmstat -d
disk- ------------reads------------ ------------writes----------- -----IO------
       total merged sectors      ms  total merged sectors      ms    cur    sec
loop0     39      0     240    2356      0      0       0       0      0      2
loop1    293      0    2628   20692      0      0       0       0      0      1
loop2     39      0     240     608      0      0       0       0      0      0
loop3     53      0    2144    1120      0      0       0       0      0      1
loop4  10817      0   23636  273344      0      0       0       0      0     11
loop5     88      0     770   20860      0      0       0       0      0      2
loop6     37      0     674    1368      0      0       0       0      0      1
loop7     54      0    2106    2888      0      0       0       0      0      2
sda    65340  13287 4657720 4544888  10025  14478  377770 1248812      0    365
sr0        0      0       0       0      0      0       0       0      0      0
sr1       17      0     112      44      0      0       0       0      0      0
sdb        0      0       0       0      0      0       0       0      0      0
loop8      5      0      16     100      0      0       0       0      0      0
loop9   1831      0    3818   49912      0      0       0       0      0      2
loop10     38      0     658     816      0      0       0       0      0      0

13.6.f. vmstat VI

vmstat Disk Fields 

 
Field        	Subfield	Meaning
=================================================================
reads	        total	    Total reads completed successfully
reads	        merged	    Grouped reads (resulting in one I/O)
reads	        ms	M       illiseconds spent reading
writes	        total	    Total writes completed successfully
writes      	merged	    Grouped writes (resulting in one I/O)
writes	        ms	        Milliseconds spent writing
I/O	            cur	        I/O in progress
I/O	            sec	        seconds spent for I/O

13.6.g. vmstat VII

If you just want to get some quick statistics on only one partition, use the -p option:


$ vmstat -p /dev/sda2 2
sda2          reads   read sectors  writes    requested writes
               65077    4635186      10521     400304
               65077    4635186      10521     400304
               65077    4635186      10522     400312
               65077    4635186      10522     400312
               65077    4635186      10522     400312
               65077    4635186      10522     400312
               65077    4635186      10529     400648
               65077    4635186      10529     400648
               65077    4635186      10529     400648

13.7.b. /proc/meminfo II

It is worthwhile to go through this listing and understand most of the entries:


/proc/meminfo Entries

 
Entry                    	Meaning
============================================================================================
MemTotal	                Total usable RAM (physical minus some kernel reserved memory)
MemFree	                    Free memory in both low and high zones
Buffers	                    Memory used for temporary block I/O storage
Cached	                    Page cache memory, mostly for file I/O
SwapCached	                Memory that was swapped back in but is still in the swap file
Active	                    Recently used memory, not to be claimed first
Inactive	                Memory not recently used, more eligible for reclamation
Active(anon)	            Active memory for anonymous pages
Inactive(anon)	            Inactive memory for anonymous pages
Active(file)	            Active memory for file-backed pages
Inactive(file)	            Inactive memory for file-backed pages
Unevictable	                Pages which can not be swapped out of memory or released
Mlocked	                    Pages which are locked in memory
SwapTotal	                Total swap space available
SwapFree	                Swap space not being used
Dirty	                    Memory which needs to be written back to disk
Writeback	                Memory actively being written back to disk
AnonPages	                Non-file back pages in cache
Mapped	                    Memory mapped pages, such as libraries
Shmem	                    Pages used for shared memory
Slab	                    Memory used in slabs
SReclaimable	            Cached memory in slabs that can be reclaimed
SUnreclaim	                Memory in slabs that can't be reclaimed
KernelStack	                Memory used in kernel stack
PageTables	                Memory being used by page table structures
Bounce	                    Memory used for block device bounce buffers
WritebackTmp	            Memory used by FUSE filesystems for writeback buffers
CommitLimit	                Total memory available to be used, including overcommission
Committed_AS	            Total memory presently allocated, whether or not it is used
VmallocTotal	            Total memory available in kernel for vmalloc allocations
VmallocUsed	                Memory actually used by vmalloc allocations
VmallocChunk	            Largest possible contiguous vmalloc area
HugePages_Total	            Total size of the huge page pool
HugePages_Free	            Huge pages that are not yet allocated
HugePages_Rsvd	            Huge pages that have been reserved, but not yet used
HugePages_Surp	            Huge pages that are surplus, used for overcommission
Hugepagesize	            Size of a huge page

 

 Note that the exact entries you may see will depend on the exact kernel version you are running.


13.8.a. OOM Killer I

The simplest way to deal with memory pressure would be to permit memory allocations to succeed as long as free memory is available and then fail when all memory is exhausted.

The second simplest way is to use swap space on disk to push some of the resident memory out of core; in this case, the total available memory (at least in theory) is the actual RAM plus the size of the swap space. The hard part of this is to figure out which pages of memory to swap out when pressure demands. In this approach, once the swap space itself is filled, requests for new memory must fail.

Linux, however, goes one better; it permits the system to overcommit memory, so that it can grant memory requests that exceed the size of RAM plus swap. While this might seem foolhardy, many (if not most) processes do not use all requested memory. 

An example would be a program that allocates a 1 MB buffer, and then uses only a few pages of the memory. Another example is that every time a child process is forked, it receives a copy of the entire memory space of the parent. Because Linux uses the COW (copy on write) technique, unless one of the processes modifies memory, no actual copy needs be made. However, the kernel has to assume that the copy might need to be done.

Thus, the kernel permits overcommission of memory, but only for pages dedicated to user processes; pages used within the kernel are not swappable and are always allocated at request time.

One can modify, and even turn off this overcommission by setting the value of /proc/sys/vm/overcommit_memory:

    0:  (default) Permit overcommission, but refuse obvious overcommits, and give root users somewhat more memory allocation than normal users.
    1:  All memory requests are allowed to overcommit.
    2:  Turn off overcommission. Memory requests will fail when the total memory commit reaches the size of the swap space plus a configurable percentage (50 by default) of RAM. This factor is modified changing /proc/sys/vm/overcommit_ratio.

13.8.b. OOM Killer II

If available memory is exhausted, Linux invokes the OOM-killer (Out Of Memory) to decide which process(es) should be exterminated to open up some memory.

There is no precise science for this; the algorithm must be heuristic and cannot satisfy everyone. In the minds of many developers the purpose of the OOM-killer is to permit a graceful shutdown, rather than be a part of normal operations.

An amusing take on this was given by Andries Brouwer (http://lwn.net/Articles/104185/):

"An aircraft company discovered that it was cheaper to fly its planes with lesGs fuel on board. The planes would be lighter and use less fuel and money was saved. On rare occasions however the amount of fuel was insufficient, and the plane would crash. This problem was solved by the engineers of the company by the development of a special OOF (out-of-fuel) mechanism. In emergency cases a passenger was selected and thrown out of the plane. (When necessary, the procedure was repeated.) A large body of theory was developed and many publications were devoted to the problem of properly selecting the victim to be ejected. Should the victim be chosen at random? Or should one choose the heaviest person? Or the oldest? Should passengers pay in order not to be ejected, so that the victim would be the poorest on board? And if for example the heaviest person was chosen, should there be a special exception in case that was the pilot? Should first class passengers be exempted? Now that the OOF mechanism existed, it would be activated every now and then, and eject passengers even when there was no fuel shortage. The engineers are still studying precisely how this malfunction is caused."

In order to make decisions of who gets sacrificed to keep the system alive, a value called the badness is computed (which can be read from /proc/[pid]/oom_score) for each process on the system and the order of the killing is determined by this value.

Two entries in the same directory can be used to promote or demote the likelihood of extermination. The value of oom_adj is the number of bits the points should be adjusted by. Normal users can only increase the badness; a decrease (a negative value for oom_adj) can only be specified by a superuser. The value of oom_adj_score directly adjusts the point value. Note that the use of oom_adj is deprecated.


14.1. I/O Monitoring and Tuning - Introduction

video

14.2. Learning Objectives

By the end of this chapter, you should be able to:

    Use iostat to monitor system I/O device activity.
    Use iotop to display a constantly updated table of current I/O usage.
    Use ionice to set both the I/O scheduling class and the priority for a given process.


14.3. Disk Bottlenecks

Disk performance problems can be strongly coupled to other factors, such as insufficient memory or inadequate network hardware and tuning. Disentangling can be difficult.

As a rule, a system can be considered as I/O-bound when the CPU is found sitting idle waiting for I/O to complete, or the network is waiting to clear buffers.

However, one can be misled. What appears to be insufficient memory can result from too slow I/O; if memory buffers that are being used for reading and writing fill up, it may appear that memory is the problem, when the real problem is that buffers are not filling up or emptying out fast enough. Similarly, network transfers may be waiting for I/O to complete and cause network throughput to suffer.

Both real-time monitoring and tracing are necessary tools for locating and mitigating disk bottlenecks. However, rare or non-repeating problems can make this difficult to accomplish.

There are many relevant variables and I/O tuning is complex. We will also consider I/O scheduling later.

14.4.a. iostat I

iostat is the basic workhorse utility for monitoring I/O device activity on the system. It can generate reports with a lot of information, with the precise content controlled by options.

You can see in this screenshot what simply typing iostat gives us.

$ iostat

Linux 4.4.0-121-generic (george-HP-Pavilion-17-Notebook-PC) 	24/04/2018 	_x86_64_	(4 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           4.85    0.03    2.79   10.38    0.00   81.95

Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
loop0             0.01         0.02         0.00        120          0
loop1             0.06         0.25         0.00       1314          0
loop2             0.01         0.02         0.00        120          0
loop3             0.01         0.21         0.00       1072          0
loop4             2.48         2.67         0.00      13879          0
loop5             0.02         0.07         0.00        385          0
loop6             0.01         0.06         0.00        337          0
loop7             0.01         0.20         0.00       1053          0
sda              39.82       722.98       508.69    3756300    2642957
scd1              0.00         0.01         0.00         56          0
loop8             0.00         0.00         0.00          8          0
loop9             0.47         0.49         0.00       2539          0
loop10            0.01         0.06         0.00        329          0

14.4.b. iostat II

After a brief summary of CPU utilization, I/O statistics are given: tps (I/O transactions per second; logical requests can be merged into one actual request), blocks read and written per unit time, where the blocks are generally sectors of 512 bytes; and the total blocks read and written.

Information is broken out by disk partition (and if LVM is being used also by dm (device mapper) logical partitions).


14.5.a. iostat Options I

A somewhat different display is generated by giving the -k option, which shows results in KB instead of blocks. You can also use -m to get results in MB.

14.5.b. iostat Options II

Another useful option is -N to show by device name (or -d for a somewhat different format), as in the screenshot provided.

14.6.a. iostat Extended Oprions I

A much more detailed report can be obtained by using the -x option (for extended).

14.6.b. iostat Extended Options II

The fields you saw in the screenshot on the previous page have the following meanings:

 

Extended iostat Fields 
Field    	Meaning 
Device 	    Device or partition name 
rrqm/s 	    Number of read requests merged per second, queued to device 
wrqm/s	    Number of write requests merged per second, queued to device 
r/s 	    Number of read requests per second, issued to the device
w/s 	    Number of write requests per second, issued to the device 
rkB/s 	    KB read from the device per second 
wkB/s 	    KB written to the device per second 
avgrq-sz 	Average request size in 512 byte sectors per second 
avgqu-sz 	Average queue length of requests issued to the device 
await 	    Average time (in msecs) I/O requests between when a request is issued and when it is completed: queue time plus service time 
svctm 	    Average service time (in msecs) for I/O requests 
%util 	    Percentage of CPU time during the device serviced requests 

 

Note that if the utilization percentage approaches 100, the system is saturated, or I/O bound.


14.7.a. iotop I

Another very useful utility is iotop, which must be run as root. It displays a table of current I/O usage and updates periodically, like top. You can see in the screenshot what typing sudo iotop with no options gives us.

Please note that the be and rt entries in the PRIO are explained in the ionice section, and stand for best effort and real time.


14.8.a. Using ionice to Set I/O Priorities I

The ionice utility lets you set both the I/O scheduling class and priority for a given process. It takes the form:

$ ionice [-c class] [-n priority] [-p pid ] [COMMAND [ARGS] ]

If a pid is given with the -p argument results apply to the requested process, otherwise it is the process that will be started by COMMAND with possible arguments. If no arguments are given, ionice returns the scheduling class and priority of the current shell process, as in:

$ ionice

idle: prio 7

The -c parameter specifies the I/O scheduling class, which can have the following 3 values:

I/O Scheduling Classes

I/O Scheduling 
Class	            -c value	        Meaning
===================================================================================================
None or Unknown	        0	            Default value
Real Time	            1 	            Get first access to the disk, can starve other processes. The priority defines how big a time slice each process gets.
Best effort 	        2 	            All programs serviced in round-robin fashion, according to priority settings. The Default. 
Idle	                3 	            No access to disk I/O unless no other program has asked for it for a defined period. 


14.8.b. Using ionice to Set I/O Priorities II

The Best Effort and Real Time classes take the -n argument which gives the priority, which can range from 0 to 7, with 0 being the highest priority. An example:

$ ionice -c 2 -n 3 -p 30078

Note: ionice works only when using the CFQ I/O Scheduler, which we will talk about in the next section.

15.1. I/O Scheduling - Introduction

System performance often depends very heavily on optimizing the I/O scheduling strategy. Many (often competing) factors influence behavior; these include minimizing hardware access times, avoiding wear and tear on storage media, ensuring data integrity, granting timely access to applications that need to do I/O, and being able to prioritize important tasks. Linux offers a variety of I/O Schedulers to choose from, each of which has tunable parameters, as well as a number of utilities for reporting on and analyzing I/O performance.

15.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain the importance of I/O scheduling and describe the conflicting requirements that need to be satisfied.
    Delineate and contrast the options available under Linux.  
    Understand how the CFQ (Completely Fair Queue) and Deadline algorithms work.

15.3. I/O Scheduling

The I/O scheduler provides the interface between the generic block layer and low-level physical device drivers. Both the VM (Virtual Memory) and VFS (Virtual File System) layers submit I/O requests to block devices; it is the job of the I/O scheduling layer to prioritize and order these requests before they are given to the block devices.

Any I/O scheduling algorithm has to satisfy certain (sometimes conflicting) requirements:

    Hardware access times should be minimized; i.e., requests should be ordered according to physical location on the disk. This leads to an elevator scheme where requests are inserted in the pending queue in physical order.
    Requests should be merged to the extent possible to get as big a contiguous region as possible, which also minimizes disk access time.
    Requests should be satisfied with as low a latency as is feasible; indeed,in some cases, determinism (in the sense of deadlines) may be important.
    Write operations can usually wait to migrate from caches to disk without stalling processes. Read operations, however, almost always require a process to wait for completion before proceeding further. Favoring reads over writes leads to better parallelism and system responsiveness.
    Processes should share the I/O bandwidth in a fair, or at least consciously prioritized fashion; even it means some overall performance slowdown of the I/O layer, process throughput should not suffer inordinately.

15.4. I/O Scheduler Choices

Since these demands can be conflicting, different I/O schedulers may be appropriate for different workloads; e.g., a large database server vs. a desktop system. Furthermore, different hardware may mandate different strategy. In order to provide flexibility, the Linux kernel has an object oriented scheme, in which pointers to the various needed functions are supplied in a data structure, the particular one of which can be selected at boot on the kernel command line, as in:

linux ...  elevator=[cfq|deadline|noop]

At least one of the I/O scheduling algorithms must be compiled into the kernel. The current choices are:

    Completely Fair Queueing (CFQ)
    Deadline Scheduling
    noop (A simple scheme).

The default choice is a compile configuration option; modern distributions choose either CFQ or Deadline.

15.5. I/O Scheduling and SSD Devices

The gradual introduction of SSD (Solid State Drive) devices, which use flash memory to emulate hard disks, has important implications for I/O scheduling. 

Such devices do not require an elevator scheme and benefit from wear leveling to spread I/O over the devices which have limited write/erase cycles.

One can examine /sys/block/<device>/queue/rotational to see whether or not the device is an SSD or not, as in:

$ cat /sys/block/sda/queue/rotational

1

$ cat /sys/block/sdb/queue/rotational

0


15.6.a. Tunables and Switching the I/O Scheduler at runtime I

Each of the I/O schedulers exposes parameters which can be used to tune behavior at run time. The parameters are accessed through the pseudo-filesystem mounted at /sys.

In addition, it is possible to use different I/O schedulers for different devices. The choice can be made easily through the command line. For example:

$ cat /sys/block/sda/queue/scheduler

noop deadline [cfq]

$ echo noop > /sys/block/sda/queue/scheduler

$ cat /sys/block/sda/queue/scheduler

[noop] deadline cfq



15.6.b. Tunables and Switching the I/O Scheduler at runtime II


The actual tunables vary according to the particular I/O scheduler, and can be found under:

/sys/block/<device>/queue/iosched

You can see the actual tunables for a disk using CFQ in this screenshot.

We will discuss some of these parameters shortly.


15.8. CFQ (Completely Fair Queue) Scheduler

The CFQ (Completely Fair Queue) method has the goal of equal spreading of I/O bandwidth among all processes submitting requests.

Theoretically, each process has its own I/O queue, which works together with a dispatch queue which receives the actual requests on the way to the device. In actual practice, the number of queues is fixed (at 64) and a hash process based on the process ID is used to select a queue when a request is submitted.

Dequeuing of requests is done round robin style on all the queues, each one of which works in FIFO (First In First Out) order. Thus, the work is spread out. To avoid excessive seeking operations, an entire round is selected, and then sorted into the dispatch queue before actual I/O requests are issued to the device. 


15.9. CFQ Tunables

In the examples below, the parameter HZ is a kernel-configured quantity, that corresponds to the number of jiffies per second, which the kernel uses as a coarse measure of time. Without getting into detail, let us just point out that time units HZ/2 is 0.5 seconds and 5 * HZ is 5 seconds etc.

    quantum
    Maximum queue length in one round of service.  (Default = 4);
    queued
    Minimum request allocation per queue.  (Default = 8);
    fifo_expire_sync
    FIFO timeout for sync requests.  (Default = HZ/2);
    fifo_expire_async
    FIFO timeout for async requests.  (Default = 5  *  HZ);
    fifo_batch_expire
    Rate at which the FIFO's expire.  (Default = HZ/8);
    back_seek_max
    Maximum backwards seek, in KB. (Default = 16K);
    back_seek_penalty
    Penalty for a backwards seek.  (Default = 2).

15.10. Deadline Scheduler

The Deadline I/O scheduler aggressively reorders requests with the simultaneous goals of improving overall performance and preventing large latencies for individual requests; i.e., limiting starvation.

With each and every request, the kernel associates a deadline. Read requests get higher priority than write requests.

Five separate I/O queues are maintained:

    Two sorted lists are maintained, one for reading and one for writing, and arranged by starting block.\u200b
    Two FIFO lists are maintained, again one for reading and one for writing. These lists are sorted by submission time.\u200b
    A fifth queue contains the requests that are to be shoveled to the device driver itself. This is called the dispatch queue.

Exactly how the requests are peeled off the first four queues and placed on the fifth (dispatch queue) is where the art of the algorithm is.

15.11. Deadline Tunables

Here are the available tunables for the Deadline scheduler:

    read_expire:
    How long (in milliseconds) a read request is guaranteed to occur within. (Default = HZ/2 = 500 ). 
    write_expire:
    How long (in milliseconds) a write request is guaranteed to occur within. (Default = 5 * HZ = 5000).
    writes_starved:
    How many requests we should give preference to reads over writes. (Default = 2 ).
    fifo_batch:
    How many requests should be moved from the sorted scheduler list to the dispatch queue, when the deadlines have expired. (Default = 16).
    front_merges:
    Back merges are more common than front merges as a contiguous request usually continues to the next block. Setting this parameter to 0 disables front merges and can give a boost if you know they are unlikely to be needed. (Default = 1 ).

16.1. Linux Filesystems and VFS - Introduction

16.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain the basic filesystem organization.
    Understand the role of the VFS.
    Know what filesystems are available in Linux and which ones can be used on your actual system.
    Grasp why journalling filesystems represent significant advances.
    Discuss the use of special filesystems in Linux.

16.3. Filesystem Basics

Application programs read and write files, rather than dealing with physical locations on the actual hardware on which files are stored.

Files and their names are an abstraction camouflaging the physical I/O layer. Directly writing to disk in a raw fashion (ignoring the filesystem layer) is very dangerous and is only done by low-level operating system software, never by a user application.

Local filesystems generally reside within a disk partition which can be a physical partition on a disk, or a logical partition controlled by a Logical Volume Manager (LVM). Filesystems can also be of a network nature and their true physical embodiment completely hidden to the local system across the network. 


16.4. Filesystem Tree Organization

All Linux systems use an inverted tree hierarchy branching off the root (/) directory. While the entire tree may be contained in one local filesystem in one partition, usually there are multiple partitions (or network filesystems) joined together at mount points. These can also include removable media, such as USB drives, optical drives, etc.

In addition, certain virtual pseudo filesystems (useful abstractions which exist only in memory) will be mounted within the tree; these include /proc, /sys and /dev and perhaps /tmp and /run as well.

Each of the elements mounted within the tree may in fact have its own filesystem variety. But, to the applications and operating system, it all appears in one unified tree structure. 


16.5. Virtual File System (VFS)

Linux implements a Virtual File System (VFS), as do all modern operating systems. When an application needs to access a file, it interacts with the VFS abstraction layer, which then translates all the I/O system calls (reading, writing etc.) into specific code relevant to the particular actual filesystem.

Thus, neither the specific actual filesystem or physical media and hardware on which it resides need be considered by applications. Furthermore, network filesystems (such as NFS) can be handled transparently.

This permits Linux to work with more filesystem varieties than any other operating system. This democratic attribute has been a large factor in its success.

Most filesystems have full read and write access, while a few have only read access and perhaps experimental write access. Some filesystem types, especially non-UNIX based ones, may require more manipulation in order to be represented in the VFS.

Variants such as vfat do not have distinct read/write/execute permissions for the owner/group/world fields; the VFS has to make an assumption about how to specify distinct permissions for the three types of user, and such behavior can be influenced by mounting operations.There are non-kernel filesystem implementations, such as the read/write ntfs-3g
(http://www.tuxera.com/community/ntfs-3g-download) which are reliable but have weaker performance than in-kernel filesystems.

16.6. Available FIlesystems

The most commonly used filesystems include ext4, xfs, btrfs, squashfs, nfs, and vfat.

The table below shows you a partial list of the currently supported filesystems.

 

 Available Filesystems

 
Name	                    Description
===================================================================================
ext4, ext3, ext2	        Native Linux filesystem
proc	                    Used for /proc/
vfat	                    Windows VFAT (includes FAT32, FAT, etc.)
ntfs	                    Windows NT NTFS (read-only)
udf	                        CD R/W, DVD
hfs+        	            Apple MacIntosh Extended HFS
jffs, jffs2	                Journalling Flash Filesystem
iso9660	                    cdrom etc., including Joliet extensions
tmpfs   	                Ram disk that is swappable
gfs2	                    Clustering filesystem from Red Hat
nfs	                        Network Filesystem (through version 4)
smb	                        Samba networking
ncp	                        Novell Netware FS using NCP Protocol
coda	                    Experimental distributed filesystem
afs	                        Andrew distributed filesystem, from Carnegie Mellon
ocfs2	                    Extent-based, disk cluster filesystem from Oracle 

16.8. Journalling FIlesystems

A number of newer, high performance filesystems include full journalling capability.

Journalling filesystems recover from system crashes or ungraceful shutdowns with little or no corruption, and do so very rapidly. While this comes at the price of having some more operations to do, additional enhancements can more than offset the price.

In a journalling filesystem, operations are grouped into transactions. A transaction must be completed without error, atomically; otherwise, the filesystem is not changed. A log file is maintained of transactions. When an error occurs, usually only the last transaction needs to be examined.

The following journalling filesystems are freely available under Linux:

    ext3 was an extension of the earlier non-journalling ext2 filesystem
    ext4 is a vastly enhanced outgrowth of ext3. Features include extents, 48-bit block numbers, and up to 16TB size. Most Linux distributions have used ext4 as the default filesystem for quite a few years
    reiserfs was the first journalling implementation used in Linux, but lost its leadership and further development was abandoned
    JFS was originally a product of IBM and was ported from IBM's AIX operating system
    XFS was originally a product of SGI, and was ported from SGI's IRIX operating systems. RHEL 7 has adopted XFS as its default filesystem
    btrfs is the newest of the journalling filesystems and is still under rapid development.

16.9. Current FIlesystem Types

You can see a list of the filesystem types currently registered and understood by the currently running Linux kernel by doing: 

$ cat /proc/filesystems

Note that additional filesystem types may have their code loaded only when the system tries to access a partition that uses them.

16.10. Special FIlesystems'

Linux widely employs the use of special filesystems for certain tasks. These are particularly useful for accessing various kernel data structures and tuning kernel behavior, or for implementing particular functions. Note that some of these special filesystems have no mount point; this means user applications don't interact with them, but the kernel uses them, taking advantage of VFS layers and code.

 

Special Filesystems

 

Filesystem
Mount               Point        	                    Purpose
=============================================================================================
rootfs	            None	                            During kernel load, provides an empty root directory
hugetlbfs	        Anywhere	                        Provides extended page access (2 or 4 MB on X86)
bdev	            None	                            Used for block devices
proc	            /proc	                            Pseudo filesystem access to many kernel structures and subsystems
sockfs	            None	                            Used by BSD Sockets
tmpfs	            Anywhere	                        RAM disk with swapping, re-sizing
shm	                None	                            Used by System V IPC Shared Memory
pipefs	            None	                            Used for pipes
binfmt_misc	        Anywhere	                        Used by various executable formats
devpts	            /dev/pts	                        Used by Unix98 pseudo-terminals
usbfs	            /proc/bus/usb	                    Used by USB sub-system for dynamical devices
sysfs	            /sys (or elsewhere)	                Used as a device tree
debugfs	            /sys/kernel/debug (or elsewhere)	Used for simple debugging file access

17.1. Disk Partitioning - Introduction

video

17.2. Learning Objectives

By the end of this chapter, you should be able to:

    Describe and contrast the most common types of hard disks and data buses.
    Explain disk geometry and other partitioning concepts.
    Understand how disk devices are named and how to identify their associated device nodes.
    Distinguish among and select different partitioning strategies.
    Use utilities such as blkid and fdisk.
    Back up and restore partition tables.

17.3.a. Common Disk Types I

There are a number of different hard disk types, each of which is characterized by the type of data bus they are attached to, and other factors, such as speed, capacity, how well multiple drives work simultaneously, etc.:

    SATA (Serial Advanced Technology  Attachment)
    These were designed to replace Parallel ATA (PATA), as IDE came to be called. They had faster data transfer, smaller cables and were seen by the operating system as SCSI devices, simplifying the writing of device drivers etc., even though the hardware is not real SCSI.
    Compared to PATA, SATA offers a smaller cable size (7 pins), native hot swapping, and faster and more efficient data transfer. The newest drives can handle 16 GB/s, but 3 GB/s and 6 GB/s are more common in consumer grade devices.
    SCSI (Small Computer Systems Interface)
    These have been the mainstay of Enterprise servers for decades. While they may have lower capacity than that of SATA drives, they tend to be much faster and work in parallel much better, such as is needed for RAID configurations. There are numerous SCSI versions, such as Fast, Wide, Ultra and UltraWide just to make things confusing, and there are many different device drivers depending on the hardware, unlike for SATA, where standardized drivers can fit a large variety of hardware. 
    SCSI disks range from narrow (8 bit bus) to wide (16 bit bus) with a transfer rate of from about 5 MB per second (narrow, standard SCSI) to about 160 MB per second (Ultra-Wide SCSI-3). Most PCs use single-ended or differential SCSI drives. Unfortunately, the two types are not compatible with each other. Fortunately, the two types of devices may coexist on the same controller. Single-ended device controllers may host up to 7 devices and use a maximum cable length of about 6 meters. Differential controllers may host up to 15 devices and have a maximum cable length of about 12 meters.

17.3.b. Common DIsk Types II

Other types of hard disk, besides the ones just mentioned, are:

    SAS
    Serial Attached SCSI is a newer point-to-point serial protocol replacing the earlier Parallel SCSI interface. Data transfer rates are similar to SATA, but overall performance is better.
    USB
    Universal Serial Bus devices include pen drives and external USB drives. The operating system sees them as SCSI devices.
    SSD
    Solid State Drives have come down in price, have no moving parts, use less power than drives with rotational media, and have faster transfer speeds. Internal SSDs are even installed with the same form factor and in the same enclosures as conventional drives. SSDs still cost quite a bit more, but price is decreasing. It is common to have both SSDs and rotational drives in the same machines, with frequently accessed and performance critical data transfers taking place on the SSDs.
    IDE and EIDE (Integrated Drive Electronics, and Enhanced IDE) 
    These were the standard in consumer laptops and desktops for years. However, they are small and slow when compared to more modern hardware and they have therefore become obsolete; controllers can no longer be found in current machines.


17.4.a. Disk Geometry I

Disk Geometry is a concept with a long history for rotational media; one talks of heads, cylinders, tracks and sectors. The below screenshot shows how to view the geometry with fdisk, which we will explore shortly.


17.4.b. DIsk Geomatry II

Rotational disks are composed of one or more platters, each of which is read by one more heads. The heads read a circular track off a platter as the disk spins.

These circular tracks are divided into data blocks called sectors, typically 512 bytes in size. A cylinder is a group which consists of the same track on all platters.

For a long time, this physical structural image has been less and less relevant as internal electronics on the drive actually obscure much of it. Furthermore, SSDs have no moving parts or anything like the above ingredients.

Currently, disks are starting to be manufactured with sectors larger than 512 bytes; 4 KB is becoming available. While larger sector sizes can lead to faster transfer speeds, operating system support is not yet mature in dealing with the larger sizes. 

17.5. Partitioning

Disks are divided into partitions. In geometrical terms, these consist of physically contiguous groups of sectors or cylinders.

A disk may have up to four primary partitions. One of the primary partitions can be designated as an extended partition, which can be subdivided further into logical partitions. 

SCSI and related standards, such as SATA, support up to 15 partitions on the disk. Partitions 1-4 are primary or extended partitions; partitions 5-15 are logical partitions. There can only be one extended partition, but it can be divided into as many logical partitions as needed, until one hits the maximum number of partitions allowed.

For example, the first SCSI or SATA drive is called sda, the second sdb and so on. On the first drive, /dev/sda1 is the first primary partition and /dev/sda2 is the second, etc.

If we created an extended partition as /dev/sda3 it could then be divided into logical partitions, with number designations like /dev/sda5, /dev/sda6 etc.

Note: Linux doesn't require partitions to begin or end on cylinder boundaries, but other operating systems might complain if they don't. For this reason, the widely deployed Linux partitioning utilities try to play nice and end on boundaries. Obviously, partitions should not overlap either. 


17.6.a. Why Partition? I

There are multiple reasons as to why it makes sense to divide your system data into multiple partitions, including:

    Separation
    It is desirable to isolate user and application data from operating system files, most of which are only read except during installation and upgrades. For example, /home, which contains user-specific files is often put on a separate partition. 
    Sharing
    Multiple operating systems or machines may use the same filesystems. For example, /home might be mounted as an NFS share across a network. Or one might have a multi-boot system, even with just different Linux versions and you might want to share something like /usr/local or /home.
    Security
    It may be desirable to impose different quotas, permissions and settings for different parts of the system.
    Size
    Some data is rather constant and some is rather variable or volatile and changes often and can grow quite a bit in size. For example, such variable data is often placed in a /var partition. If the partition gets filled up, it will be less likely to crash the system if one is not filling up a more critical space.


17.4.b. Why Partition? II

Other reasons are:

    Performance
    Data which has to be read often, especially in large chunks, will be accessed more rapidly if it is either placed in a partition on a quicker disk (such as an SSD) or in old-fashioned terms, close to the center of the disk where seek times are shorter.
    Swap
    Linux systems prefer to have swap space placed in a separate partition rather than a file on another partition. This has a secondary advantage that hibernation schemes exploit the space in the swap partition.

A common partition layout contains a /boot partition, a partition for the root filesystem /, a swap partition, and a partition for the /home directory tree.

Keep in mind that it is more difficult to re-size a partition after the fact than during install/creation time. Plan accordingly.

We will discuss filesystem layouts and partitioning impact on them in a later section.


17.7.a. Partition Table I

The disk partition table is contained within the disk's Master Boot Record (MBR), which is 512 bytes in length and whose structure is defined by an operating system-independent convention.

The partition table is 64 bytes long and is placed after the 446 byte boot record. (Note for the curious, there are 2 more bytes at the end of the MBR known as the magic number, signature word, or end of sector marker, which always have the value 0x55AA.)

The first 446 bytes are reserved for program code. They typically hold part of a boot loader program such as GRUB.

Only one partition on a given disk may be marked active. When the system boots, that partition is where the master boot loader looks for items to load. 

17.7.b. Partition Table II

Each entry in the partition table is 16 bytes long, and describes one of the four possible primary partitions. The information for each is:

    Active bit
    Beginning address in cylinder/head/sectors (CHS) format (ignored by Linux)
    Partition type code, indicating: xfs, LVM, ntfs, ext4, swap, etc.
    Ending address in CHS (also ignored by Linux)
    Start sector, counting linearly from 0
    Number of sectors in partition.

Linux only uses the last two fields for addressing using the linear block addressing (LBA) method.

17.8. Naming Disk Devices and Nodes

The Linux kernel interacts at a low level with disks through device nodes normally found in the /dev directory. Normally, device nodes are accessed only through the infrastructure of the kernel's Virtual File System; raw access through the device nodes is an extremely efficient way to destroy a filesystem. For example, you do this when formatting a partition, as in:

$ sudo mkfs.ext4 /dev/sda9

Device nodes for SCSI and SATA disks follow a simple naming convention:

    The first hard disk is /dev/sda
    The second hard disk is /dev/sdb
    Etc.

Partitions are also easily enumerated, as in:

    /dev/sdb1 is the first partition on the second disk
    /dev/sdc4 is the fourth partition on the third disk.

In the above, sd means SCSI or SATA disk. Back in the days where IDE disks could be found, they would have been /dev/hda3, /dev/hdb etc. 

Doing ls -l /dev will show you the current available disk device nodes.

17.9. More on SCSI Device Names

For SCSI devices we need to elaborate a little more on what we mean by first, second hard disk etc. These are determined by the controller number/ID number combination.

The drive designation (a, b, c, etc.) is primarily based on the ID number of the SCSI device rather than its position on the bus itself.

For example, if we had two SCSI controllers with target ID number 1 and 3 on controller 0 and target ID number 2 and 5 on controller 1 (with ID 2 as the last drive):

    ID 1 would be /dev/sda
    ID 3 would be /dev/sdb
    ID 2 (on controller 1) would be /dev/sdc
    ID 5 would be /dev/sdd

17.10.a. blkid and lsblk I

blkid is a utility to locate block devices and report on their attributes. It works with the libblkid library. It can take as an argument a particular device or list of devices. The screenshot below shows a use of blkid with arguments. 

blkid will only work on devices which contain data that is finger-printable; e.g., an empty partition will not generate a block-identifying UUID. blkid has two main forms of operation: either searching for a device with a specific NAME=value pair, or displaying NAME=value pairs for one or more devices. Without arguments, it will report on all devices. There are quite a few options designating how to specify devices and what attributes to report on.

17.10.b. blkid and lsblk II

A related utility is lsblk which presents results in a tree format


NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda      8:0    0 931.5G  0 disk 
\u251c\u2500sda1   8:1    0   512M  0 part /boot/efi
\u251c\u2500sda2   8:2    0 923.1G  0 part /
\u2514\u2500sda3   8:3    0     8G  0 part [SWAP]
sr0     11:0    1  1024M  0 rom  
loop0    7:0    0   4.9M  1 loop /snap/canonical-livepatch/38
loop1    7:1    0  93.5M  1 loop /snap/ao/9
loop2    7:2    0   4.4M  1 loop /snap/canonical-livepatch/26
loop3    7:3    0  81.7M  1 loop /snap/core/4206
loop4    7:4    0  86.6M  1 loop /snap/core/4486
loop5    7:5    0  38.9M  1 loop /snap/telegram-sergiusens/68
loop6    7:6    0  35.8M  1 loop /snap/telegram-sergiusens/53
loop7    7:7    0  86.5M  1 loop /snap/core/4407
loop8    7:8    0     4K  1 loop /snap/anbox-installer/17
loop9    7:9    0   4.9M  1 loop /snap/canonical-livepatch/39
loop10   7:10   0  38.9M  1 loop /snap/telegram-sergiusens/55
loop11   7:11   0   512M  0 loop /mnt

17.11. Sizing Up Partitions

Linux systems should use a minimum of two partitions:

    /(root): used for the entire logical filesystem
    - In practice, most installations will have more than one filesystem on more than one partition, which are joined together at mount points.
    - It is difficult with most filesystem types to resize the root partition; using LVM, which we will discuss later, can make this easier.
    While it is certainly possible to run Linux with just the root partition, most systems use more partitions to allow for easier backups, more efficient use of disk drives, and better security.
    Swap: used as an extension of physical memory; pages of memory which are not file-backed can be moved to disk until needed again.
    - The usual recommendation is swap size should be equal to physical memory in size; sometimes, twice that is recommended. However, the correct choice depends on the related issues of system use scenarios, as well as hardware capabilities. Examples of thinking on this subject can be found at https://help.ubuntu.com/  community/SwapFaq and http://www.novell.com/support/kb/doc.php?id=7010157.
    - The system may have multiple swap partitions and/or swap files.
    - On a single disk system, try to center the swap partition; on multiple disk systems, try to spread swap over disks.
    - Adding more and more swap will not necessarily help because, at a certain point, it becomes useless. One will need to either add more memory or re-evaluate the system setup.

Swap is used as virtual memory: Any time pages from processes are moved out of physical memory, they are generally stored on the swap device.

17.12. Backing Up and Restoring Partition Tables

Partitioning and re-partitioning disks are dangerous operations. In order to be able to restore the situation if something goes wrong, one needs to know how to backup and restore partition tables.

Backing up can be easily done with dd, as in:

$ sudo dd if=/dev/sda of=mbrbackup bs=512 count=1

which will back up the MBR on the first disk, including the 64-bit partition table which is part of it.

The MBR can then be restored, if necessary, by doing:

$ sudo dd if=mbrbackup of=/dev/sda bs=512 count=1

Note that the above commands only copy the primary partition table; they do not deal with any partition tables stored in the other partitions (for extended partitions, etc.)

Note: You should always assume that changing the disk partition table might eliminate all data in all filesystems on the disk (It should not, but be cautious!). Therefore, it is always prudent to make a backup of all data (that is not already backed up) before doing any of this type of work.

In particular, one must be careful in using dd: A simple typing error or misused option could destroy your entire disk; hence, do backups! 

17.13. Partition Table Editors

There are a number of utilities which can be used to manage partition tables:

    fdisk is a menu driven partition table editor. It is the most standard and one of the most flexible of the partition table editors. It is the only one of these utilities we will discuss.
    sfdisk is a non-interactive partition editor program, making it useful for scripting. Use the sfdisk tool with care!
    parted is the GNU partition manipulation program. It can create, remove, resize, and move partitions (including certain filesystems).
    gparted is a widely-used graphical interface to parted.

Many Linux distributions have a live/installation version which can be run off either a CDROM or USB stick. These media usually include a copy of gparted, so they can easily be used as a graphical partitioning tool on disks which are not actually being used while the partitioning program is run.

Note that gparted can do a lot of operations besides just adding and deleting partitions and the other operations fdisk can do, like designating the partition type. One can move and resize partitions and format them as well, which implies it has to understand the details of many filesystem types; this goes far beyond a partition editor's essential functions.

While this is convenient, it is difficult to get right and errors can have serious consequences. Thus, it is often good to drop down to the command line and do each of these operations separately with lower-level tools. In fact, Red Hat Enterprise Linux no longer supports gparted.

17.14.a. Using fdisk I

fdisk will always be included in any Linux installation, so it is a good idea to learn how to use it. You must be root to run fdisk. It can be somewhat complex to handle, and caution is advised.

The fdisk interface is simple and text-menu driven. After starting on a particular disk, as in:

$ sudo fdisk /dev/sdb

the main (one letter) commands are:

    m: Display the menu
    p: List the partition table
    n: Create a new partition
    d: Delete a partition
    t: Change a partition type
    w: Write the new partition table information and exit
    q: Quit without making changes.

Fortunately, no actual changes are made until you write the partition table to the disk by entering w. It is therefore important to verify your partition table is correct (with p) before writing to disk with w. If something is wrong, you can jump out safely with q.

17.14.b. Using fdisk II

The system will not use the new partition table until you reboot. However, you can use the following command:

$ sudo partprobe -s

to try and read in the revised partition table. However, this doesn't always work reliably and it is best to reboot before doing things like formatting new partitions, etc., as mixing up partitions can be catastrophic.

At any time you can do:

$ cat /proc/partitions

to examine what partitions the operating system is currently aware of.

18.1. Filesystem Features: Attributes, Creating, Checking, Mounting - Introduction

video

18.2. Learning Objectives

By the end of this chapter, you should be able to:

    Explain concepts such as inodes, directory files and extended attributes.
    Create and format filesystems.
    Check and fix errors on filesystems.
    Mount and unmount filesystems.

18.3. Inodes

An inode is a data structure on disk that describes and stores file attributes, including location. Every file is associated with its own inode. The information stored in the inode includes:

    Permissions\u200b
    User and group ownership\u200b
    Size\u200b
    Timestamps (nanosecond)
    - \u200bLast access time
    - Last modification time
    - Change time

Note: file names are not stored in a file's inode, but are instead stored in the directory file.

All I/O activity concerning a file usually also involves the file's inode as information must be updated.

18.4. Directory Files

A directory file is a particular type of file that is used to associate file names and inodes. There are two ways to associate (or link) a file name with an inode:

    Hard links point to an inode.\u200b
    Soft (or symbolic) links point to a file name which has an associated inode.

Each association of a directory file contents and an inode is known as a link. Additional links can be created using ln.

Because it is possible (and quite common) for two or more directory entries to point to the same inode (hard links), a file can be known by multiple names, each of which has its own place in the directory structure. However, it can have only one inode no matter which name is being used.

When a process refers to a pathname, the kernel searches directories to find the corresponding inode number. After the name has been converted to an inode number, the inode is loaded into memory and is used by subsequent requests.

18.5.a. Extended Attributes and lsattr/chattr I

 Extended Attributes associate metadata not interpreted directly by the filesystem with files. Four namespaces exist: user, trusted, security, and system. Later, we will see that the system namespace is used for Access Control Lists (ACLs), and the security namespace is used by SELinux.

Flag values are stored in the file inode and may be modified and set only by the root user. They are viewed with lsattr and set with chattr.

In the user namespace, flags may be set for files:

    i: Immutable
    A file with the immutable attribute cannot be modified (not even by root). It cannot be deleted or renamed. No hard link can be created to it, and no data can be written to the file. Only the superuser can set or clear this attribute.
    a: Append-only
    A file with the append-only attribute set can only be opened in append mode for writing. Only the superuser can set or clear this attribute.
    d: No-dump
    A file with the no-dump attribute set is ignored when the dump program is run. This is useful for swap and cache files that you don't want to waste time backing up.
    A: No atime update
    A file with the no-atime-update attribute set will not modify its atime (access time) record when the file is accessed but not otherwise modified. This can increase the performance on some systems because it reduces the amount of disk I/O on the system. 

18.5.b. Extended Attributes and lsattr/chattr II

Note that there are other flags that can be set; typing man chattr will show the whole list. The format for chattr is:

$ chattr [+|-|=mode] filename

lsattr is used to display attributes for a file:

$ lsattr filename

18.6.a. Creating and Formatting Filesystems I

Every filesystem type has a utility for formatting (making) a filesystem on a partition. The generic name for these utilities is mkfs. However, this is just a frontend for filesystem-specific programs.

$ ls -lh /sbin/mkfs*
-rwxr-xr-x 1 root root  11K Feb 15 10:22 /sbin/mkfs
-rwxr-xr-x 1 root root  27K Feb 15 10:22 /sbin/mkfs.bfs
-rwxr-xr-x 1 root root  35K Feb 15 10:22 /sbin/mkfs.cramfs
lrwxrwxrwx 1 root root    9 Dec 23  2015 /sbin/mkfs.exfat -> mkexfatfs
lrwxrwxrwx 1 root root    6 Oct 30  2015 /sbin/mkfs.ext2 -> mke2fs
lrwxrwxrwx 1 root root    6 Oct 30  2015 /sbin/mkfs.ext3 -> mke2fs
lrwxrwxrwx 1 root root    6 Oct 30  2015 /sbin/mkfs.ext4 -> mke2fs
lrwxrwxrwx 1 root root    6 Oct 30  2015 /sbin/mkfs.ext4dev -> mke2fs
-rwxr-xr-x 1 root root  27K May 26  2016 /sbin/mkfs.fat
-rwxr-xr-x 1 root root  76K Feb 15 10:22 /sbin/mkfs.minix
lrwxrwxrwx 1 root root    8 May 26  2016 /sbin/mkfs.msdos -> mkfs.fat
lrwxrwxrwx 1 root root    6 Jan 28  2017 /sbin/mkfs.ntfs -> mkntfs
lrwxrwxrwx 1 root root   10 Nov  7  2015 /sbin/mkfs.reiserfs -> mkreiserfs
lrwxrwxrwx 1 root root    8 May 26  2016 /sbin/mkfs.vfat -> mkfs.fat
-rwxr-xr-x 1 root root 356K Sep  8  2017 /sbin/mkfs.xfs

18.6.b. Creating and Formatting Filesystems II

Thus, the following two commands are entirely equivalent:

$ sudo mkfs -t ext4 /dev/sda10

$ sudo mkfs.ext4 /dev/sda10

The general format for mkfs is:

mkfs [-t fstype] [options] [device-file]

where [device-file] is usually a device name like /dev/sda3 or /dev/vg/lvm1.

Each filesystem type has its own particular options that can be set when formatting. For example, when creating an ext4 filesystem, one thing to keep in mind are the journalling settings. These include defining the journal file size and whether or not to use an external journal file.

One should look at the man page for each of the mkfs.* programs to see details.

18.7.a. Checking and Fixing Filesystems I

Every filesystem type has a utility designed to check for errors (and hopefully fix any that are found). The generic name for these utilities is fsck. However, this is just a frontend for filesystem-specific programs.


$ ls -lh /sbin/fsck*
-rwxr-xr-x 1 root root 44K Feb 15 10:22 /sbin/fsck
-rwxr-xr-x 1 root root 35K Feb 15 10:22 /sbin/fsck.cramfs
lrwxrwxrwx 1 root root   9 Dec 23  2015 /sbin/fsck.exfat -> exfatfsck
lrwxrwxrwx 1 root root   6 Oct 30  2015 /sbin/fsck.ext2 -> e2fsck
lrwxrwxrwx 1 root root   6 Oct 30  2015 /sbin/fsck.ext3 -> e2fsck
lrwxrwxrwx 1 root root   6 Oct 30  2015 /sbin/fsck.ext4 -> e2fsck
lrwxrwxrwx 1 root root   6 Oct 30  2015 /sbin/fsck.ext4dev -> e2fsck
-rwxr-xr-x 1 root root 59K May 26  2016 /sbin/fsck.fat
-rwxr-xr-x 1 root root 76K Feb 15 10:22 /sbin/fsck.minix
lrwxrwxrwx 1 root root   8 May 26  2016 /sbin/fsck.msdos -> fsck.fat
-rwxr-xr-x 1 root root 333 Feb  5  2016 /sbin/fsck.nfs
-rwxr-xr-x 1 root root 282 Nov  7  2015 /sbin/fsck.reiserfs
lrwxrwxrwx 1 root root   8 May 26  2016 /sbin/fsck.vfat -> fsck.fat
-rwxr-xr-x 1 root root 433 Sep  8  2017 /sbin/fsck.xfs
-rwxr-xr-x 1 root root 262 Mar 29 19:39 /sbin/fsck.zfs

18.7.b. Checking and Fixing Filesystems II

Thus, the following two commands are entirely equivalent:

$ sudo fsck -t ext4 /dev/sda10
$ sudo fsck.ext4 /dev/sda10

If the filesystem is of a type understood by the operating system, you can almost always just do:

$ sudo fsck -t ext4 /dev/sda10

and the system will figure out the type by examining the first few bytes on the partition.

fsck is run automatically after a set number of mounts or a set interval since the last time it was run or after an abnormal shutdown. It should only be run on unmounted filesystems. You can force a check of all mounted filesystems at boot by doing:

$ sudo touch /forcefsck
$ sudo reboot

The file /forcefsck will disappear after the successful check. One reason this is a valuable trick is it can do a fsck on the root filesystem, which is hard to do on a running system.


18.7.c. Checking and Fixing Filesystems III

The general format for fsck is:

fsck [-t fstype] [options] [device-file]

where [device-file] is usually a device name like /dev/sda3 or /dev/vg/lvm1. Usually, one does not need to specify the filesystem type, as fsck can figure it out by examining the superblocks at the start of the partition.

One can control whether any errors found should be fixed one by one manually with the -r option, or automatically, as best possible, by using the -a option, etc. In addition, each filesystem type may have its own particular options that can be set when checking.

Note that journalling filesystems are much faster to check than older generation filesystems for two reasons:

    One rarely needs to scan the entire partition for errors, as everything but the very last transaction has been logged and confirmed, so it takes almost no time to check.\u200b
    Even if one does check the whole filesystem, newer filesystems have been designed with fast fsck in mind; older filesystems did not think much about this when they were designed as sizes were much smaller.

One should look at the man page for each of the fsck.* programs to see details.

18.8. Mounting and Unmounting Filesystems

All accessible files in Linux are organized into one large hierarchical tree structure with the head of the tree being the root directory (/). However, it is common to have more than one partition (each of which can have its own filesystem type) joined together in the same filesystem tree. These partitions can also be on different physical devices, even on a network.

The mount program allows attaching at any point in the tree structure; umount allows detaching them.

The mount point is the directory where the filesystem is attached. It must exist before mount can use it; mkdir can be used to create an empty directory. If a pre-existing directory is used and it contains files prior to being used as a mount point, they will be hidden after mounting. These files are not deleted and will again be visible when the filesystem is unmounted.

By default, only the superuser can mount and unmount filesystems.

18.9. mount

Each filesystem is mounted under a specific directory, as in:

$ sudo mount -t ext /dev/sdb4 /home

    Mounts an ext4 filesystem
    The filesystem is located on a specific partition of a hard drive (/dev/sdb4)
    The filesystem is mounted at the position /home in the current directory tree
    Any files residing in the original /home directory are hidden until the partition is unmounted.

Note that in this example the filesystem is mounted by using the device node it resides on. However, it is also possible to mount using a label or a UUID. Thus, the following are all equivalent:

$ sudo mount /dev/sda2  /home
$ sudo mount LABEL=home /home
$ sudo mount    -L home /home
$ sudo mount UUID=26d58ee2-9d20-4dc7-b6ab-aa87c3cfb69a /home
$ sudo mount   -U 26d58ee2-9d20-4dc7-b6ab-aa87c3cfb69a /home

Labels are assigned by filesystem type specific utilities, such as e2label, and UUIDs are assigned when partitions are created as containers for the filesystem.

While any of these three methods for specifying the device can be used, modern systems deprecate using the device node form because the names can change according to how the system is booted, which hard drives are found first, etc. Labels are an improvement, but, on rare occasions, one could have two partitions that wind up with the same label. UUIDs, however, should always be unique, and are created when partitions are created.

18.10.a. mount Options I

mount takes many options, some generic like -a (mount all filesystems mentioned in /etc/fstab) and many filesystem specific; it has a very long man page. A common example would be:

$ sudo mount -o remount,ro /myfs 

which remounts a filesystem with a read-only attribute. 

18.11. umount

Filesystems can be unmounted, as in:

$ umount [device-file | mount-point]

Below are some examples of how to unmount a filesystem:

    Unmount the /home filesystem:
    $ sudo umount /home
    Unmount the /dev/sda3 device:
    $ sudo umount /dev/sda3

Note that the command to unmount a filesystem is umount (not unmount!).

Like mount, umount has many options, many of which are specific to filesystem type. Once again, the man pages are the best source for specific option information.

The most common error encountered when unmounting a filesystem is trying to do this on a filesystem currently in use; i.e., there are current applications using files or other entries in the filesystem.

This can be as simple as having a terminal window open in a directory on the mounted filesystem. Just using cd in that window, or killing it, will get rid of the device is busy error and allow unmounting.

However, if there are other processes inducing this error, you must kill them before unmounting the filesystem. You can use fuser to find out which users are using the filesystem and kill them (be careful with this, you may also want to warn users first). You can also use lsof ("list open files") to try and see which files are being used and blocking unmounting.

18.12. Network Shares (NFS)

t is common to mount remote filesystems through network shares, so they appear as if they were on the local machine. Probably the most common method used historically has been NFS (Network File System).

NFS was originally developed by Sun Microsystems in 1989, and has been continuously updated. Modern systems use NFSv4, which has been con\u200btinuously updated since 2000.

Other network filesystems include AFS (Andrew File System), and SMB (Server Message Book), also termed CIFS (Common Internet File System).

Because a network filesystem may be unavailable at any time, eith\u200ber because it is not present on the network share, or the network is unavailable, systems have to be prepared for this possibility.

Thus, in such circumstances, a system should be instructed not to get hung, or blocked, while waiting longer than a specified period. These can be specified in the mount command:

$ sudo mount -t nfs myserver.com:/sharedir /mnt/sharedir\u200b

or in /etc/fstab. Put the following line in /etc/fstab to mount on boot or with mount -a:\u200b

myserver.com:/sharedir /mnt/sharedir nfs rsize=8192,wsize=8192,timeo=14,intr 0 0

The system may try to mount the NFS filesystem before the network is up. The _netdev and noauto options can be used. For more information, check man nfs, examine the mount options.

It can also be solved using autofs or automount.

Mount has a large amount of options, some of which are specific to nfs. See the man pages for both nfs and mount for \u200bmore details.

18.13.a. Mounting Filesystems at Boot I

During system boot, the command mount -a is executed. This mounts all filesystems listed in the /etc/fstab configuration file. Entries can refer to both local and remote network-mounted filesystems. Here is an example showing you how to mount all filesystems listed in the /etc/fstab configuration file during system boot.

This file shows what filesystems may be automatically mounted at boot and where they may be found on the local machine or network. It can specify who may mount them and with what permissions, and other relevant options. Some of the lines refer to special pseudo-filesystems such as proc, sys, and devpts.

18.13.b. Mounting Filesystems at Boot II

Each record in the file contains fields separated by white space listing:

    Device node, label, or UUID
    For filesystems which do not have a device node, such as tmpfs, proc, and sysfs, this field is just a place holder; sometimes, you will see the word none in that column, or used on the command line.
    Mount point
    This can also be a place holder, like for swap, which is not mounted anywhere.
    A comma-separated list of options
    dump frequency (or a 0) 
    This is used by the dump -w command.
    fsck pass number (or 0, meaning do not check state at boot).

18.13.c. Mounting Filesystems at Boot III

The mount and umount utilities can use information in /etc/fstab; in such a case one could type

$ sudo mount /usr/src    

instead of

$ sudo mount LABEL=src /usr/src

in the above example.

18.14. Automatic Filesystem Mounting

Linux systems have long had the ability to mount a filesystem only when it is needed. Historically, this was done using autofs. This utility requires installation of the autofs package using the appropriate package manager and configuration of files in /etc.

While autofs is very flexible and well understood, systemd-based systems (including all recent enterprise Linux distributions) come with automount facilities built into the systemd framework. Configuring this is as simple as adding a line in /etc/fstab specifying the proper device, mount point and mounting options, such as:

LABEL=Sam128 /SAM ext4 noauto,x-systemd.automount,x-systemd.device-timeout=10,x-systemd.idle-timeout=30 0 0

and then, either rebooting or issuing the command:

$ sudo systemctl daemon-reload
$ sudo systemctl restart local-fs.target

Next, we will give an example and explain the options. 

18.15. automount Example

The example provided mounts a USB pen drive that is always plugged into the system, only when it is used. Options in /etc/fstab:

    noauto
    Do not mount at boot. Here, auto does not refer to automount.

    x-systemd.automount
    Use the systemd automount facility.

    x-systemd.automount.device-timeout=10
    If this device is not available, say it is a network device accessible through NFS, timeout after 10 seconds instead of getting hung.

    x-systemd.automount.idle-timeout=30
    If the device is not used for 30 seconds, unmount it. 

Note that the device may be mounted during boot, but then it should be unmounted after the timeout specified.

18.16. Listing Currently Mounted Filesystems

The list of currently mounted filesystems can be seen by typing: $ mount

19.1. Filesystem Features: Swap, Quotas, Usage - Introduction

Linux uses a robust swap space implementation through which the virtual memory system permits the apparent use of more memory than is physically available. Filesystem quotas can be used to administer user account usage of disk space. Utilities such as df and du enable easy monitoring of filesystem usage and capacities. 

19.1. Learning Objectives

By the end of this chapter, you should be able to:

    Explain the concepts of swap and quotas.
    Use the utilities that help manage quotas: quotacheck, quotaon, quotaoff, edquota, and quota.
    Use the utilities df and du.

19.3.a. Swap I

Linux employs a virtual memory system, in which the operating system can function as if it had more memory than it really does. This kind of memory overcommission functions in two ways:

    Many programs do not actually use all the memory they are given permission to use. Sometimes, this is because child processes inherit a copy of the parent's memory regions utilizing a COW (Copy On Write) technique, in which the child only obtains a unique copy (on a page-by-page basis) when there is a change.
    When memory pressure becomes important, less active memory regions may be swapped out to disk, to be recalled only when needed again.

Such swapping is usually done to one or more dedicated partitions or files; Linux permits multiple swap areas, so the needs can be adjusted dynamically. Each area has a priority, and lower priority areas are not used until higher priority areas are filled.

19.3.b. Swap II

In most situations, the recommended swap size is the total RAM on the system. You can see what your system is currently using for swap areas by looking at /proc/swaps and get basic memory statistics with free:

19.3.c. Swap III

The only commands involving swap are:

    mkswap: format a swap partition or file
    swapon: activate a swap partition or file
    swapoff: deactivate a swap partition or file.

At any given time, most memory is in use for caching file contents to prevent actually going to the disk any more than necessary, or in a sub-optimal order or timing. Such pages of memory are never swapped out as the backing store is the files themselves, so writing out a swap would be pointless; instead, dirty pages (memory containing updated file contents that no longer reflect the stored data) are flushed out to disk.

It is also worth pointing out that in Linux memory used by the kernel itself, as opposed to application memory, is never swapped out, in distinction to some other operating systems.

19.4. Quotas

Linux can use and enforce quotas on filesystems. Disk quotas allow administrators to control the maximum space particular users (or groups) are allowed. Considerable flexibility is allowed and quotas can be assigned on a per filesystem basis. Protection is provided against a subset of users exhausting collective resources.   

These utilities help manage quotas:

    quotacheck: generates and updates quota accounting files
    quotaon: enables quota accounting
    quotaoff: disables quota accounting
    edquota: used for editing user or group quotas
    quota: reports on usage and limits.

Quota operations require the existence of the files aquota.user and aquota.group in the root directory of the filesystem using quotas.

Quotas may be enabled or disabled on a per filesystem basis. In addition, Linux supports the use of quotas based on user and group IDs.

Different filesystem types may have additional quota-related utilities, such as xfs_quota.

19.5.a. Setting up Quotas I

To create a filesystem quota, you must first make sure you have mounted the filesystem with the user and/or group quota mount options. Without these, nothing else will work. The basic steps are:

    Mount the filesystem with user and/or group quota options:
    - Add the usrquota and/or grpquota options to the filesystems entry in /etc/fstab
    - Remount the filesystem (or mount it if new)
    Run quotacheck on the filesystem to set up quotas
    Enable quotas on the filesystem
    Set quotas with the edquota program.


19.5.b. Setting up Quotas II

Thus, to create a filesystem quota you must first make sure that you have mounted the filesystem with the user and/or group quota mount options. Without these, nothing else will work.

First, you need to put the right options in /etc/fstab as in:

/dev/sda5 /home ext4 defaults,usrquota 1 1

where we have assumed /home is on a dedicated partition.

Then, test with the following commands:

$ sudo mount -o remount /home

$ sudo quotacheck -vu /home

$ sudo quotaon -vu /home

$ sudo edquota someusername

You may also want to set up grace periods with edquota. The mount options that should be used in the /etc/fstab file are usrquota for user quotas and grpquota for group quotas.


19.6. quotacheck

The quotacheck utility creates/updates the quota accounting files (aquota.user and aquota.group) for the filesystem.

To update user files for all filesystems in /etc/fstab with user quota options:

$ sudo quotacheck -ua

To update group files for all filesystems in /etc/fstab with group quota options:

$ sudo quotacheck -ga

To update the user file for a particular filesystem:

$ sudo quotacheck -u [somefilesystem]

To update the group file for a particular filesystem:

$ sudo quotacheck -g [somefilesystem]

Use the -v option to get more verbose output.

quotacheck is generally only run when quotas are initially turned on (or need to be updated). The program may also be run when fsck reports errors in the filesystem when the system is starting up.

19.7.a. Turning quotas on and off I

quotaon is used to turn filesystem quotas on; quotaoff is used to turn them off. They are used as in:

$ sudo quotaon  [flags] [filesystem]

$ sudo quotaoff [flags] [filesystem]

where the flags can be:

-a, --all                               turn quotas off for all filesystems
-f, --off                               turn quotas off
-u, --user                              operate on user quotas
-g, --group                             operate on group quotas
-p, --print-state                       print whether quotas are on or off
-x, --xfs-command=cmd                   perform XFS quota command
-F, --format=formatname                 operate on specific quota format
-v, --verbose                           print more messages
-h, --help                              display this help text and exit
-V, --version                           display version information and exit

19.7.b. Turning quotas on and off II

Note that quotaon and quotaoff programs are really one and the same and operate accordingly to which name they are called with.

For example:

$ sudo quotaon -av
/dev/sda6 [/]: group quotas turned on
/dev/sda5 [/home]: user quotas turned on

$ sudo quotaoff -av
/dev/sda6 [/]: group quotas turned off
/dev/sda5 [/home]: user quotas turned off

$ sudo quotaon -avu
/dev/sda5 [/home]: user quotas turned on

$ sudo quotaoff -avu
/dev/sda5 [/home]: user quotas turned off

$ sudo quotaon -avg
/dev/sda6 [/]: group quotas turned on

$ sudo quotaoff -avg
/dev/sda6 [/]: group quotas turned off

Note also that quota operations will fail if the files aquota.user or aquota.group do not exist.


19.8. Examining Quotas

The quota utility is used to generate reports on quotas:

    quota (or quota -u) returns your current user quota.
    quota -g returns your current group quota.
    The superuser may look at quotas for any user or group by specifying a user or group name.

For example:

$ sudo quota george

Disk quotas for user george (uid 1000):

   Filesystem   blocks quota limit grace files quota limit grace

      /dev/sda5 837572   500  1000        5804     0     0

$ sudo quota gracie

Disk quotas for user gracie (uid 1001):

  Filesystem     blocks quota limit grace files quota limit grace

    /dev/sda5     83757  5000 10000        5804     0     0

19.9.a. Setting Quotas I

Typing edquota brings up the quota editor. For the specified user or group, a temporary file is created with a text representation of the current disk quotas for that user or group.

Then, an editor is invoked for that file, and quotas may then be modified. Once you leave the editor, the temporary file is read and the binary quota files adopt the changes.

The only fields which can be edited in the quota are the soft and hard limits. The other fields are informational only.

Below are examples of how to use edquota:

    edquota -u [username] edits limits for username
    edquota -g [groupname] edits limits for groupname
    edquota -u -p [userproto] [username] copies userproto's user quota values to username
    edquota -g -p [groupproto] [groupname] copies groupproto's group quota values to groupname
    edquota -t to set grace periods

The third and fourth commands are useful for including in scripts which might be used to create new accounts and set quotas for them.


19.9.b. Setting Quotas II

Quotas for users and groups may be set for disk blocks and/or inodes. In addition, soft and hard limits may be set as well as grace periods: Soft limits may be exceeded for a grace period. Hard limits may never be exceeded.

The grace period is set on a per filesystem basis.

$ sudo edquota gracie

$ sudo edquota -t


19.10. Filesystem Usage

The df (disk free) utility examines filesystem capacity and usage. In the example we provided here the -h option means "human-readable" (i.e., in KB, MB, GB, not bytes) and -T shows the filesystem type. Using the -i option would show inode information instead of bytes.


19.11. Disk Space Usage


